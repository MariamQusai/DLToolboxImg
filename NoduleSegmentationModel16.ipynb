{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NoduleSegmentationModel16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/x110/DLToolboxImg/blob/master/NoduleSegmentationModel16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EIFzslyej3R8",
        "toc": true
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Colab-Configuration\" data-toc-modified-id=\"Colab-Configuration-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Colab Configuration</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Settings\" data-toc-modified-id=\"Settings-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Settings</a></span></li><li><span><a href=\"#Model-Code\" data-toc-modified-id=\"Model-Code-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model Code</a></span></li><li><span><a href=\"#Nodule-Segmentation:-Model\" data-toc-modified-id=\"Nodule-Segmentation:-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Nodule Segmentation: Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-mean-of-images\" data-toc-modified-id=\"Find-mean-of-images-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Find mean of images</a></span></li><li><span><a href=\"#Find-variance-of-images\" data-toc-modified-id=\"Find-variance-of-images-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Find variance of images</a></span></li></ul></li><li><span><a href=\"#Data-Iterator\" data-toc-modified-id=\"Data-Iterator-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Data Iterator</a></span></li><li><span><a href=\"#Evaluation-Metric\" data-toc-modified-id=\"Evaluation-Metric-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Evaluation Metric</a></span></li><li><span><a href=\"#Model-Architecture\" data-toc-modified-id=\"Model-Architecture-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Model Architecture</a></span></li></ul></li><li><span><a href=\"#Nodule-Segmentation:-Model\" data-toc-modified-id=\"Nodule-Segmentation:-Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Nodule Segmentation: Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optimizer\" data-toc-modified-id=\"Optimizer-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Optimizer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find--learning-rate\" data-toc-modified-id=\"Find--learning-rate-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Find  learning rate</a></span></li><li><span><a href=\"#Optimizer-Parameters\" data-toc-modified-id=\"Optimizer-Parameters-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Optimizer Parameters</a></span></li></ul></li></ul></li></ul></div>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "W6ljz0jskI2x"
      },
      "cell_type": "markdown",
      "source": [
        "# Colab Configuration"
      ]
    },
    {
      "metadata": {
        "id": "wmIVeRAD-6xW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "colab = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "code_folding": [
          0
        ],
        "colab_type": "code",
        "id": "2nWGr82Ik3t_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3baB9y9EJoA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "code_folding": [
          0
        ],
        "colab_type": "code",
        "id": "faJWgZ4m-OyT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab:    \n",
        "    # Remove CUDA 9 completely\n",
        "    !apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "    !apt-get remove cuda-*\n",
        "    !dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "    !apt autoremove\n",
        "    !apt-get update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "code_folding": [
          0
        ],
        "colab_type": "code",
        "id": "xQt0wZRLkM62",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab:\n",
        "    # Install CUDA 8\n",
        "    !wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb\n",
        "    !dpkg -i --force-overwrite cuda-repo-ubuntu1604_8.0.61-1_amd64.deb\n",
        "    !apt-get update\n",
        "    !apt-get install cuda-8-0\n",
        "\n",
        "    # install will fail, need to force dpkg to overwrite the configuration file\n",
        "\n",
        "    !wget http://archive.ubuntu.com/ubuntu/pool/main/m/mesa/libglx-mesa0_18.0.5-0ubuntu0~18.04.1_amd64.deb\n",
        "    !dpkg -i --force-overwrite libglx-mesa0_18.0.5-0ubuntu0~18.04.1_amd64.deb\n",
        "\n",
        "    !wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/nvidia-410_410.48-0ubuntu1_amd64.deb\n",
        "    !dpkg -i --force-overwrite nvidia-410_410.48-0ubuntu1_amd64.deb\n",
        "\n",
        "    !apt --fix-broken install\n",
        "    !apt-get install cuda-8-0\n",
        "\n",
        "    #More packages ro install \n",
        "    !pip uninstall -y numpy\n",
        "    !pip uninstall -y scipy\n",
        "    !pip install turicreate\n",
        "    # The worng version of MXNET will be installed.\n",
        "    !pip uninstall -y mxnet\n",
        "    !pip install scipy\n",
        "    # Instal CUDA8-compatible version of mxnet 1.1.0\n",
        "    !pip install mxnet-cu80==1.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "hreX2n06B5dg"
      },
      "cell_type": "markdown",
      "source": [
        "#  Load Data"
      ]
    },
    {
      "metadata": {
        "id": "G4saZxdM-6x2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab:\n",
        "    root_path = \"/content/drive/My Drive/x110/\"\n",
        "else:\n",
        "    root_path = \"/home/mas/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXHf1r38Kyi4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = \"x110/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "M7hmz4sRBd40",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab:\n",
        "    !mkdir {PATH}\n",
        "    !mkdir {PATH+\"Datasets\"}\n",
        "    !mkdir {PATH+\"Datasets/Dataset5/\"}\n",
        "    !mkdir {PATH+\"Datasets/Dataset5/processed/\"}\n",
        "    !mkdir {PATH+\"model\"}\n",
        "\n",
        "    !mkdir x110/DLToolboxImg\n",
        "    !git clone https://github.com/x110/DLToolboxImg.git x110/DLToolboxImg\n",
        "\n",
        "\n",
        "    dataset_path = root_path+'Datasets/Dataset5/processed/.'\n",
        "    !cp -a \"{dataset_path}\" {PATH+\"Datasets/Dataset5/processed/\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tdlUnJDra1Ne",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm -r x110/DLToolboxImg\n",
        "#!mkdir x110/DLToolboxImg\n",
        "#!git clone https://github.com/x110/DLToolboxImg.git x110/DLToolboxImg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TWY_-L4qDQXY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_path1 = root_path+\"model/model15/\"\n",
        "#model details\n",
        "prefix1 = \"jan17\"\n",
        "model_epoch=0\n",
        "\n",
        "model_path2 = root_path+\"model/model15/\"\n",
        "prefix2 = \"jan17\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7oArm9XTEWk-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "load_model = True\n",
        "find_stats = False#True\n",
        "bs = 34#100#64#34"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-A_IctC4ABII"
      },
      "cell_type": "markdown",
      "source": [
        "# Settings"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HT3hdPbNk6zy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Dataset Path \n",
        "interm_dir4 = root_path+ \"Datasets/Dataset5/processed/\"\n",
        "s = \"2018_11_25\"\n",
        "train_data_path=interm_dir4+'train'+s+'pos.rec'\n",
        "train_idx_path=interm_dir4+'train'+s+'pos.idx'\n",
        "valid_data_path=interm_dir4+'valid'+s+'pos.rec'\n",
        "valid_idx_path=interm_dir4+'valid'+s+'pos.idx'\n",
        "test_data_path=interm_dir4+'test'+s+'pos.rec'\n",
        "test_idx_path=interm_dir4+'test'+s+'pos.idx'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ITGUgg7UB6BJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if load_model and colab:\n",
        "  drivefile = model_path1+prefix1+\"-\"+\"{:04d}\".format(model_epoch)+\".params\"\n",
        "  drivefile2 = model_path1+prefix1+\"-symbol.json\"\n",
        "  colabfile = PATH+\"model/\"+prefix1+\"-\"+\"{:04d}\".format(model_epoch)+\".params\"\n",
        "  colabfile2 = PATH+\"model/\"+prefix1+\"-symbol.json\"\n",
        "\n",
        "  !cp  \"{drivefile}\" {colabfile}\n",
        "  !cp  \"{drivefile2}\" {colabfile2}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZH7G6KOCw3En",
        "colab_type": "code",
        "outputId": "0b111db6-e2c4-416f-a7ca-f324caec8a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda-repo-ubuntu1604_8.0.61-1_amd64.deb\n",
            "drive\n",
            "libglx-mesa0_18.0.5-0ubuntu0~18.04.1_amd64.deb\n",
            "nvidia-410_410.48-0ubuntu1_amd64.deb\n",
            "sample_data\n",
            "x110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fRuO7y9fj3R3"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Code"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "F7JkqZ0mj3SM",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,\"x110/DLToolboxImg/src/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2yYRVHIdj3SU",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import mynnet7 as nn\n",
        "import pickle\n",
        "import mxnet as mx\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Vbr8CTJj4t8F",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import mxnet as mx\n",
        "import sys, os\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import re\n",
        "from mxnet.io import DataIter\n",
        "from mxnet.io import DataBatch\n",
        "import pandas as pd\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from collections import namedtuple\n",
        "import pickle\n",
        "\n",
        "Batch = namedtuple('Batch', ['data'])\n",
        "\n",
        "BATCH_SIZE,INPUT_SIZE_z,INPUT_SIZE_y, INPUT_SIZE_x = 8,32,32,32\n",
        "\n",
        "class FileIter(DataIter):\n",
        "    def __init__(self, path,path_idx,\n",
        "                 data_name=\"data\",\n",
        "                 label_name=\"softmax_label\",\n",
        "                 batch_size=1,\n",
        "                 do_augment=False,\n",
        "                 random_flip=False,\n",
        "                 random_rot=False,\n",
        "                 random_elastic=False, \n",
        "                 mean_image=.28,\n",
        "                 std_image = .28,\n",
        "                 do_shuffle = True):\n",
        "\n",
        "        \n",
        "        random.seed(313)\n",
        "        self.ind2=None\n",
        "        self.do_shuffle = do_shuffle\n",
        "        self.epoch = 0\n",
        "        self.mean_image = mean_image\n",
        "        self.std_image = std_image\n",
        "        \n",
        "        super(FileIter, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.do_augment=do_augment\n",
        "        self.random_flip = random_flip\n",
        "        self.random_rot = random_rot\n",
        "        self.random_elastic = random_elastic\n",
        "\n",
        "        self.data_name = data_name\n",
        "        self.label_name = label_name\n",
        "\n",
        "        self.record = mx.recordio.MXIndexedRecordIO(path_idx, path, 'r')#mx.recordio.MXRecordIO(path, 'r')\n",
        "\n",
        "        \n",
        "        def readrecord(record):\n",
        "            record.reset()\n",
        "            num_data=0\n",
        "            while True:\n",
        "                item = record.read()\n",
        "                num_data+=1\n",
        "                if not item:\n",
        "                    break\n",
        "            return num_data-1\n",
        "        \n",
        "        \n",
        "        self.num_data = readrecord(self.record)#len(open(self.flist_name, 'r').readlines())\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.idx = self.shuffle_idx()\n",
        "        self.cursor = -1\n",
        "        self.cursor2 = -1\n",
        "        self.ind = self.idx[0]\n",
        "        self.record.reset()\n",
        "\n",
        "        self.data, self.label = self._read()\n",
        "        self.reset()\n",
        "            \n",
        "    def shuffle_idx(self):\n",
        "        num_data = self.num_data//self.batch_size*self.batch_size\n",
        "        idx = [i for i in range(num_data)]\n",
        "        if self.do_shuffle:\n",
        "            random.shuffle(idx)\n",
        "        idx = np.array(idx)\n",
        "        idx = idx.reshape(-1,self.batch_size)\n",
        "        return idx\n",
        "    \n",
        "    def _read(self):\n",
        "        \"\"\"get two list, each list contains two elements: name and nd.array value\"\"\"\n",
        "                \n",
        "        data = {}\n",
        "        label = {}\n",
        "\n",
        "        dd = []\n",
        "        ll = []\n",
        "        \n",
        "        if self.ind2 is None:\n",
        "            ind = self.ind\n",
        "        else:\n",
        "            ind = self.ind2\n",
        "            self.ind2=None\n",
        "            \n",
        "        for i in range(0, self.batch_size):\n",
        "            \n",
        "            item = self.record.read_idx(ind[i])            \n",
        "            header, l = mx.recordio.unpack_img(item)\n",
        "            \n",
        "            d=header.label\n",
        "\n",
        "            d=d.reshape((32,32,32))- self.mean_image\n",
        "            d = d/self.std_image\n",
        "            \n",
        "            l=l.reshape((32,32,32))\n",
        "            \n",
        "            if self.random_elastic:            \n",
        "              if random.randint(0, 100) > 50:\n",
        "                d=np.array([elastic_transform(subd, 34, 4) for subd  in d])\n",
        "                l=np.array([elastic_transform(subl, 34, 4) for subl  in l])\n",
        "\n",
        "                \n",
        "            data11=np.concatenate((d,l),axis=0)  \n",
        "            \n",
        "\n",
        "            if self.random_rot:\n",
        "              if random.randint(0, 100) > 50:\n",
        "                n,rows,cols = data11.shape\n",
        "                rot =40* random.random()-20\n",
        "                M = cv2.getRotationMatrix2D((cols/2,rows/2),rot,1)\n",
        "                data11=np.array([cv2.warpAffine(d,M,(cols,rows))for d in data11])\n",
        "\n",
        "            d,l=np.vsplit(data11,2)\n",
        "\n",
        "            if self.random_flip:\n",
        "            \tl=l.reshape((32,32,32))\n",
        "            \td,l = random_flip_img(d,l, horizontal_chance=0.5, vertical_chance=0.5)\n",
        "\n",
        "            d = np.expand_dims(d, axis=0) \n",
        "            d = np.expand_dims(d, axis=0)\n",
        "            l=l.reshape((32*32*32))\n",
        "            l=l.astype(float)\n",
        "            l = np.expand_dims(l, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "            dd.append(d)\n",
        "            ll.append(l)\n",
        "\n",
        "        d = np.vstack(dd)\n",
        "        l = np.vstack(ll)\n",
        "        data[self.data_name] = d\n",
        "        label[self.label_name] = l\n",
        "        res = list(data.items()), list(label.items())\n",
        "        return res\n",
        "\n",
        "    @property\n",
        "    def provide_data(self):\n",
        "        \"\"\"The name and shape of data provided by this iterator\"\"\"\n",
        "        res = [(k, tuple(list(v.shape[0:]))) for k, v in self.data]\n",
        "        # print \"data : \" + str(res)\n",
        "        return res\n",
        "\n",
        "    @property\n",
        "    def provide_label(self):\n",
        "        \"\"\"The name and shape of label provided by this iterator\"\"\"\n",
        "        res = [(k, tuple(list(v.shape[0:]))) for k, v in self.label]\n",
        "        return res\n",
        "    \n",
        "\n",
        "    def reset(self):\n",
        "        self.cursor = -1\n",
        "        self.cursor2 = -1\n",
        "        self.record.reset()\n",
        "        self.epoch += 1\n",
        "        self.idx = self.shuffle_idx()\n",
        "        \n",
        "\n",
        "\n",
        "    def getpad(self):\n",
        "        return 0\n",
        "\n",
        "    def iter_next(self):\n",
        "        self.cursor += self.batch_size\n",
        "        self.cursor2 += 1\n",
        "        num_data = self.num_data//self.batch_size*self.batch_size\n",
        "            \n",
        "\n",
        "        if self.cursor < self.num_data:\n",
        "            self.ind = self.idx[self.cursor2]\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def eof(self):\n",
        "        res = self.cursor >= self.num_data\n",
        "        return res\n",
        "\n",
        "    def next(self):\n",
        "        \"\"\"return one dict which contains \"data\" and \"label\" \"\"\"\n",
        "        if self.iter_next():\n",
        "            self.data, self.label = self._read()\n",
        " \n",
        "            res = DataBatch(data=[mx.nd.array(self.data[0][1])], label=[mx.nd.array(self.label[0][1])], pad=self.getpad(), index=None)\n",
        "\n",
        "            return res\n",
        "        else:\n",
        "            raise StopIteration\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9hXyEtQCQZpY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "ELASTIC_INDICES = None  # needed to make it faster to fix elastic deformation per epoch.\n",
        "def elastic_transform(image, alpha, sigma, random_state=None):\n",
        "  global ELASTIC_INDICES\n",
        "  shape = image.shape\n",
        "\n",
        "  if ELASTIC_INDICES == None:\n",
        "      if random_state is None:\n",
        "          random_state = np.random.RandomState(1301)\n",
        "\n",
        "      dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
        "      dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
        "      x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]))\n",
        "      ELASTIC_INDICES = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1))\n",
        "  return map_coordinates(image, ELASTIC_INDICES, order=1).reshape(shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lc2EWJ_VQeoZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_flip_img(X,Y, horizontal_chance=0.5, vertical_chance=0.5):\n",
        "    import cv2\n",
        "    flip_horizontal = False\n",
        "    if random.random() < horizontal_chance:\n",
        "        flip_horizontal = True\n",
        "\n",
        "    flip_vertical = False\n",
        "    if random.random() < vertical_chance:\n",
        "        flip_vertical = True\n",
        "\n",
        "    if not flip_horizontal and not flip_vertical:\n",
        "        return (X,Y)\n",
        "\n",
        "    flip_val = 1\n",
        "    if flip_vertical:\n",
        "        flip_val = -1 if flip_horizontal else 0\n",
        "\n",
        "    Xaug = np.array([cv2.flip(x, flip_val) for x in X])\n",
        "    Yaug = np.array([cv2.flip(x, flip_val) for x in Y])\n",
        "\n",
        "    return (Xaug,Yaug)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UvT1TmQgBdoL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.ndimage.interpolation import zoom\n",
        "def resample(imgs, spacing, new_spacing,order=2):\n",
        "    if len(imgs.shape)==3:\n",
        "        new_shape = np.round(imgs.shape * spacing / new_spacing)\n",
        "        true_spacing = spacing * imgs.shape / new_shape\n",
        "        resize_factor = new_shape / imgs.shape\n",
        "        imgs = zoom(imgs, resize_factor, mode = 'nearest',order=order)\n",
        "        return imgs, true_spacing\n",
        "    elif len(imgs.shape)==4:\n",
        "        n = imgs.shape[-1]\n",
        "        newimg = []\n",
        "        for i in range(n):\n",
        "            slice = imgs[:,:,:,i]\n",
        "            newslice,true_spacing = resample(slice,spacing,new_spacing)\n",
        "            newimg.append(newslice)\n",
        "        newimg=np.transpose(np.array(newimg),[1,2,3,0])\n",
        "        return newimg,true_spacing\n",
        "    else:\n",
        "        raise ValueError('wrong shape')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ii6TA8bkBnev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "    def resample(self):\n",
        "\n",
        "        image=self.image_HU.copy() #zxy\n",
        "\n",
        "        image=image.swapaxes(0,2) #yxz\n",
        "        image=image.swapaxes(0,1) #xyz\n",
        "\n",
        "        resize_factor = self.original_spacing/self.desired_spacing\n",
        "\n",
        "        new_real_shape = image.shape * resize_factor\n",
        "\n",
        "        new_shape = np.round(new_real_shape)\n",
        "\n",
        "        real_resize_factor = new_shape/image.shape\n",
        "\n",
        "        new_spacing = self.original_spacing/real_resize_factor\n",
        "\n",
        "        image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
        "\n",
        "        image=image.swapaxes(0,2) #zyx\n",
        "        image=image.swapaxes(1,2) #zxy\n",
        "\n",
        "        return image, new_spacing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "soL0gxgvbybh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2rhJhA7sbyni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7z7MuZFKbysQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i1gjnrgZbywY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uQ-7Sa0jbyqf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wkuGr3Psbyld",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "r57gImHw6rX4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qEE6i_txGY1C",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "mx.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xe-Fv5N2a9Ra"
      },
      "cell_type": "markdown",
      "source": [
        "# Nodule Segmentation: Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GWkyDSB2j3S_"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "T_OZbL4Mj3TC"
      },
      "cell_type": "markdown",
      "source": [
        "### Find mean of images"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "To2ssEIvj3TG",
        "outputId": "ed900bd9-b624-42e1-88a4-76e30bd1a4cd",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "cell_type": "code",
      "source": [
        "if find_stats:\n",
        "    BATCH_SIZE=1\n",
        "    train_iter=nn.FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_augment=True,mean_image=0,std_image=1)\n",
        "    train_iter.reset()\n",
        "    x_mean = np.zeros((32,32,32))\n",
        "    for i,batch in enumerate(train_iter):\n",
        "        X =  batch.data[0][0][0].asnumpy()\n",
        "        x_mean+=X\n",
        "    x_mean=np.mean(x_mean/i)\n",
        "    # Saving the objects:\n",
        "    with open(interm_dir4+'x_mean.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "        pickle.dump([x_mean], f)\n",
        "\n",
        "else:\n",
        "    with open(interm_dir4+'x_mean.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
        "        x_mean = pickle.load(f)\n",
        "x_mean#x_mean=0.2826227159416579"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a5a90de34235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterm_dir4\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'x_mean.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3: open(..., 'rb')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mx_mean\u001b[0m\u001b[0;31m#x_mean=0.2826227159416579\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/x110/Datasets/Dataset5/processed/x_mean.pkl'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eRUFk9Juj3TT",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_mean=0.28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "raNj5rVmj3Td"
      },
      "cell_type": "markdown",
      "source": [
        "### Find variance of images"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z7p4QBZKj3Tg",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if find_stats: \n",
        "    BATCH_SIZE=1\n",
        "    train_iter=nn.FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_augment=True,mean_image=0,std_image = 1)\n",
        "    train_iter.reset()\n",
        "    x_var = np.zeros((32,32,32))\n",
        "    for i,batch in enumerate(train_iter):\n",
        "        X =  (batch.data[0][0][0].asnumpy()-x_mean)**2\n",
        "        x_var+=X\n",
        "    #x_var=x_var/(i-1)\n",
        "    #x_var#x_mean=.2815\n",
        "    N = i*32*32*32\n",
        "    x_var = np.sum(x_var)/(N-1)\n",
        "    x_var#x_var = .07877\n",
        "    x_std = np.sqrt(x_var)#x_std=.2807\n",
        "    with open(interm_dir4+'x_std.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "        pickle.dump([x_std], f)\n",
        "else:\n",
        "    with open(interm_dir4+'x_std.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
        "        x_std = pickle.load(f)\n",
        "x_std#x_std=0.2817920662435274"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yXzLyS3Lj3To",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_std = 0.28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nIpXpHQxj3Tw"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Iterator"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cb3ZRqqWj3Ty",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=bs\n",
        "train_iter=FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,random_elastic = True,random_flip=True,random_rot=True,do_augment=True,mean_image=x_mean,std_image = x_std,do_shuffle=True)\n",
        "input_shapes = dict(train_iter.provide_data+train_iter.provide_label)\n",
        "print(input_shapes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "39QY_Ip9j3T8",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=bs\n",
        "valid_iter=FileIter(valid_data_path,valid_idx_path,batch_size=BATCH_SIZE,do_augment=False,mean_image=x_mean,std_image = x_std,do_shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EO0l_t4Ej3UC",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_iter.reset()\n",
        "valid_iter.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MKxlY8J9j3UH"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metric"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LIeANhbqj3UJ",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_coef2(label, y):\n",
        "    smooth = 1.\n",
        "    label=mx.nd.array(label).as_in_context(mx.gpu(0))\n",
        "    y=mx.nd.array(y).as_in_context(mx.gpu(0))\n",
        "    intersection = mx.nd.sum(label*y)\n",
        "    return ((2. * intersection + smooth) / (mx.nd.sum(label) +mx.nd.sum(mx.nd.abs(y)) + smooth))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z7Cb9A9_PP4f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def logloss2(label, y,w=[.9,.1]):\n",
        "    smooth = 1.\n",
        "    label=mx.nd.array(label).as_in_context(mx.gpu(0))\n",
        "    y=mx.nd.array(y).as_in_context(mx.gpu(0))\n",
        "    eps=1e-12\n",
        "    return mx.nd.mean(-(w[0]*label*mx.nd.log(y+eps)+w[1]*(1-label)*mx.nd.log(1-y+eps)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aVZdy14Zc8V2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ===============Evaluation metric(s)================= \n",
        "eval_metrics_1 =  mx.metric.CustomMetric(feval=logloss2)\n",
        "eval_metrics_2 = mx.metric.CustomMetric(feval=nn.dice_coef2)\n",
        "metric= mx.metric.CompositeEvalMetric()\n",
        "for child_metric in [eval_metrics_1, eval_metrics_2]:\n",
        "  metric.add(child_metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "g9Lb-RuGj3Uc"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pt98E9Faj3Uf",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mTiJEEydj3Uy",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if load_model:\n",
        "    network, arg_params, aux_params = mx.model.load_checkpoint(model_path1+prefix1 , model_epoch)\n",
        "\n",
        "    # Binding\n",
        "    exe = network.simple_bind(ctx=mx.gpu(0), **input_shapes)\n",
        "\n",
        "\n",
        "    exe.copy_params_from(arg_params, aux_params)\n",
        "    \n",
        "    # get handle to input arrays\n",
        "    arg_arrays = dict(zip(network.list_arguments(), exe.arg_arrays))\n",
        "    data = arg_arrays[train_iter.provide_data[0][0]]\n",
        "    label = arg_arrays[train_iter.provide_label[0][0]]\n",
        "else:\n",
        "\n",
        "    network = nn.get_net_319()\n",
        "    init = mx.init.Normal(0.01) #note biases and gamma/beta are not affected\n",
        "\n",
        "    # Binding\n",
        "    exe = network.simple_bind(ctx=mx.gpu(), **input_shapes)\n",
        "    # get handle to input arrays\n",
        "    arg_arrays = dict(zip(network.list_arguments(), exe.arg_arrays))\n",
        "    data = arg_arrays[train_iter.provide_data[0][0]]\n",
        "    label = arg_arrays[train_iter.provide_label[0][0]]\n",
        "    for name, arr in arg_arrays.items():\n",
        "        if name not in input_shapes:\n",
        "            init(name, arr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aiWYX4iBG4ZE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  epoch=0\n",
        "  arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
        "  aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
        "  mx.model.save_checkpoint(model_path2+prefix2, epoch, network, arg, aux)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "p36aWzqzbH75"
      },
      "cell_type": "markdown",
      "source": [
        "# Nodule Segmentation: Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_VAcRTIBj3VB"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "aw1eUaNVj3VJ"
      },
      "cell_type": "markdown",
      "source": [
        "### Find  learning rate"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "17MM3ZvwYbBV",
        "outputId": "4f479c3a-86a1-4f0f-fdb0-b62f9cf5b65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "find_learning_rate = True\n",
        "b=.1\n",
        "a=.01\n",
        "\n",
        "nb=train_iter.num_data//train_iter.batch_size\n",
        "\n",
        "if find_learning_rate:\n",
        "\n",
        "  lrs = []\n",
        "  loss = []\n",
        "  \n",
        "  sched=nn.lr_find(a,nb,end_lr=b)\n",
        "  # We also need to create an optimizer for updating weights\n",
        "  opt = mx.optimizer.SGD(\n",
        "      learning_rate=a,\n",
        "      momentum=0.9,\n",
        "      wd=0.00001,\n",
        "      lr_scheduler=sched)\n",
        "\n",
        "  updater = mx.optimizer.get_updater(opt)\n",
        "  for epoch in range(0,1):\n",
        "\n",
        "      start = time.time()\n",
        "\n",
        "      metric.reset()\n",
        "\n",
        "      train_iter.reset()\n",
        "\n",
        "      valid_iter.reset()\n",
        "\n",
        "      sched.reset()\n",
        "\n",
        "      sched.on_train_begin()\n",
        "\n",
        "\n",
        "      for batch in train_iter:\n",
        "          # Copy data to executor input. Note the [:].\n",
        "          data[:] = batch.data[0]\n",
        "          label[:] = batch.label[0]\n",
        "\n",
        "          # Forward\n",
        "          outputs=exe.forward(is_train=True)\n",
        "          # Backward\n",
        "          exe.backward()\n",
        "\n",
        "          # Update\n",
        "          for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
        "              weight, grad = pair\n",
        "              updater(i, grad, weight)   \n",
        "          #metric.update(batch.label[0], exe.outputs[0])#\n",
        "          metric.update(batch.label[0], exe.outputs[0])\n",
        "\n",
        "          e=metric.get()\n",
        "          e = dict(zip(e[0], e[1]))\n",
        "  \n",
        "          err_train=-e['dice_coef2'].asnumpy()[0]\n",
        "          sched.on_batch_end(err_train)\n",
        "\n",
        "      if epoch % 100== 0:       \n",
        "          #print(\"do_checkpoint\")\n",
        "          arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
        "          aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
        "          #mx.model.save_checkpoint(prefix, epoch, network, arg, aux)\n",
        "\n",
        "\n",
        "      #compute valid loss per epoch    \n",
        "      metric.reset()\n",
        "      for batch in valid_iter:        \n",
        "          data[:] = batch.data[0]       \n",
        "          label[:] = batch.label[0]\n",
        "          # predict\n",
        "          outputs = exe.forward(is_train=False)\n",
        "          metric.update(batch.label[0], exe.outputs[0])\n",
        "      e0=metric.get()\n",
        "      e = dict(zip(e0[0], e0[1]))\n",
        "      err_valid=-e['dice_coef2'].asnumpy()[0]\n",
        "      end = time.time()\n",
        "      print('time:',end-start,'Epoch:',epoch,'trainloss:',err_train,'validloss:',err_valid,'CE',outputs[1].asnumpy())\n",
        "      for x,y in zip(e0[0],e0[1]):\n",
        "        print(x,y[0].asnumpy()[0], end=\", \", flush=True)\n",
        "  lrs.extend(sched.lrs)\n",
        "  loss.extend(sched.losses)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mxnet/recordio.py:370: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  header = header._replace(label=np.fromstring(s, np.float32, header.flag))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time: 136.8477602005005 Epoch: 0 trainloss: -0.680025 validloss: -0.6151931 CE [-0.66701543]\n",
            "logloss2 0.2656961, dice_coef2 0.6151931, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "G8PveIwFyrOs",
        "outputId": "c4162496-082a-440d-c44e-a9270e24e9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(lrs, loss,'*-')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6131afcc88>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFOCAYAAAB9mZ/eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnGHjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1-w5Z85n15Nz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network, arg_params, aux_params = mx.model.load_checkpoint(model_path2+prefix2 ,178)\n",
        "exe.copy_params_from(arg_params, aux_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xKkdAPIdGab",
        "colab_type": "code",
        "outputId": "5aa70223-1830-445a-aeec-b1536d463307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "lrs[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0038461538461538464,\n",
              " 0.007692307692307693,\n",
              " 0.011538461538461539,\n",
              " 0.015384615384615385,\n",
              " 0.019230769230769232,\n",
              " 0.023076923076923078,\n",
              " 0.026923076923076925,\n",
              " 0.03076923076923077,\n",
              " 0.03461538461538462,\n",
              " 0.038461538461538464]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UbwF-vYiEBKJ",
        "outputId": "e8eb92f8-f542-4911-b277-b9513adaf474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "lrs[7]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03076923076923077"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ScwvyY2Hj3WA"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizer Parameters"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QQMspdjFl1eQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if colab:\n",
        "  #logfile = \"errorlogmodel10.csv\"\n",
        "  logfile = model_path2+\"errorlogmodel15.csv\"\n",
        "\n",
        "else:\n",
        "  logfile = model_path2+\"errorlogmodel15.csv\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5B2wpqFMzz-C",
        "outputId": "d4bd255b-d189-49ea-c71b-9b1b38f48b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "exists = os.path.isfile(logfile)\n",
        "exists"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YmQgF9RBteXo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#exists = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3KrV7AO1i62v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "col_names = ['epoch',\n",
        "             'lr',\n",
        "             'loss',\n",
        "             'E1train',\n",
        "             'E1valid',\n",
        "             'E2train',\n",
        "             'E2valid']\n",
        "df = pd.DataFrame(columns=col_names)\n",
        "\n",
        "if not exists:\n",
        "  df.to_csv(logfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eMbv0lVruIIK",
        "outputId": "9ecb6c20-d4d2-434a-d664-bdc9ce314a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(logfile, index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>lr</th>\n",
              "      <th>loss</th>\n",
              "      <th>E1train</th>\n",
              "      <th>E1valid</th>\n",
              "      <th>E2train</th>\n",
              "      <th>E2valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [epoch, lr, loss, E1train, E1valid, E2train, E2valid]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "a8AWu5Ia0euI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import copy\n",
        "#import math\n",
        "\n",
        "\n",
        "def plot_schedule(schedule_fn, iterations=1500):\n",
        "    # Iteration count starting at 1\n",
        "    iterations = [i+1 for i in range(iterations)]\n",
        "    lrs = [schedule_fn(i) for i in iterations]\n",
        "    plt.scatter(iterations, lrs)\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.show()\n",
        "\n",
        "class CosineAnnealingSchedule():\n",
        "    def __init__(self, min_lr, max_lr, cycle_length):\n",
        "        \"\"\"\n",
        "        min_lr: lower bound for learning rate (float)\n",
        "        max_lr: upper bound for learning rate (float)\n",
        "        cycle_length: iterations between start and finish (int)\n",
        "        \"\"\"\n",
        "        self.min_lr = min_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.cycle_length = cycle_length\n",
        "        \n",
        "    def __call__(self, iteration):\n",
        "        if iteration <= self.cycle_length:\n",
        "            unit_cycle = (1 + math.cos(iteration * math.pi / self.cycle_length)) / 2\n",
        "            adjusted_cycle = (unit_cycle * (self.max_lr - self.min_lr)) + self.min_lr\n",
        "            return adjusted_cycle\n",
        "        else:\n",
        "            return self.min_lr\n",
        "          \n",
        "    \n",
        "    \n",
        "class TriangularSchedule():\n",
        "    def __init__(self, min_lr, max_lr, cycle_length, inc_fraction=0.5):     \n",
        "        \"\"\"\n",
        "        min_lr: lower bound for learning rate (float)\n",
        "        max_lr: upper bound for learning rate (float)\n",
        "        cycle_length: iterations between start and finish (int)\n",
        "        inc_fraction: fraction of iterations spent in increasing stage (float)\n",
        "        \"\"\"\n",
        "        self.min_lr = min_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.cycle_length = cycle_length\n",
        "        self.inc_fraction = inc_fraction\n",
        "        \n",
        "    def __call__(self, iteration):\n",
        "        if iteration <= self.cycle_length*self.inc_fraction:\n",
        "            unit_cycle = iteration * 1 / (self.cycle_length * self.inc_fraction)\n",
        "        elif iteration <= self.cycle_length:\n",
        "            unit_cycle = (self.cycle_length - iteration) * 1 / (self.cycle_length * (1 - self.inc_fraction))\n",
        "        else:\n",
        "            unit_cycle = 0\n",
        "        adjusted_cycle = (unit_cycle * (self.max_lr - self.min_lr)) + self.min_lr\n",
        "        return adjusted_cycle\n",
        "\n",
        "class CyclicalSchedule():\n",
        "    def __init__(self, schedule_class, cycle_length, cycle_length_decay=1, cycle_magnitude_decay=1, **kwargs):\n",
        "        \"\"\"\n",
        "        schedule_class: class of schedule, expected to take `cycle_length` argument\n",
        "        cycle_length: iterations used for initial cycle (int)\n",
        "        cycle_length_decay: factor multiplied to cycle_length each cycle (float)\n",
        "        cycle_magnitude_decay: factor multiplied learning rate magnitudes each cycle (float)\n",
        "        kwargs: passed to the schedule_class\n",
        "        \"\"\"\n",
        "        self.schedule_class = schedule_class\n",
        "        self.length = cycle_length\n",
        "        self.length_decay = cycle_length_decay\n",
        "        self.magnitude_decay = cycle_magnitude_decay\n",
        "        self.kwargs = kwargs\n",
        "    \n",
        "    def __call__(self, iteration):\n",
        "        cycle_idx = 0\n",
        "        cycle_length = self.length\n",
        "        idx = self.length\n",
        "        while idx <= iteration:\n",
        "            cycle_length = math.ceil(cycle_length * self.length_decay)\n",
        "            cycle_idx += 1\n",
        "            idx += cycle_length\n",
        "        cycle_offset = iteration - idx + cycle_length\n",
        "        \n",
        "        schedule = self.schedule_class(cycle_length=cycle_length, **self.kwargs)\n",
        "        return schedule(cycle_offset) * self.magnitude_decay**cycle_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HrdKZPyR6acE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 378\n",
        "lr =.012#.2#.2#0.075#.01#.3#.02#.15#.34#.2#.01#.002"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cn4Toviupm6l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CZR4pWdZ0J7V",
        "outputId": "43834ca2-1be0-41dc-97e2-33d941230c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "schedule = CyclicalSchedule(TriangularSchedule, min_lr=lr/5, max_lr=lr,\n",
        "                            cycle_length=10, cycle_length_decay=1, cycle_magnitude_decay=1)\n",
        "plot_schedule(schedule,iterations=26)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFZCAYAAADuEZdYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kV6h_vWZ-63B",
        "colab_type": "code",
        "outputId": "49138f37-ea47-4ed0-bf7b-2d7c2e1e3bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_iter.num_data/100,train_iter.num_data/34"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26.29, 77.32352941176471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I2EXT_W9Wz3y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m1=.85\n",
        "m2=.95\n",
        "\n",
        "# We also need to create an optimizer for updating weights\n",
        "# ===============Optimizer=================                        \n",
        "opt = mx.optimizer.SGD(\n",
        "    learning_rate=lr,momentum=m1,wd=0.00001)\n",
        "\n",
        "updater = mx.optimizer.get_updater(opt)\n",
        "\n",
        "updater.optimizer.lr_scheduler=schedule"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4bfQwTtyZwvF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4kTljGINPUpz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    now\n",
        "except:\n",
        "  now=178\n",
        "  err_validold = -.68"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c7EogiUVnm1X",
        "outputId": "51c1436e-ed1d-4240-d92b-023828778b96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6063
        }
      },
      "cell_type": "code",
      "source": [
        "lrs=[]\n",
        "ms=[]\n",
        "lrold=-1\n",
        "epoch_r  =now\n",
        "epoch_r\n",
        "Es_train=[]\n",
        "Es_valid=[]\n",
        "for epoch in range(epoch_r+1,epoch_r+epochs):\n",
        "  \n",
        "    start = time.time()\n",
        "    \n",
        "    ELASTIC_INDICES = None\n",
        "    \n",
        "    metric.reset()\n",
        "\n",
        "    train_iter.reset()\n",
        "    \n",
        "    valid_iter.reset()\n",
        "    \n",
        "\n",
        "    for batch in train_iter:\n",
        "        # Copy data to executor input. Note the [:].\n",
        "        data[:] = batch.data[0]\n",
        "        label[:] = batch.label[0]\n",
        "\n",
        "        # Forward\n",
        "        outputs=exe.forward(is_train=True)\n",
        "        Es_train.append(outputs[1].asnumpy()[0])\n",
        "        # Backward\n",
        "        exe.backward()\n",
        "\n",
        "        # Update\n",
        "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
        "            weight, grad = pair\n",
        "            updater(i, grad, weight)   \n",
        "        metric.update(batch.label[0], exe.outputs[0])#metric.update(label,p)\n",
        "        if (opt.learning_rate-lrold)<0:\n",
        "          opt.momentum=m2\n",
        "          lrold = opt.learning_rate\n",
        "        else: \n",
        "          opt.momentum=m1\n",
        "          lrold=opt.learning_rate\n",
        "        lrs.append(opt.learning_rate)\n",
        "        ms.append(opt.momentum)\n",
        "    e=metric.get()\n",
        "    ed={}\n",
        "    e_key,e_val = e\n",
        "    for k,v in zip(e_key,e_val):\n",
        "      ed[k]=v.asnumpy()[0]\n",
        "    err_train=-ed['dice_coef2']\n",
        "    err_train2=ed['logloss2']\n",
        "    \n",
        "    loss = outputs[1].asnumpy()[0] \n",
        "    \n",
        "    if epoch % 1== 0:       \n",
        "        #print(\"do_checkpoint\")\n",
        "        arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
        "        aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
        "        mx.model.save_checkpoint(model_path2+prefix2, epoch, network, arg, aux)\n",
        "        \n",
        "\n",
        "    #compute valid loss per epoch    \n",
        "    metric.reset()\n",
        "    for batch in valid_iter:        \n",
        "        data[:] = batch.data[0]       \n",
        "        label[:] = batch.label[0]\n",
        "        # predict\n",
        "        outputs = exe.forward(is_train=False)\n",
        "        Es_valid.append(outputs[1].asnumpy()[0])\n",
        "        metric.update(batch.label[0], exe.outputs[0])\n",
        "    e=metric.get()\n",
        "    ed={}\n",
        "    e_key,e_val = e\n",
        "    for k,v in zip(e_key,e_val):\n",
        "      ed[k]=v.asnumpy()[0]\n",
        "    err_valid=-ed['dice_coef2']\n",
        "    err_valid2=ed['logloss2']\n",
        "    \n",
        "    if err_valid<err_validold:       \n",
        "        #print(\"do_checkpoint\")\n",
        "        arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
        "        aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
        "        mx.model.save_checkpoint(model_path2+prefix2+'bst', epoch, network, arg, aux)\n",
        "        err_validold = err_valid\n",
        "    \n",
        "    \n",
        "    end = time.time()\n",
        "    print('time:',end-start,'Epoch:',epoch,\"/\",epochs+now,\"loss\",loss,'trainloss:',err_train,'validloss:',err_valid,'trainloss2:',err_train2,'validloss2:',err_valid2)\n",
        "    myCsvRow = [(epoch,lr,loss,err_train,err_valid,err_train2,err_valid2)]\n",
        "    df = pd.DataFrame.from_records(myCsvRow,columns = col_names)\n",
        "    df.to_csv(logfile, mode='a', header=False)\n",
        "now=epoch\n",
        "mx.model.save_checkpoint(model_path2+prefix2, epoch, network, arg, aux)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mxnet/recordio.py:370: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  header = header._replace(label=np.fromstring(s, np.float32, header.flag))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time: 119.44086766242981 Epoch: 179 / 556 loss -0.8315225 trainloss: -0.68207234 validloss: -0.61624706 trainloss2: 0.1319377 validloss2: 0.26447088\n",
            "time: 119.03286051750183 Epoch: 180 / 556 loss -0.80949336 trainloss: -0.6829003 validloss: -0.60954267 trainloss2: 0.13096632 validloss2: 0.28300092\n",
            "time: 118.99733400344849 Epoch: 181 / 556 loss -0.84059644 trainloss: -0.68340665 validloss: -0.6066986 trainloss2: 0.13325335 validloss2: 0.27792042\n",
            "time: 119.04269695281982 Epoch: 182 / 556 loss -0.7811875 trainloss: -0.6762508 validloss: -0.6141632 trainloss2: 0.13272086 validloss2: 0.26646692\n",
            "time: 119.01160430908203 Epoch: 183 / 556 loss -0.80104136 trainloss: -0.68315536 validloss: -0.6105102 trainloss2: 0.13080084 validloss2: 0.27324915\n",
            "time: 119.24834370613098 Epoch: 184 / 556 loss -0.79269445 trainloss: -0.6813851 validloss: -0.59891516 trainloss2: 0.13149115 validloss2: 0.2815691\n",
            "time: 119.23680663108826 Epoch: 185 / 556 loss -0.8250178 trainloss: -0.67935896 validloss: -0.6041806 trainloss2: 0.13213441 validloss2: 0.28449827\n",
            "time: 118.9846568107605 Epoch: 186 / 556 loss -0.81072426 trainloss: -0.6762606 validloss: -0.6117581 trainloss2: 0.13328351 validloss2: 0.27058995\n",
            "time: 119.22552680969238 Epoch: 187 / 556 loss -0.79809266 trainloss: -0.6801246 validloss: -0.60928994 trainloss2: 0.13136823 validloss2: 0.2806366\n",
            "time: 119.14923334121704 Epoch: 188 / 556 loss -0.82733154 trainloss: -0.68205094 validloss: -0.61488837 trainloss2: 0.13050959 validloss2: 0.27244237\n",
            "time: 119.10042762756348 Epoch: 189 / 556 loss -0.7938187 trainloss: -0.68288666 validloss: -0.6096552 trainloss2: 0.13198502 validloss2: 0.2755589\n",
            "time: 118.979159116745 Epoch: 190 / 556 loss -0.8184527 trainloss: -0.6848742 validloss: -0.61358005 trainloss2: 0.13045464 validloss2: 0.26867637\n",
            "time: 119.15880274772644 Epoch: 191 / 556 loss -0.80761886 trainloss: -0.6813545 validloss: -0.6092384 trainloss2: 0.1339857 validloss2: 0.27971652\n",
            "time: 119.02202939987183 Epoch: 192 / 556 loss -0.79036725 trainloss: -0.67883754 validloss: -0.6147225 trainloss2: 0.13233455 validloss2: 0.27047384\n",
            "time: 118.85135293006897 Epoch: 193 / 556 loss -0.83523834 trainloss: -0.68241453 validloss: -0.6072075 trainloss2: 0.13404466 validloss2: 0.2799324\n",
            "time: 119.22627663612366 Epoch: 194 / 556 loss -0.8105408 trainloss: -0.68292046 validloss: -0.61344504 trainloss2: 0.1306944 validloss2: 0.27359062\n",
            "time: 118.95248794555664 Epoch: 195 / 556 loss -0.8197877 trainloss: -0.6817445 validloss: -0.6073889 trainloss2: 0.13302264 validloss2: 0.28178608\n",
            "time: 118.92096424102783 Epoch: 196 / 556 loss -0.8214132 trainloss: -0.68104994 validloss: -0.6126004 trainloss2: 0.13153803 validloss2: 0.27634045\n",
            "time: 119.17357206344604 Epoch: 197 / 556 loss -0.81509674 trainloss: -0.68061435 validloss: -0.60763454 trainloss2: 0.12938327 validloss2: 0.27737403\n",
            "time: 119.31950640678406 Epoch: 198 / 556 loss -0.81332195 trainloss: -0.68118197 validloss: -0.60686815 trainloss2: 0.13283749 validloss2: 0.27611628\n",
            "time: 119.1906476020813 Epoch: 199 / 556 loss -0.80806077 trainloss: -0.6831674 validloss: -0.6192887 trainloss2: 0.13317758 validloss2: 0.27733138\n",
            "time: 119.23076367378235 Epoch: 200 / 556 loss -0.8398658 trainloss: -0.68273264 validloss: -0.6103239 trainloss2: 0.13040517 validloss2: 0.27949807\n",
            "time: 119.11968183517456 Epoch: 201 / 556 loss -0.8174326 trainloss: -0.6833561 validloss: -0.6175293 trainloss2: 0.13175443 validloss2: 0.27384174\n",
            "time: 119.26162958145142 Epoch: 202 / 556 loss -0.80628324 trainloss: -0.6799138 validloss: -0.613624 trainloss2: 0.13389789 validloss2: 0.28190827\n",
            "time: 119.11678910255432 Epoch: 203 / 556 loss -0.80144215 trainloss: -0.6809492 validloss: -0.60710263 trainloss2: 0.13162124 validloss2: 0.28361958\n",
            "time: 119.23143196105957 Epoch: 204 / 556 loss -0.82850504 trainloss: -0.68137187 validloss: -0.6100511 trainloss2: 0.13257602 validloss2: 0.2721441\n",
            "time: 119.13115620613098 Epoch: 205 / 556 loss -0.7962269 trainloss: -0.68129593 validloss: -0.61314905 trainloss2: 0.13188037 validloss2: 0.26898634\n",
            "time: 119.19083666801453 Epoch: 206 / 556 loss -0.79846126 trainloss: -0.680748 validloss: -0.60928476 trainloss2: 0.13175729 validloss2: 0.27910012\n",
            "time: 119.35413932800293 Epoch: 207 / 556 loss -0.8235405 trainloss: -0.6792898 validloss: -0.6109217 trainloss2: 0.1332868 validloss2: 0.2768418\n",
            "time: 119.23627018928528 Epoch: 208 / 556 loss -0.8498068 trainloss: -0.6802924 validloss: -0.61261827 trainloss2: 0.13429491 validloss2: 0.28275478\n",
            "time: 119.18047904968262 Epoch: 209 / 556 loss -0.7894262 trainloss: -0.68083596 validloss: -0.6045142 trainloss2: 0.13214406 validloss2: 0.27851066\n",
            "time: 119.35941505432129 Epoch: 210 / 556 loss -0.82175744 trainloss: -0.6822511 validloss: -0.6115841 trainloss2: 0.13142575 validloss2: 0.27013883\n",
            "time: 119.40332436561584 Epoch: 211 / 556 loss -0.8228153 trainloss: -0.68055844 validloss: -0.6134208 trainloss2: 0.13120812 validloss2: 0.27391797\n",
            "time: 119.059898853302 Epoch: 212 / 556 loss -0.8150223 trainloss: -0.6835454 validloss: -0.61120236 trainloss2: 0.12964134 validloss2: 0.27309296\n",
            "time: 118.9691174030304 Epoch: 213 / 556 loss -0.7870464 trainloss: -0.68328464 validloss: -0.61384195 trainloss2: 0.1338606 validloss2: 0.27184972\n",
            "time: 119.18315839767456 Epoch: 214 / 556 loss -0.8250857 trainloss: -0.6802071 validloss: -0.6089855 trainloss2: 0.13205063 validloss2: 0.27323812\n",
            "time: 119.20731925964355 Epoch: 215 / 556 loss -0.830404 trainloss: -0.6780297 validloss: -0.6171716 trainloss2: 0.1329213 validloss2: 0.26849592\n",
            "time: 119.27801156044006 Epoch: 216 / 556 loss -0.8173554 trainloss: -0.6851666 validloss: -0.60644996 trainloss2: 0.13051686 validloss2: 0.279503\n",
            "time: 119.35736227035522 Epoch: 217 / 556 loss -0.78635734 trainloss: -0.6797798 validloss: -0.61708605 trainloss2: 0.1354939 validloss2: 0.27448192\n",
            "time: 119.25499296188354 Epoch: 218 / 556 loss -0.79230726 trainloss: -0.68260324 validloss: -0.60654616 trainloss2: 0.13211147 validloss2: 0.2748476\n",
            "time: 119.47505068778992 Epoch: 219 / 556 loss -0.8217905 trainloss: -0.6824463 validloss: -0.6112016 trainloss2: 0.13134468 validloss2: 0.27785105\n",
            "time: 119.18400430679321 Epoch: 220 / 556 loss -0.81633705 trainloss: -0.6843604 validloss: -0.60763747 trainloss2: 0.13077846 validloss2: 0.27383602\n",
            "time: 119.1681764125824 Epoch: 221 / 556 loss -0.8268448 trainloss: -0.6839046 validloss: -0.6098021 trainloss2: 0.13135237 validloss2: 0.2721196\n",
            "time: 119.21119284629822 Epoch: 222 / 556 loss -0.8425953 trainloss: -0.6810689 validloss: -0.60784864 trainloss2: 0.13182785 validloss2: 0.27985966\n",
            "time: 119.21595406532288 Epoch: 223 / 556 loss -0.81137 trainloss: -0.6844482 validloss: -0.6088172 trainloss2: 0.13189429 validloss2: 0.27853134\n",
            "time: 119.19085311889648 Epoch: 224 / 556 loss -0.80475056 trainloss: -0.6825872 validloss: -0.6111981 trainloss2: 0.13336968 validloss2: 0.26997435\n",
            "time: 119.0775465965271 Epoch: 225 / 556 loss -0.8127782 trainloss: -0.6792802 validloss: -0.60761535 trainloss2: 0.13088462 validloss2: 0.27665108\n",
            "time: 119.24673628807068 Epoch: 226 / 556 loss -0.82952595 trainloss: -0.68054277 validloss: -0.61293507 trainloss2: 0.13092966 validloss2: 0.27587196\n",
            "time: 119.1756546497345 Epoch: 227 / 556 loss -0.8114463 trainloss: -0.68397754 validloss: -0.6112954 trainloss2: 0.1325269 validloss2: 0.2803689\n",
            "time: 119.14726233482361 Epoch: 228 / 556 loss -0.8085414 trainloss: -0.680878 validloss: -0.6129344 trainloss2: 0.13133049 validloss2: 0.27914393\n",
            "time: 119.21523594856262 Epoch: 229 / 556 loss -0.8036371 trainloss: -0.6861266 validloss: -0.61134195 trainloss2: 0.1330054 validloss2: 0.27544728\n",
            "time: 119.33205556869507 Epoch: 230 / 556 loss -0.8340408 trainloss: -0.68227714 validloss: -0.6086485 trainloss2: 0.13055153 validloss2: 0.27868193\n",
            "time: 119.14070177078247 Epoch: 231 / 556 loss -0.7915602 trainloss: -0.6800325 validloss: -0.6136366 trainloss2: 0.13164113 validloss2: 0.27286887\n",
            "time: 119.19806337356567 Epoch: 232 / 556 loss -0.8035848 trainloss: -0.68193454 validloss: -0.6063463 trainloss2: 0.1290344 validloss2: 0.2842594\n",
            "time: 119.16879677772522 Epoch: 233 / 556 loss -0.8277533 trainloss: -0.6818951 validloss: -0.6107617 trainloss2: 0.13281617 validloss2: 0.27398753\n",
            "time: 119.17291021347046 Epoch: 234 / 556 loss -0.8163667 trainloss: -0.67984045 validloss: -0.60889417 trainloss2: 0.13073644 validloss2: 0.27813247\n",
            "time: 119.16737627983093 Epoch: 235 / 556 loss -0.8042123 trainloss: -0.68031806 validloss: -0.61166364 trainloss2: 0.1322054 validloss2: 0.26811853\n",
            "time: 119.20279908180237 Epoch: 236 / 556 loss -0.8047775 trainloss: -0.68342936 validloss: -0.6126323 trainloss2: 0.13092923 validloss2: 0.28177866\n",
            "time: 119.19832563400269 Epoch: 237 / 556 loss -0.8117955 trainloss: -0.6811248 validloss: -0.61505365 trainloss2: 0.13189113 validloss2: 0.27146673\n",
            "time: 119.15030765533447 Epoch: 238 / 556 loss -0.7915271 trainloss: -0.6794081 validloss: -0.6142368 trainloss2: 0.13157822 validloss2: 0.2716411\n",
            "time: 119.2257251739502 Epoch: 239 / 556 loss -0.7943644 trainloss: -0.68350565 validloss: -0.6028816 trainloss2: 0.1297683 validloss2: 0.27464604\n",
            "time: 119.67685675621033 Epoch: 240 / 556 loss -0.797045 trainloss: -0.6841584 validloss: -0.61017925 trainloss2: 0.134011 validloss2: 0.2741942\n",
            "time: 119.69905638694763 Epoch: 241 / 556 loss -0.83471847 trainloss: -0.6826332 validloss: -0.6067556 trainloss2: 0.13302498 validloss2: 0.27826047\n",
            "time: 119.72299766540527 Epoch: 242 / 556 loss -0.8049832 trainloss: -0.68633866 validloss: -0.6101756 trainloss2: 0.12872738 validloss2: 0.27235278\n",
            "time: 119.65120315551758 Epoch: 243 / 556 loss -0.8096027 trainloss: -0.68061507 validloss: -0.61705476 trainloss2: 0.13078488 validloss2: 0.27180433\n",
            "time: 119.84028482437134 Epoch: 244 / 556 loss -0.81017977 trainloss: -0.67958003 validloss: -0.60435987 trainloss2: 0.13183175 validloss2: 0.27888992\n",
            "time: 119.67940092086792 Epoch: 245 / 556 loss -0.81562763 trainloss: -0.6808753 validloss: -0.6125428 trainloss2: 0.13246918 validloss2: 0.28120178\n",
            "time: 119.72973227500916 Epoch: 246 / 556 loss -0.8015362 trainloss: -0.6836301 validloss: -0.6129857 trainloss2: 0.13055103 validloss2: 0.2792993\n",
            "time: 119.74983954429626 Epoch: 247 / 556 loss -0.81424147 trainloss: -0.6828904 validloss: -0.61667293 trainloss2: 0.1320558 validloss2: 0.27127543\n",
            "time: 119.83660221099854 Epoch: 248 / 556 loss -0.832665 trainloss: -0.68124753 validloss: -0.6094881 trainloss2: 0.13433641 validloss2: 0.28021157\n",
            "time: 119.83857464790344 Epoch: 249 / 556 loss -0.8191147 trainloss: -0.68234974 validloss: -0.6043661 trainloss2: 0.1304162 validloss2: 0.28428414\n",
            "time: 119.70426201820374 Epoch: 250 / 556 loss -0.80769974 trainloss: -0.6829304 validloss: -0.6072605 trainloss2: 0.13035102 validloss2: 0.28191388\n",
            "time: 119.59328269958496 Epoch: 251 / 556 loss -0.8561978 trainloss: -0.67862517 validloss: -0.6140812 trainloss2: 0.1347269 validloss2: 0.2736712\n",
            "time: 119.79602813720703 Epoch: 252 / 556 loss -0.8102744 trainloss: -0.6818922 validloss: -0.6102348 trainloss2: 0.12863031 validloss2: 0.27678046\n",
            "time: 119.58529710769653 Epoch: 253 / 556 loss -0.83785677 trainloss: -0.68012226 validloss: -0.60818654 trainloss2: 0.13209487 validloss2: 0.27776045\n",
            "time: 119.61139678955078 Epoch: 254 / 556 loss -0.80622375 trainloss: -0.68403083 validloss: -0.6074146 trainloss2: 0.13133264 validloss2: 0.2871157\n",
            "time: 119.70260286331177 Epoch: 255 / 556 loss -0.80465245 trainloss: -0.6829949 validloss: -0.61009604 trainloss2: 0.13094227 validloss2: 0.27394524\n",
            "time: 119.67811441421509 Epoch: 256 / 556 loss -0.78365433 trainloss: -0.68177724 validloss: -0.6095839 trainloss2: 0.13265789 validloss2: 0.28503865\n",
            "time: 119.53338623046875 Epoch: 257 / 556 loss -0.80182123 trainloss: -0.68092644 validloss: -0.61119944 trainloss2: 0.13357978 validloss2: 0.27385825\n",
            "time: 119.5698139667511 Epoch: 258 / 556 loss -0.82855636 trainloss: -0.6816218 validloss: -0.6133519 trainloss2: 0.12878172 validloss2: 0.27673027\n",
            "time: 119.69657897949219 Epoch: 259 / 556 loss -0.7982446 trainloss: -0.68680316 validloss: -0.61141235 trainloss2: 0.1297965 validloss2: 0.27482456\n",
            "time: 119.64534568786621 Epoch: 260 / 556 loss -0.8171148 trainloss: -0.6833183 validloss: -0.6083963 trainloss2: 0.13237199 validloss2: 0.2774701\n",
            "time: 119.58107995986938 Epoch: 261 / 556 loss -0.8169825 trainloss: -0.6815213 validloss: -0.6121612 trainloss2: 0.1330459 validloss2: 0.27656627\n",
            "time: 119.61801028251648 Epoch: 262 / 556 loss -0.82126284 trainloss: -0.6840402 validloss: -0.61322683 trainloss2: 0.12945877 validloss2: 0.28209928\n",
            "time: 119.74089860916138 Epoch: 263 / 556 loss -0.83940905 trainloss: -0.6840229 validloss: -0.6070929 trainloss2: 0.1323221 validloss2: 0.2827878\n",
            "time: 119.6655924320221 Epoch: 264 / 556 loss -0.8172441 trainloss: -0.6822859 validloss: -0.61458045 trainloss2: 0.133169 validloss2: 0.2751068\n",
            "time: 119.41293120384216 Epoch: 265 / 556 loss -0.8448097 trainloss: -0.68460935 validloss: -0.6097116 trainloss2: 0.12989478 validloss2: 0.28095448\n",
            "time: 119.16867232322693 Epoch: 266 / 556 loss -0.8213421 trainloss: -0.6822246 validloss: -0.6070405 trainloss2: 0.13249825 validloss2: 0.27924338\n",
            "time: 119.18151354789734 Epoch: 267 / 556 loss -0.8058192 trainloss: -0.6829459 validloss: -0.6187635 trainloss2: 0.13266489 validloss2: 0.27852055\n",
            "time: 119.15407872200012 Epoch: 268 / 556 loss -0.804024 trainloss: -0.6841924 validloss: -0.6108866 trainloss2: 0.13227731 validloss2: 0.2769543\n",
            "time: 119.19701814651489 Epoch: 269 / 556 loss -0.8303111 trainloss: -0.6817601 validloss: -0.60664374 trainloss2: 0.13100082 validloss2: 0.28791404\n",
            "time: 119.1271710395813 Epoch: 270 / 556 loss -0.83466345 trainloss: -0.6866785 validloss: -0.61399496 trainloss2: 0.13244146 validloss2: 0.27949294\n",
            "time: 119.15987086296082 Epoch: 271 / 556 loss -0.7991073 trainloss: -0.68441737 validloss: -0.6131628 trainloss2: 0.1318445 validloss2: 0.27951896\n",
            "time: 119.24319458007812 Epoch: 272 / 556 loss -0.7992501 trainloss: -0.6782781 validloss: -0.6184467 trainloss2: 0.13299437 validloss2: 0.27166227\n",
            "time: 119.13651013374329 Epoch: 273 / 556 loss -0.81957304 trainloss: -0.68371826 validloss: -0.61034775 trainloss2: 0.1324057 validloss2: 0.27896598\n",
            "time: 119.13202619552612 Epoch: 274 / 556 loss -0.79690844 trainloss: -0.683238 validloss: -0.61152506 trainloss2: 0.13022403 validloss2: 0.2748193\n",
            "time: 119.1307442188263 Epoch: 275 / 556 loss -0.8148615 trainloss: -0.68278646 validloss: -0.613941 trainloss2: 0.1316123 validloss2: 0.2800836\n",
            "time: 119.16453456878662 Epoch: 276 / 556 loss -0.82368296 trainloss: -0.6840074 validloss: -0.6089143 trainloss2: 0.13519125 validloss2: 0.27847826\n",
            "time: 119.22444462776184 Epoch: 277 / 556 loss -0.833122 trainloss: -0.68517596 validloss: -0.6116373 trainloss2: 0.13073765 validloss2: 0.279977\n",
            "time: 119.15974259376526 Epoch: 278 / 556 loss -0.80393094 trainloss: -0.68143487 validloss: -0.6042097 trainloss2: 0.13203526 validloss2: 0.27718163\n",
            "time: 119.25938677787781 Epoch: 279 / 556 loss -0.80529803 trainloss: -0.68379647 validloss: -0.60785043 trainloss2: 0.12936461 validloss2: 0.28419048\n",
            "time: 119.09706616401672 Epoch: 280 / 556 loss -0.791728 trainloss: -0.68097997 validloss: -0.6119631 trainloss2: 0.13321368 validloss2: 0.28216803\n",
            "time: 119.1544759273529 Epoch: 281 / 556 loss -0.8233947 trainloss: -0.682499 validloss: -0.612085 trainloss2: 0.12875585 validloss2: 0.27708012\n",
            "time: 119.15936732292175 Epoch: 282 / 556 loss -0.80518365 trainloss: -0.6822568 validloss: -0.609937 trainloss2: 0.13533309 validloss2: 0.27879456\n",
            "time: 119.24631381034851 Epoch: 283 / 556 loss -0.83950883 trainloss: -0.6845306 validloss: -0.6073269 trainloss2: 0.13025531 validloss2: 0.28182408\n",
            "time: 119.38407325744629 Epoch: 284 / 556 loss -0.8270105 trainloss: -0.68334347 validloss: -0.61272717 trainloss2: 0.13109352 validloss2: 0.27143383\n",
            "time: 119.24978041648865 Epoch: 285 / 556 loss -0.80315405 trainloss: -0.6847146 validloss: -0.6113797 trainloss2: 0.1323896 validloss2: 0.28306112\n",
            "time: 119.43300652503967 Epoch: 286 / 556 loss -0.8063266 trainloss: -0.68371594 validloss: -0.61296755 trainloss2: 0.13061304 validloss2: 0.2843092\n",
            "time: 119.4111020565033 Epoch: 287 / 556 loss -0.8287584 trainloss: -0.6838559 validloss: -0.6017406 trainloss2: 0.12854448 validloss2: 0.2834666\n",
            "time: 119.59641075134277 Epoch: 288 / 556 loss -0.8148856 trainloss: -0.6835334 validloss: -0.6132664 trainloss2: 0.12996642 validloss2: 0.27848652\n",
            "time: 120.36869072914124 Epoch: 289 / 556 loss -0.8338822 trainloss: -0.68518394 validloss: -0.6094448 trainloss2: 0.13243496 validloss2: 0.28025383\n",
            "time: 120.13616228103638 Epoch: 290 / 556 loss -0.8131915 trainloss: -0.683593 validloss: -0.6118373 trainloss2: 0.1309844 validloss2: 0.27960092\n",
            "time: 120.25285768508911 Epoch: 291 / 556 loss -0.81401086 trainloss: -0.6831066 validloss: -0.6075683 trainloss2: 0.133969 validloss2: 0.28437918\n",
            "time: 120.27895545959473 Epoch: 292 / 556 loss -0.83980817 trainloss: -0.6840088 validloss: -0.6028573 trainloss2: 0.13131459 validloss2: 0.28407237\n",
            "time: 120.05774331092834 Epoch: 293 / 556 loss -0.8176997 trainloss: -0.6814766 validloss: -0.61488783 trainloss2: 0.13303396 validloss2: 0.2786103\n",
            "time: 120.18633341789246 Epoch: 294 / 556 loss -0.8133661 trainloss: -0.68516284 validloss: -0.6106635 trainloss2: 0.13116886 validloss2: 0.2797742\n",
            "time: 120.18647742271423 Epoch: 295 / 556 loss -0.8161306 trainloss: -0.6827031 validloss: -0.6090923 trainloss2: 0.13259077 validloss2: 0.27610385\n",
            "time: 120.0754292011261 Epoch: 296 / 556 loss -0.8064154 trainloss: -0.68592584 validloss: -0.60591185 trainloss2: 0.13131192 validloss2: 0.28251407\n",
            "time: 120.13784694671631 Epoch: 297 / 556 loss -0.8184951 trainloss: -0.6806094 validloss: -0.61450213 trainloss2: 0.12860829 validloss2: 0.27330208\n",
            "time: 120.05973982810974 Epoch: 298 / 556 loss -0.8139323 trainloss: -0.68247133 validloss: -0.6067315 trainloss2: 0.13340986 validloss2: 0.2827614\n",
            "time: 119.99149513244629 Epoch: 299 / 556 loss -0.829444 trainloss: -0.6815333 validloss: -0.6087549 trainloss2: 0.13234568 validloss2: 0.27534354\n",
            "time: 120.12979698181152 Epoch: 300 / 556 loss -0.81021947 trainloss: -0.684727 validloss: -0.6210284 trainloss2: 0.13440125 validloss2: 0.27045587\n",
            "time: 119.9965934753418 Epoch: 301 / 556 loss -0.7986348 trainloss: -0.68388563 validloss: -0.6075857 trainloss2: 0.130449 validloss2: 0.27353847\n",
            "time: 120.14308404922485 Epoch: 302 / 556 loss -0.8195267 trainloss: -0.6814844 validloss: -0.60898066 trainloss2: 0.12857096 validloss2: 0.27707103\n",
            "time: 120.19171333312988 Epoch: 303 / 556 loss -0.8108175 trainloss: -0.6816382 validloss: -0.6160504 trainloss2: 0.13422918 validloss2: 0.2746444\n",
            "time: 120.22370290756226 Epoch: 304 / 556 loss -0.80487996 trainloss: -0.6820796 validloss: -0.61454344 trainloss2: 0.12976338 validloss2: 0.27648503\n",
            "time: 120.13851523399353 Epoch: 305 / 556 loss -0.7953229 trainloss: -0.6842051 validloss: -0.60490984 trainloss2: 0.13306595 validloss2: 0.27771863\n",
            "time: 120.18717193603516 Epoch: 306 / 556 loss -0.8172252 trainloss: -0.68203086 validloss: -0.6102456 trainloss2: 0.13286223 validloss2: 0.2785193\n",
            "time: 120.13967752456665 Epoch: 307 / 556 loss -0.84395087 trainloss: -0.6850744 validloss: -0.6061785 trainloss2: 0.12987638 validloss2: 0.2877502\n",
            "time: 120.15279984474182 Epoch: 308 / 556 loss -0.80552524 trainloss: -0.6824603 validloss: -0.60882086 trainloss2: 0.1318219 validloss2: 0.27781025\n",
            "time: 120.15037488937378 Epoch: 309 / 556 loss -0.825074 trainloss: -0.6830862 validloss: -0.6018959 trainloss2: 0.12898968 validloss2: 0.2867406\n",
            "time: 119.92947125434875 Epoch: 310 / 556 loss -0.79387057 trainloss: -0.68281716 validloss: -0.61801904 trainloss2: 0.13083416 validloss2: 0.2707592\n",
            "time: 120.1160056591034 Epoch: 311 / 556 loss -0.82206345 trainloss: -0.6870127 validloss: -0.60198545 trainloss2: 0.13093673 validloss2: 0.2844691\n",
            "time: 120.08685970306396 Epoch: 312 / 556 loss -0.77487165 trainloss: -0.6848152 validloss: -0.6039304 trainloss2: 0.12915593 validloss2: 0.2805217\n",
            "time: 120.2129077911377 Epoch: 313 / 556 loss -0.8288958 trainloss: -0.68602186 validloss: -0.61196554 trainloss2: 0.13127284 validloss2: 0.27522027\n",
            "time: 120.0280818939209 Epoch: 314 / 556 loss -0.829276 trainloss: -0.684927 validloss: -0.61104375 trainloss2: 0.13126913 validloss2: 0.28306004\n",
            "time: 120.18425011634827 Epoch: 315 / 556 loss -0.83913344 trainloss: -0.68339455 validloss: -0.6091495 trainloss2: 0.13015993 validloss2: 0.28040132\n",
            "time: 120.21900057792664 Epoch: 316 / 556 loss -0.8117729 trainloss: -0.68585414 validloss: -0.6094974 trainloss2: 0.13101222 validloss2: 0.280086\n",
            "time: 120.09859704971313 Epoch: 317 / 556 loss -0.7953663 trainloss: -0.68420976 validloss: -0.6078498 trainloss2: 0.131314 validloss2: 0.2754467\n",
            "time: 120.13600087165833 Epoch: 318 / 556 loss -0.8386264 trainloss: -0.6847375 validloss: -0.60531855 trainloss2: 0.13146493 validloss2: 0.28768197\n",
            "time: 120.01882886886597 Epoch: 319 / 556 loss -0.80715233 trainloss: -0.6832804 validloss: -0.61156386 trainloss2: 0.12921235 validloss2: 0.27715838\n",
            "time: 120.17966198921204 Epoch: 320 / 556 loss -0.8343774 trainloss: -0.6871646 validloss: -0.6113591 trainloss2: 0.12850903 validloss2: 0.27665234\n",
            "time: 119.95817637443542 Epoch: 321 / 556 loss -0.82015455 trainloss: -0.6814972 validloss: -0.61194676 trainloss2: 0.130474 validloss2: 0.27535006\n",
            "time: 119.92936587333679 Epoch: 322 / 556 loss -0.7915581 trainloss: -0.6793574 validloss: -0.60815513 trainloss2: 0.13046274 validloss2: 0.27640104\n",
            "time: 119.95184016227722 Epoch: 323 / 556 loss -0.8416647 trainloss: -0.6869939 validloss: -0.60819906 trainloss2: 0.1336597 validloss2: 0.28365445\n",
            "time: 119.92929768562317 Epoch: 324 / 556 loss -0.8440705 trainloss: -0.68525815 validloss: -0.6069198 trainloss2: 0.13277446 validloss2: 0.28302497\n",
            "time: 120.11814665794373 Epoch: 325 / 556 loss -0.83011085 trainloss: -0.6844541 validloss: -0.6080544 trainloss2: 0.12912238 validloss2: 0.28243667\n",
            "time: 120.11750340461731 Epoch: 326 / 556 loss -0.79469705 trainloss: -0.68084425 validloss: -0.60890585 trainloss2: 0.12859808 validloss2: 0.27577612\n",
            "time: 120.1389548778534 Epoch: 327 / 556 loss -0.8225548 trainloss: -0.6857021 validloss: -0.60797286 trainloss2: 0.1347932 validloss2: 0.27866864\n",
            "time: 119.9980046749115 Epoch: 328 / 556 loss -0.8114729 trainloss: -0.68197656 validloss: -0.60900337 trainloss2: 0.13170975 validloss2: 0.27974853\n",
            "time: 120.18112421035767 Epoch: 329 / 556 loss -0.8001444 trainloss: -0.6809301 validloss: -0.6103684 trainloss2: 0.13013685 validloss2: 0.28035507\n",
            "time: 120.1005346775055 Epoch: 330 / 556 loss -0.8366246 trainloss: -0.68523234 validloss: -0.6054034 trainloss2: 0.1302294 validloss2: 0.27256095\n",
            "time: 120.15941548347473 Epoch: 331 / 556 loss -0.82739156 trainloss: -0.6853186 validloss: -0.6086224 trainloss2: 0.13124043 validloss2: 0.28061113\n",
            "time: 119.90674901008606 Epoch: 332 / 556 loss -0.81949705 trainloss: -0.68101555 validloss: -0.6107451 trainloss2: 0.13353056 validloss2: 0.2754977\n",
            "time: 120.10823798179626 Epoch: 333 / 556 loss -0.8250454 trainloss: -0.68450695 validloss: -0.6150509 trainloss2: 0.1308623 validloss2: 0.27526444\n",
            "time: 120.05378913879395 Epoch: 334 / 556 loss -0.8194546 trainloss: -0.68588394 validloss: -0.6048531 trainloss2: 0.13083902 validloss2: 0.2768299\n",
            "time: 120.05963635444641 Epoch: 335 / 556 loss -0.81191045 trainloss: -0.68312186 validloss: -0.6112325 trainloss2: 0.13207726 validloss2: 0.2845935\n",
            "time: 120.09984564781189 Epoch: 336 / 556 loss -0.8043882 trainloss: -0.68326604 validloss: -0.6134238 trainloss2: 0.1340416 validloss2: 0.2804064\n",
            "time: 120.05246067047119 Epoch: 337 / 556 loss -0.7923172 trainloss: -0.6837278 validloss: -0.6020631 trainloss2: 0.12909071 validloss2: 0.28563493\n",
            "time: 120.28194618225098 Epoch: 338 / 556 loss -0.8227172 trainloss: -0.68177825 validloss: -0.6071857 trainloss2: 0.13169636 validloss2: 0.2842127\n",
            "time: 120.15781712532043 Epoch: 339 / 556 loss -0.8009403 trainloss: -0.6850565 validloss: -0.60884416 trainloss2: 0.13237853 validloss2: 0.28118744\n",
            "time: 120.18861675262451 Epoch: 340 / 556 loss -0.83187366 trainloss: -0.6861277 validloss: -0.60538316 trainloss2: 0.13005179 validloss2: 0.28696597\n",
            "time: 120.08769583702087 Epoch: 341 / 556 loss -0.82162994 trainloss: -0.68686134 validloss: -0.6075207 trainloss2: 0.13130628 validloss2: 0.28156173\n",
            "time: 120.15479135513306 Epoch: 342 / 556 loss -0.8096597 trainloss: -0.6870759 validloss: -0.6095072 trainloss2: 0.12820038 validloss2: 0.27705824\n",
            "time: 120.16944217681885 Epoch: 343 / 556 loss -0.821869 trainloss: -0.68342847 validloss: -0.62089026 trainloss2: 0.13105173 validloss2: 0.27382767\n",
            "time: 120.1844835281372 Epoch: 344 / 556 loss -0.8211266 trainloss: -0.6840935 validloss: -0.6137038 trainloss2: 0.13308962 validloss2: 0.28121665\n",
            "time: 120.0012617111206 Epoch: 345 / 556 loss -0.8368686 trainloss: -0.68814754 validloss: -0.6161377 trainloss2: 0.12930262 validloss2: 0.27345276\n",
            "time: 120.01850771903992 Epoch: 346 / 556 loss -0.8156184 trainloss: -0.6839472 validloss: -0.60579205 trainloss2: 0.13044228 validloss2: 0.28183475\n",
            "time: 120.08389592170715 Epoch: 347 / 556 loss -0.81721735 trainloss: -0.6877367 validloss: -0.6087948 trainloss2: 0.12947312 validloss2: 0.28238487\n",
            "time: 120.02403402328491 Epoch: 348 / 556 loss -0.82192266 trainloss: -0.68516505 validloss: -0.61203146 trainloss2: 0.12996155 validloss2: 0.27261156\n",
            "time: 120.00692582130432 Epoch: 349 / 556 loss -0.82251346 trainloss: -0.6828402 validloss: -0.609215 trainloss2: 0.1338031 validloss2: 0.27905276\n",
            "time: 120.03151059150696 Epoch: 350 / 556 loss -0.8073777 trainloss: -0.68133515 validloss: -0.6166128 trainloss2: 0.1281194 validloss2: 0.26455548\n",
            "time: 119.94944500923157 Epoch: 351 / 556 loss -0.80472386 trainloss: -0.68298775 validloss: -0.6079185 trainloss2: 0.12948407 validloss2: 0.27831122\n",
            "time: 120.00058197975159 Epoch: 352 / 556 loss -0.8201097 trainloss: -0.68504745 validloss: -0.6056829 trainloss2: 0.13360505 validloss2: 0.28566018\n",
            "time: 120.14660263061523 Epoch: 353 / 556 loss -0.8395003 trainloss: -0.68479264 validloss: -0.61185354 trainloss2: 0.13029741 validloss2: 0.27848548\n",
            "time: 120.08560466766357 Epoch: 354 / 556 loss -0.8058566 trainloss: -0.6826346 validloss: -0.6145993 trainloss2: 0.13262479 validloss2: 0.27546024\n",
            "time: 119.86954689025879 Epoch: 355 / 556 loss -0.84584695 trainloss: -0.6835679 validloss: -0.6091775 trainloss2: 0.1285384 validloss2: 0.28860927\n",
            "time: 120.05486607551575 Epoch: 356 / 556 loss -0.8201159 trainloss: -0.6865162 validloss: -0.61399347 trainloss2: 0.130501 validloss2: 0.27685142\n",
            "time: 120.11474967002869 Epoch: 357 / 556 loss -0.81149536 trainloss: -0.6874979 validloss: -0.60865134 trainloss2: 0.13265118 validloss2: 0.2734326\n",
            "time: 120.17504906654358 Epoch: 358 / 556 loss -0.8235223 trainloss: -0.6843632 validloss: -0.6095698 trainloss2: 0.13098858 validloss2: 0.2870236\n",
            "time: 120.04129576683044 Epoch: 359 / 556 loss -0.80689937 trainloss: -0.6888808 validloss: -0.60774565 trainloss2: 0.13073066 validloss2: 0.27644214\n",
            "time: 119.92272877693176 Epoch: 360 / 556 loss -0.80133843 trainloss: -0.6824406 validloss: -0.6032079 trainloss2: 0.12899972 validloss2: 0.27627\n",
            "time: 120.04559183120728 Epoch: 361 / 556 loss -0.8317336 trainloss: -0.68200296 validloss: -0.6022594 trainloss2: 0.13209544 validloss2: 0.27790746\n",
            "time: 119.95107674598694 Epoch: 362 / 556 loss -0.8435843 trainloss: -0.67923427 validloss: -0.6043047 trainloss2: 0.13250914 validloss2: 0.28793147\n",
            "time: 119.92921280860901 Epoch: 363 / 556 loss -0.8355029 trainloss: -0.684546 validloss: -0.61200035 trainloss2: 0.13218156 validloss2: 0.28455344\n",
            "time: 119.8135392665863 Epoch: 364 / 556 loss -0.82773244 trainloss: -0.68405557 validloss: -0.59905726 trainloss2: 0.13290183 validloss2: 0.2925153\n",
            "time: 120.01621222496033 Epoch: 365 / 556 loss -0.8022683 trainloss: -0.6825038 validloss: -0.61237574 trainloss2: 0.12768403 validloss2: 0.28080684\n",
            "time: 120.08017945289612 Epoch: 366 / 556 loss -0.82799065 trainloss: -0.685347 validloss: -0.6101486 trainloss2: 0.13317083 validloss2: 0.2797309\n",
            "time: 119.93081998825073 Epoch: 367 / 556 loss -0.80661714 trainloss: -0.68275356 validloss: -0.60262257 trainloss2: 0.13100569 validloss2: 0.27803287\n",
            "time: 119.99134469032288 Epoch: 368 / 556 loss -0.8204931 trainloss: -0.6807719 validloss: -0.603138 trainloss2: 0.1318446 validloss2: 0.2788011\n",
            "time: 119.79536175727844 Epoch: 369 / 556 loss -0.82536304 trainloss: -0.68413776 validloss: -0.6099798 trainloss2: 0.13013591 validloss2: 0.28034818\n",
            "time: 120.05452728271484 Epoch: 370 / 556 loss -0.81240493 trainloss: -0.6841389 validloss: -0.6038681 trainloss2: 0.12994166 validloss2: 0.2805859\n",
            "time: 120.01136684417725 Epoch: 371 / 556 loss -0.7921024 trainloss: -0.68123287 validloss: -0.6122256 trainloss2: 0.13056783 validloss2: 0.28250232\n",
            "time: 119.88391590118408 Epoch: 372 / 556 loss -0.8143388 trainloss: -0.6841321 validloss: -0.610222 trainloss2: 0.13065523 validloss2: 0.27722558\n",
            "time: 119.92107558250427 Epoch: 373 / 556 loss -0.8170421 trainloss: -0.6819381 validloss: -0.60913557 trainloss2: 0.12854981 validloss2: 0.28028446\n",
            "time: 119.84177017211914 Epoch: 374 / 556 loss -0.78693354 trainloss: -0.6902409 validloss: -0.6061379 trainloss2: 0.12745902 validloss2: 0.28253135\n",
            "time: 119.92200422286987 Epoch: 375 / 556 loss -0.80817306 trainloss: -0.6855598 validloss: -0.6081523 trainloss2: 0.13340928 validloss2: 0.27988905\n",
            "time: 120.02226281166077 Epoch: 376 / 556 loss -0.8309077 trainloss: -0.6813055 validloss: -0.61009675 trainloss2: 0.13179655 validloss2: 0.2825056\n",
            "time: 120.1324474811554 Epoch: 377 / 556 loss -0.83137596 trainloss: -0.6857177 validloss: -0.6033271 trainloss2: 0.12796398 validloss2: 0.28369257\n",
            "time: 119.70134949684143 Epoch: 378 / 556 loss -0.8233883 trainloss: -0.68185794 validloss: -0.61581784 trainloss2: 0.13060498 validloss2: 0.27482793\n",
            "time: 119.14108276367188 Epoch: 379 / 556 loss -0.8071283 trainloss: -0.6877873 validloss: -0.6094553 trainloss2: 0.13167222 validloss2: 0.28062364\n",
            "time: 119.0589292049408 Epoch: 380 / 556 loss -0.8145996 trainloss: -0.68592966 validloss: -0.6075457 trainloss2: 0.12905328 validloss2: 0.29455414\n",
            "time: 119.15095496177673 Epoch: 381 / 556 loss -0.7830955 trainloss: -0.68301225 validloss: -0.6179795 trainloss2: 0.1307632 validloss2: 0.27608413\n",
            "time: 119.17195272445679 Epoch: 382 / 556 loss -0.8182033 trainloss: -0.6851026 validloss: -0.60782427 trainloss2: 0.13182455 validloss2: 0.28396556\n",
            "time: 118.97952103614807 Epoch: 383 / 556 loss -0.836924 trainloss: -0.68105364 validloss: -0.6098505 trainloss2: 0.13054952 validloss2: 0.27905282\n",
            "time: 119.15459179878235 Epoch: 384 / 556 loss -0.8148944 trainloss: -0.6845259 validloss: -0.61105394 trainloss2: 0.13034946 validloss2: 0.27781522\n",
            "time: 119.12075018882751 Epoch: 385 / 556 loss -0.85412717 trainloss: -0.6866128 validloss: -0.61210686 trainloss2: 0.13134623 validloss2: 0.28736982\n",
            "time: 118.86359000205994 Epoch: 386 / 556 loss -0.82044196 trainloss: -0.68145746 validloss: -0.6163734 trainloss2: 0.13078976 validloss2: 0.2756637\n",
            "time: 118.8577527999878 Epoch: 387 / 556 loss -0.8353181 trainloss: -0.6868312 validloss: -0.6086466 trainloss2: 0.13174863 validloss2: 0.2860754\n",
            "time: 118.97236800193787 Epoch: 388 / 556 loss -0.82067984 trainloss: -0.6828993 validloss: -0.6095733 trainloss2: 0.12983245 validloss2: 0.28373778\n",
            "time: 118.94859290122986 Epoch: 389 / 556 loss -0.7997402 trainloss: -0.68331134 validloss: -0.60618955 trainloss2: 0.12940197 validloss2: 0.29041627\n",
            "time: 118.93588376045227 Epoch: 390 / 556 loss -0.8335804 trainloss: -0.6867049 validloss: -0.6126961 trainloss2: 0.12854688 validloss2: 0.28710043\n",
            "time: 118.86460876464844 Epoch: 391 / 556 loss -0.7949888 trainloss: -0.6821324 validloss: -0.6060106 trainloss2: 0.13135114 validloss2: 0.28552052\n",
            "time: 119.06413245201111 Epoch: 392 / 556 loss -0.8085368 trainloss: -0.68561834 validloss: -0.6152959 trainloss2: 0.12874527 validloss2: 0.27949202\n",
            "time: 119.06514501571655 Epoch: 393 / 556 loss -0.84925056 trainloss: -0.6881607 validloss: -0.60276914 trainloss2: 0.12988575 validloss2: 0.28393903\n",
            "time: 118.94842457771301 Epoch: 394 / 556 loss -0.8122535 trainloss: -0.6861399 validloss: -0.61385286 trainloss2: 0.13162999 validloss2: 0.26870328\n",
            "time: 118.97016930580139 Epoch: 395 / 556 loss -0.80020976 trainloss: -0.6837092 validloss: -0.6080862 trainloss2: 0.13005242 validloss2: 0.27377832\n",
            "time: 119.16916394233704 Epoch: 396 / 556 loss -0.83730465 trainloss: -0.68653744 validloss: -0.61252034 trainloss2: 0.12992005 validloss2: 0.27612203\n",
            "time: 118.89313054084778 Epoch: 397 / 556 loss -0.8326731 trainloss: -0.68682516 validloss: -0.59976304 trainloss2: 0.12865445 validloss2: 0.28424668\n",
            "time: 119.25804114341736 Epoch: 398 / 556 loss -0.7941163 trainloss: -0.6814271 validloss: -0.60682577 trainloss2: 0.13069677 validloss2: 0.27828464\n",
            "time: 119.15144109725952 Epoch: 399 / 556 loss -0.8406593 trainloss: -0.6852512 validloss: -0.60754734 trainloss2: 0.12777333 validloss2: 0.27777195\n",
            "time: 119.15482640266418 Epoch: 400 / 556 loss -0.8150099 trainloss: -0.6849475 validloss: -0.6066986 trainloss2: 0.13286562 validloss2: 0.28720993\n",
            "time: 119.12057328224182 Epoch: 401 / 556 loss -0.83733666 trainloss: -0.68770796 validloss: -0.606127 trainloss2: 0.1313913 validloss2: 0.28422052\n",
            "time: 119.24035787582397 Epoch: 402 / 556 loss -0.8453687 trainloss: -0.6830923 validloss: -0.6084233 trainloss2: 0.12948805 validloss2: 0.28521705\n",
            "time: 119.14654636383057 Epoch: 403 / 556 loss -0.8205123 trainloss: -0.6818734 validloss: -0.6101824 trainloss2: 0.13013177 validloss2: 0.28580514\n",
            "time: 119.10619735717773 Epoch: 404 / 556 loss -0.81177986 trainloss: -0.6829863 validloss: -0.61229193 trainloss2: 0.1340503 validloss2: 0.28385308\n",
            "time: 119.241366147995 Epoch: 405 / 556 loss -0.81949806 trainloss: -0.68405855 validloss: -0.6043369 trainloss2: 0.13077329 validloss2: 0.2842152\n",
            "time: 119.14683198928833 Epoch: 406 / 556 loss -0.840448 trainloss: -0.685926 validloss: -0.60793364 trainloss2: 0.12895024 validloss2: 0.2877135\n",
            "time: 119.17596554756165 Epoch: 407 / 556 loss -0.8076797 trainloss: -0.6839365 validloss: -0.61212784 trainloss2: 0.13042347 validloss2: 0.27689502\n",
            "time: 119.21276879310608 Epoch: 408 / 556 loss -0.8276918 trainloss: -0.68592185 validloss: -0.61161387 trainloss2: 0.13160509 validloss2: 0.2801965\n",
            "time: 119.12231016159058 Epoch: 409 / 556 loss -0.8209951 trainloss: -0.6848854 validloss: -0.61690634 trainloss2: 0.13008022 validloss2: 0.28012422\n",
            "time: 119.1397922039032 Epoch: 410 / 556 loss -0.8088913 trainloss: -0.68380994 validloss: -0.6056418 trainloss2: 0.13417438 validloss2: 0.28143427\n",
            "time: 119.24434399604797 Epoch: 411 / 556 loss -0.8067688 trainloss: -0.68185955 validloss: -0.61971724 trainloss2: 0.13172208 validloss2: 0.26994392\n",
            "time: 119.11117649078369 Epoch: 412 / 556 loss -0.8183953 trainloss: -0.68591255 validloss: -0.6173078 trainloss2: 0.13202238 validloss2: 0.2736376\n",
            "time: 119.25418472290039 Epoch: 413 / 556 loss -0.81527954 trainloss: -0.681538 validloss: -0.6085051 trainloss2: 0.12948677 validloss2: 0.2813712\n",
            "time: 119.11739253997803 Epoch: 414 / 556 loss -0.8465434 trainloss: -0.68147063 validloss: -0.61183244 trainloss2: 0.13286343 validloss2: 0.28006294\n",
            "time: 119.17459797859192 Epoch: 415 / 556 loss -0.83652973 trainloss: -0.68983734 validloss: -0.6152839 trainloss2: 0.13093701 validloss2: 0.27467868\n",
            "time: 119.1484386920929 Epoch: 416 / 556 loss -0.8296802 trainloss: -0.68572193 validloss: -0.6100244 trainloss2: 0.12976718 validloss2: 0.28048366\n",
            "time: 119.05651140213013 Epoch: 417 / 556 loss -0.84866303 trainloss: -0.6871569 validloss: -0.61562765 trainloss2: 0.12946635 validloss2: 0.27979818\n",
            "time: 119.02323126792908 Epoch: 418 / 556 loss -0.8263245 trainloss: -0.68395036 validloss: -0.60635465 trainloss2: 0.1305727 validloss2: 0.28747624\n",
            "time: 119.14990139007568 Epoch: 419 / 556 loss -0.7774414 trainloss: -0.68286335 validloss: -0.60772306 trainloss2: 0.13248968 validloss2: 0.2849382\n",
            "time: 119.15390396118164 Epoch: 420 / 556 loss -0.843198 trainloss: -0.6836093 validloss: -0.59334314 trainloss2: 0.12847051 validloss2: 0.29830647\n",
            "time: 119.17237591743469 Epoch: 421 / 556 loss -0.82514596 trainloss: -0.68272763 validloss: -0.61756444 trainloss2: 0.13201928 validloss2: 0.27359343\n",
            "time: 119.17129921913147 Epoch: 422 / 556 loss -0.81414086 trainloss: -0.68265253 validloss: -0.60879743 trainloss2: 0.12713377 validloss2: 0.28371778\n",
            "time: 119.2260890007019 Epoch: 423 / 556 loss -0.819206 trainloss: -0.6837029 validloss: -0.60679775 trainloss2: 0.12927338 validloss2: 0.28149417\n",
            "time: 119.12554025650024 Epoch: 424 / 556 loss -0.80768776 trainloss: -0.68535167 validloss: -0.6095037 trainloss2: 0.13224755 validloss2: 0.2809832\n",
            "time: 119.2188823223114 Epoch: 425 / 556 loss -0.83763796 trainloss: -0.6838508 validloss: -0.6150707 trainloss2: 0.13191436 validloss2: 0.27849686\n",
            "time: 119.14377450942993 Epoch: 426 / 556 loss -0.82860786 trainloss: -0.68845254 validloss: -0.6082683 trainloss2: 0.13179065 validloss2: 0.2825359\n",
            "time: 119.20347595214844 Epoch: 427 / 556 loss -0.82182974 trainloss: -0.6841897 validloss: -0.61243784 trainloss2: 0.13051319 validloss2: 0.2723897\n",
            "time: 119.10159969329834 Epoch: 428 / 556 loss -0.8478458 trainloss: -0.68764585 validloss: -0.61151224 trainloss2: 0.1324864 validloss2: 0.2879462\n",
            "time: 119.2013144493103 Epoch: 429 / 556 loss -0.846473 trainloss: -0.6827077 validloss: -0.61617583 trainloss2: 0.13133089 validloss2: 0.27314907\n",
            "time: 119.12399578094482 Epoch: 430 / 556 loss -0.81832457 trainloss: -0.68646276 validloss: -0.61196226 trainloss2: 0.12826174 validloss2: 0.278465\n",
            "time: 118.94460344314575 Epoch: 431 / 556 loss -0.84399515 trainloss: -0.68651694 validloss: -0.60834146 trainloss2: 0.13070449 validloss2: 0.274565\n",
            "time: 119.15796971321106 Epoch: 432 / 556 loss -0.8190535 trainloss: -0.68646246 validloss: -0.61018324 trainloss2: 0.13227132 validloss2: 0.2819819\n",
            "time: 119.2504780292511 Epoch: 433 / 556 loss -0.82893723 trainloss: -0.6891589 validloss: -0.603956 trainloss2: 0.12661669 validloss2: 0.2780957\n",
            "time: 119.11496758460999 Epoch: 434 / 556 loss -0.7997273 trainloss: -0.6862236 validloss: -0.60975254 trainloss2: 0.12823953 validloss2: 0.284384\n",
            "time: 119.17056441307068 Epoch: 435 / 556 loss -0.78871745 trainloss: -0.68383414 validloss: -0.6061762 trainloss2: 0.13203959 validloss2: 0.28405267\n",
            "time: 119.21687650680542 Epoch: 436 / 556 loss -0.7958082 trainloss: -0.683476 validloss: -0.6111584 trainloss2: 0.13200107 validloss2: 0.28447667\n",
            "time: 119.17220187187195 Epoch: 437 / 556 loss -0.8019785 trainloss: -0.6825282 validloss: -0.61128926 trainloss2: 0.13217664 validloss2: 0.28149995\n",
            "time: 119.1255042552948 Epoch: 438 / 556 loss -0.83340293 trainloss: -0.6818321 validloss: -0.6109399 trainloss2: 0.13406444 validloss2: 0.2842911\n",
            "time: 119.20188975334167 Epoch: 439 / 556 loss -0.81956947 trainloss: -0.6869133 validloss: -0.6146949 trainloss2: 0.129475 validloss2: 0.27282035\n",
            "time: 119.17007160186768 Epoch: 440 / 556 loss -0.80959255 trainloss: -0.6888889 validloss: -0.5964413 trainloss2: 0.13239492 validloss2: 0.293518\n",
            "time: 119.21085786819458 Epoch: 441 / 556 loss -0.8048993 trainloss: -0.6847595 validloss: -0.61172086 trainloss2: 0.12992956 validloss2: 0.27993798\n",
            "time: 119.13958406448364 Epoch: 442 / 556 loss -0.8095072 trainloss: -0.6850753 validloss: -0.606523 trainloss2: 0.1304003 validloss2: 0.28904477\n",
            "time: 119.15061163902283 Epoch: 443 / 556 loss -0.79832023 trainloss: -0.68703634 validloss: -0.60878694 trainloss2: 0.13226473 validloss2: 0.28149623\n",
            "time: 119.17097187042236 Epoch: 444 / 556 loss -0.8310644 trainloss: -0.68488353 validloss: -0.6058131 trainloss2: 0.13213202 validloss2: 0.29865044\n",
            "time: 119.16035962104797 Epoch: 445 / 556 loss -0.8294123 trainloss: -0.6832303 validloss: -0.6073044 trainloss2: 0.13300167 validloss2: 0.28187338\n",
            "time: 119.15778017044067 Epoch: 446 / 556 loss -0.80618435 trainloss: -0.6844638 validloss: -0.60416 trainloss2: 0.13326989 validloss2: 0.28237256\n",
            "time: 119.18036341667175 Epoch: 447 / 556 loss -0.7768101 trainloss: -0.6870156 validloss: -0.60314155 trainloss2: 0.13051797 validloss2: 0.2770916\n",
            "time: 119.17895650863647 Epoch: 448 / 556 loss -0.8449424 trainloss: -0.68517244 validloss: -0.61381423 trainloss2: 0.13126156 validloss2: 0.27647132\n",
            "time: 119.15387511253357 Epoch: 449 / 556 loss -0.80473083 trainloss: -0.6834534 validloss: -0.6102815 trainloss2: 0.13147628 validloss2: 0.28551397\n",
            "time: 119.17797017097473 Epoch: 450 / 556 loss -0.81592107 trainloss: -0.68325526 validloss: -0.61491084 trainloss2: 0.1283466 validloss2: 0.2733506\n",
            "time: 119.16225671768188 Epoch: 451 / 556 loss -0.8177963 trainloss: -0.68617845 validloss: -0.61378497 trainloss2: 0.13156141 validloss2: 0.2779435\n",
            "time: 119.2096951007843 Epoch: 452 / 556 loss -0.8277489 trainloss: -0.68324345 validloss: -0.61154383 trainloss2: 0.13191447 validloss2: 0.27919492\n",
            "time: 119.10045123100281 Epoch: 453 / 556 loss -0.82486176 trainloss: -0.6825378 validloss: -0.61017144 trainloss2: 0.13301432 validloss2: 0.29924625\n",
            "time: 119.21221876144409 Epoch: 454 / 556 loss -0.832036 trainloss: -0.68807817 validloss: -0.60975164 trainloss2: 0.13065289 validloss2: 0.2843155\n",
            "time: 119.1721830368042 Epoch: 455 / 556 loss -0.7837081 trainloss: -0.68266755 validloss: -0.6122845 trainloss2: 0.13071312 validloss2: 0.28686944\n",
            "time: 119.10340428352356 Epoch: 456 / 556 loss -0.8363042 trainloss: -0.68644404 validloss: -0.60774887 trainloss2: 0.13086487 validloss2: 0.2858607\n",
            "time: 119.22566056251526 Epoch: 457 / 556 loss -0.8108268 trainloss: -0.6847816 validloss: -0.60807604 trainloss2: 0.12947127 validloss2: 0.2767583\n",
            "time: 119.1639289855957 Epoch: 458 / 556 loss -0.83307344 trainloss: -0.6863369 validloss: -0.6125034 trainloss2: 0.13027065 validloss2: 0.28074396\n",
            "time: 119.1776077747345 Epoch: 459 / 556 loss -0.8003961 trainloss: -0.6847203 validloss: -0.6124677 trainloss2: 0.13197355 validloss2: 0.27773112\n",
            "time: 119.18316912651062 Epoch: 460 / 556 loss -0.8235078 trainloss: -0.68836194 validloss: -0.6043763 trainloss2: 0.12978819 validloss2: 0.28817105\n",
            "time: 119.16555738449097 Epoch: 461 / 556 loss -0.8434678 trainloss: -0.68777895 validloss: -0.6070898 trainloss2: 0.12851028 validloss2: 0.2806687\n",
            "time: 119.14282369613647 Epoch: 462 / 556 loss -0.84014684 trainloss: -0.68036205 validloss: -0.60268193 trainloss2: 0.13025147 validloss2: 0.28476775\n",
            "time: 119.145911693573 Epoch: 463 / 556 loss -0.8080756 trainloss: -0.6854012 validloss: -0.6055878 trainloss2: 0.13165864 validloss2: 0.28658354\n",
            "time: 119.2238495349884 Epoch: 464 / 556 loss -0.83215404 trainloss: -0.68667305 validloss: -0.6049972 trainloss2: 0.13117719 validloss2: 0.2811638\n",
            "time: 119.14187717437744 Epoch: 465 / 556 loss -0.79214925 trainloss: -0.6833077 validloss: -0.6158506 trainloss2: 0.13032727 validloss2: 0.27661058\n",
            "time: 119.13314533233643 Epoch: 466 / 556 loss -0.81958985 trainloss: -0.68607974 validloss: -0.60052747 trainloss2: 0.1313735 validloss2: 0.2827048\n",
            "time: 119.23293805122375 Epoch: 467 / 556 loss -0.8362062 trainloss: -0.6873419 validloss: -0.608816 trainloss2: 0.13051331 validloss2: 0.2907697\n",
            "time: 119.12709856033325 Epoch: 468 / 556 loss -0.84320575 trainloss: -0.6856935 validloss: -0.60651946 trainloss2: 0.13218167 validloss2: 0.28141195\n",
            "time: 119.12374711036682 Epoch: 469 / 556 loss -0.8197228 trainloss: -0.6828002 validloss: -0.60471225 trainloss2: 0.1305715 validloss2: 0.2856566\n",
            "time: 119.22318577766418 Epoch: 470 / 556 loss -0.8381908 trainloss: -0.68538934 validloss: -0.60757565 trainloss2: 0.12985703 validloss2: 0.2834778\n",
            "time: 119.18955755233765 Epoch: 471 / 556 loss -0.8253553 trainloss: -0.6881539 validloss: -0.6126447 trainloss2: 0.13187416 validloss2: 0.2831095\n",
            "time: 119.13227701187134 Epoch: 472 / 556 loss -0.8394368 trainloss: -0.68196714 validloss: -0.6065988 trainloss2: 0.13258056 validloss2: 0.2828225\n",
            "time: 119.10766100883484 Epoch: 473 / 556 loss -0.79957986 trainloss: -0.6845613 validloss: -0.60900116 trainloss2: 0.13145876 validloss2: 0.27461964\n",
            "time: 118.95344972610474 Epoch: 474 / 556 loss -0.8244752 trainloss: -0.679467 validloss: -0.608859 trainloss2: 0.12954237 validloss2: 0.277766\n",
            "time: 119.1558825969696 Epoch: 475 / 556 loss -0.80229944 trainloss: -0.6838438 validloss: -0.6067923 trainloss2: 0.12963802 validloss2: 0.2785892\n",
            "time: 119.18191862106323 Epoch: 476 / 556 loss -0.81263274 trainloss: -0.6804127 validloss: -0.5967002 trainloss2: 0.13001221 validloss2: 0.2814146\n",
            "time: 119.10189032554626 Epoch: 477 / 556 loss -0.83412963 trainloss: -0.68716735 validloss: -0.6169283 trainloss2: 0.13184135 validloss2: 0.27525225\n",
            "time: 119.00507092475891 Epoch: 478 / 556 loss -0.8236348 trainloss: -0.684253 validloss: -0.6102857 trainloss2: 0.12771681 validloss2: 0.28288344\n",
            "time: 119.21779417991638 Epoch: 479 / 556 loss -0.78312314 trainloss: -0.6878293 validloss: -0.60286885 trainloss2: 0.12692314 validloss2: 0.2825652\n",
            "time: 119.12366390228271 Epoch: 480 / 556 loss -0.82174754 trainloss: -0.6841441 validloss: -0.5999127 trainloss2: 0.13046484 validloss2: 0.29107338\n",
            "time: 119.10381698608398 Epoch: 481 / 556 loss -0.820111 trainloss: -0.6814979 validloss: -0.61014986 trainloss2: 0.13155958 validloss2: 0.2798433\n",
            "time: 119.17784452438354 Epoch: 482 / 556 loss -0.82187027 trainloss: -0.6862278 validloss: -0.60811955 trainloss2: 0.12969011 validloss2: 0.2874852\n",
            "time: 119.00410628318787 Epoch: 483 / 556 loss -0.8058906 trainloss: -0.6866701 validloss: -0.60287076 trainloss2: 0.13043831 validloss2: 0.28654402\n",
            "time: 119.12125086784363 Epoch: 484 / 556 loss -0.8033578 trainloss: -0.6857471 validloss: -0.61056435 trainloss2: 0.12976885 validloss2: 0.2868049\n",
            "time: 119.19012570381165 Epoch: 485 / 556 loss -0.8252755 trainloss: -0.6837647 validloss: -0.6108171 trainloss2: 0.13036738 validloss2: 0.2861036\n",
            "time: 119.10667371749878 Epoch: 486 / 556 loss -0.768604 trainloss: -0.68387395 validloss: -0.619278 trainloss2: 0.13174622 validloss2: 0.2679257\n",
            "time: 119.209055185318 Epoch: 487 / 556 loss -0.8283456 trainloss: -0.68881303 validloss: -0.60445905 trainloss2: 0.12928225 validloss2: 0.286787\n",
            "time: 119.22796034812927 Epoch: 488 / 556 loss -0.8117553 trainloss: -0.6865983 validloss: -0.60871404 trainloss2: 0.13272418 validloss2: 0.2909934\n",
            "time: 119.12200713157654 Epoch: 489 / 556 loss -0.8226228 trainloss: -0.6883862 validloss: -0.6114035 trainloss2: 0.12922682 validloss2: 0.28537545\n",
            "time: 119.19737148284912 Epoch: 490 / 556 loss -0.8346562 trainloss: -0.68453944 validloss: -0.60822713 trainloss2: 0.1303125 validloss2: 0.28372005\n",
            "time: 119.12434959411621 Epoch: 491 / 556 loss -0.8053713 trainloss: -0.6850452 validloss: -0.60748094 trainloss2: 0.1300394 validloss2: 0.28362063\n",
            "time: 119.02261519432068 Epoch: 492 / 556 loss -0.82660574 trainloss: -0.6845555 validloss: -0.60741425 trainloss2: 0.12913303 validloss2: 0.2855009\n",
            "time: 119.08758115768433 Epoch: 493 / 556 loss -0.817984 trainloss: -0.68412393 validloss: -0.6112076 trainloss2: 0.12993695 validloss2: 0.2825473\n",
            "time: 119.20130848884583 Epoch: 494 / 556 loss -0.8106428 trainloss: -0.6861539 validloss: -0.59834176 trainloss2: 0.12756567 validloss2: 0.2840271\n",
            "time: 119.14827084541321 Epoch: 495 / 556 loss -0.81851745 trainloss: -0.6855128 validloss: -0.60502684 trainloss2: 0.12948951 validloss2: 0.28246883\n",
            "time: 119.19075870513916 Epoch: 496 / 556 loss -0.80529654 trainloss: -0.68373746 validloss: -0.6049545 trainloss2: 0.13048624 validloss2: 0.28709552\n",
            "time: 119.1649980545044 Epoch: 497 / 556 loss -0.82708937 trainloss: -0.68615687 validloss: -0.60680974 trainloss2: 0.13213281 validloss2: 0.28946778\n",
            "time: 119.1649284362793 Epoch: 498 / 556 loss -0.7951766 trainloss: -0.6812351 validloss: -0.6115203 trainloss2: 0.13104129 validloss2: 0.29047352\n",
            "time: 119.20581364631653 Epoch: 499 / 556 loss -0.8311079 trainloss: -0.6873774 validloss: -0.6030775 trainloss2: 0.13065124 validloss2: 0.28201786\n",
            "time: 119.09519338607788 Epoch: 500 / 556 loss -0.822537 trainloss: -0.680041 validloss: -0.61080366 trainloss2: 0.13242897 validloss2: 0.2921288\n",
            "time: 119.1432876586914 Epoch: 501 / 556 loss -0.83892214 trainloss: -0.68768156 validloss: -0.59693927 trainloss2: 0.1299464 validloss2: 0.28961244\n",
            "time: 119.23982405662537 Epoch: 502 / 556 loss -0.845538 trainloss: -0.6868875 validloss: -0.6081912 trainloss2: 0.13299017 validloss2: 0.2889979\n",
            "time: 119.1620500087738 Epoch: 503 / 556 loss -0.82249373 trainloss: -0.6867549 validloss: -0.61128926 trainloss2: 0.12935705 validloss2: 0.28413007\n",
            "time: 119.19255304336548 Epoch: 504 / 556 loss -0.8181934 trainloss: -0.6834374 validloss: -0.60980695 trainloss2: 0.12986629 validloss2: 0.28458285\n",
            "time: 119.17986679077148 Epoch: 505 / 556 loss -0.8440394 trainloss: -0.68582356 validloss: -0.6023611 trainloss2: 0.13342609 validloss2: 0.2848622\n",
            "time: 119.20242071151733 Epoch: 506 / 556 loss -0.83180773 trainloss: -0.6850961 validloss: -0.60359627 trainloss2: 0.12862827 validloss2: 0.2878436\n",
            "time: 119.1251151561737 Epoch: 507 / 556 loss -0.8302395 trainloss: -0.686117 validloss: -0.60963947 trainloss2: 0.13081363 validloss2: 0.2908835\n",
            "time: 119.12685966491699 Epoch: 508 / 556 loss -0.82978165 trainloss: -0.68462896 validloss: -0.60910565 trainloss2: 0.13412929 validloss2: 0.28755197\n",
            "time: 119.2539963722229 Epoch: 509 / 556 loss -0.8428779 trainloss: -0.6871675 validloss: -0.60736865 trainloss2: 0.1320023 validloss2: 0.28363076\n",
            "time: 119.1384801864624 Epoch: 510 / 556 loss -0.7893169 trainloss: -0.6880804 validloss: -0.6119437 trainloss2: 0.1307825 validloss2: 0.27923793\n",
            "time: 119.19668650627136 Epoch: 511 / 556 loss -0.8132238 trainloss: -0.6855861 validloss: -0.61262757 trainloss2: 0.12937957 validloss2: 0.2768742\n",
            "time: 119.10299134254456 Epoch: 512 / 556 loss -0.8464082 trainloss: -0.6832389 validloss: -0.61020464 trainloss2: 0.12997141 validloss2: 0.2786309\n",
            "time: 119.16739749908447 Epoch: 513 / 556 loss -0.8257625 trainloss: -0.68762314 validloss: -0.60157603 trainloss2: 0.13049848 validloss2: 0.2853678\n",
            "time: 119.19955444335938 Epoch: 514 / 556 loss -0.79526573 trainloss: -0.68613875 validloss: -0.60469264 trainloss2: 0.12796934 validloss2: 0.28824666\n",
            "time: 119.17383575439453 Epoch: 515 / 556 loss -0.8336383 trainloss: -0.6845528 validloss: -0.6029537 trainloss2: 0.13111413 validloss2: 0.28815776\n",
            "time: 119.10716485977173 Epoch: 516 / 556 loss -0.78260833 trainloss: -0.68379 validloss: -0.6076064 trainloss2: 0.13104343 validloss2: 0.288213\n",
            "time: 119.25092482566833 Epoch: 517 / 556 loss -0.8315218 trainloss: -0.6844077 validloss: -0.6071482 trainloss2: 0.12961987 validloss2: 0.28481063\n",
            "time: 119.08031964302063 Epoch: 518 / 556 loss -0.84047896 trainloss: -0.6831476 validloss: -0.6048713 trainloss2: 0.12674335 validloss2: 0.2837976\n",
            "time: 119.24213576316833 Epoch: 519 / 556 loss -0.8449447 trainloss: -0.68776923 validloss: -0.60813856 trainloss2: 0.13038018 validloss2: 0.27985412\n",
            "time: 119.07181763648987 Epoch: 520 / 556 loss -0.83386064 trainloss: -0.687975 validloss: -0.6028171 trainloss2: 0.1282731 validloss2: 0.28618088\n",
            "time: 119.26816630363464 Epoch: 521 / 556 loss -0.79863036 trainloss: -0.6866518 validloss: -0.61379266 trainloss2: 0.12827629 validloss2: 0.27302697\n",
            "time: 119.38136506080627 Epoch: 522 / 556 loss -0.8393158 trainloss: -0.6850087 validloss: -0.60472697 trainloss2: 0.12912393 validloss2: 0.2851806\n",
            "time: 119.1477472782135 Epoch: 523 / 556 loss -0.7703549 trainloss: -0.6882896 validloss: -0.60510874 trainloss2: 0.13140608 validloss2: 0.27945346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I91j6ggRGbRL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "err_validold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ecbUuVKF-63b",
        "colab_type": "code",
        "outputId": "50fdbc4f-7171-404c-d343-3d966f5ca334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(logfile, index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>lr</th>\n",
              "      <th>loss</th>\n",
              "      <th>E1train</th>\n",
              "      <th>E1valid</th>\n",
              "      <th>E2train</th>\n",
              "      <th>E2valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.826918</td>\n",
              "      <td>-0.675099</td>\n",
              "      <td>-0.599859</td>\n",
              "      <td>0.135192</td>\n",
              "      <td>0.258439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.805080</td>\n",
              "      <td>-0.666980</td>\n",
              "      <td>-0.598860</td>\n",
              "      <td>0.135607</td>\n",
              "      <td>0.264365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.828745</td>\n",
              "      <td>-0.664764</td>\n",
              "      <td>-0.595688</td>\n",
              "      <td>0.139914</td>\n",
              "      <td>0.273182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.786168</td>\n",
              "      <td>-0.662371</td>\n",
              "      <td>-0.597828</td>\n",
              "      <td>0.141871</td>\n",
              "      <td>0.272680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.788752</td>\n",
              "      <td>-0.664622</td>\n",
              "      <td>-0.596941</td>\n",
              "      <td>0.139785</td>\n",
              "      <td>0.272957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch    lr      loss   E1train   E1valid   E2train   E2valid\n",
              "0      1  0.02 -0.826918 -0.675099 -0.599859  0.135192  0.258439\n",
              "0      2  0.02 -0.805080 -0.666980 -0.598860  0.135607  0.264365\n",
              "0      3  0.02 -0.828745 -0.664764 -0.595688  0.139914  0.273182\n",
              "0      4  0.02 -0.786168 -0.662371 -0.597828  0.141871  0.272680\n",
              "0      5  0.02 -0.788752 -0.664622 -0.596941  0.139785  0.272957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "metadata": {
        "id": "rXWCkemn-63s",
        "colab_type": "code",
        "outputId": "82fe6599-5e9e-4b2c-d4ff-0f03ab46197d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(df['epoch'],df['E1train'])\n",
        "plt.plot(df['epoch'],df['E1valid'],'r')\n",
        "plt.title('E1')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'E1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFZCAYAAAC173eYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd4FOXax/HvbN9NDwk9oSWQUI0R\nUBB7QVRUNEIUXz0qykHFrqBiw4KeA4oKR1HsCBpRUVSwgYogCAgoECC0UENCerbvzvvHhkioISTZ\nzOb+XFcuze7szHMzu/ntPDPzPIqqqipCCCGEaPR0wW6AEEIIIWpGQlsIIYTQCAltIYQQQiMktIUQ\nQgiNkNAWQgghNEJCWwghhNAIQ7AbIIQIri5dupCYmIher6/2+IsvvkjPnj3xeDxMnDiRd955h59/\n/pmWLVsGqaVCCAltIQQffPDBUcN41KhR9OjRo4FbJIQ4EukeF0Ic06hRoxg9enSwmyGEQEJbCHEc\naWlpwW6CEKKSdI8LIbjhhhuqndOOjY3lo48+CmKLhBBHIqEthDjmOW0hROMh3eNCCCGERkhoCyGE\nEBqhyNScQjRtR7tPe/jw4QwcOJDhw4cDsHXr1qrl3nvvPVq0aBGM5grRpEloCyGEEBoh3eNCCCGE\nRkhoCyGEEBohoS2EEEJohIS2EEIIoRES2kIIIYRGNPoR0fLzy4LdhHoRE2OjqMge7GbUm1CvD0K/\nRqlP+0K9xlCtLz4+4qjPyZF2kBgM+uMvpGGhXh+Efo1Sn/aFeo2hXt+RSGgLIYQQGiGhLYQQQmiE\nhLYQQgihERLaQgghhEZIaAshhBAaIaEthBBCaISEthBCCKEREtpCCCGERkhoCyGEEBohoS2EEEJo\nRKMfe7xJ8/sxLvwJXeF+3OecjxoXF+wWCSGECCIJ7cbI7cb8WRa2qa9gyF4PgKrT4elzOu6Bl+Ia\nOAh/x05BbqQQQoiGJqHdiChlpVjefxfrtKno9+xG1etxXjMUb0pXzN99i3HpEky/Lyb8yUfxpqTi\nuuRS3AMvxdsrDXRypkMIIUKdhHYjoNu7B+ubr2N5dzq6slJUWxj220fhuG0U/oREAByj70XJz8f8\n/TxM387F9PMCwl76L2Ev/Rdfy1a4Bw7CNfBSPGeeBSZTkCsSQghRHxRVVdVgN+JYQnU+7fj4CAp/\nW4516itYsmaheDz44+Jx3PZvHDfdghodc+wVVFRgWvgT5nlfY/ruW3RFRQD4IyJxn38B7oGX4r7g\nItTIqPov5gC7HX3udvQ7thOVmkR+26SG23YQxMdHhOz7E6S+UBDqNYZqfceaT1uOtBuaqmJY+ju8\n+RqxX30FgLdTEo5Ro3FmDAOLpWbrCQvDfenluC+9HLxejMt+x/TtXMzffoPli8+wfPEZqtGIp9+Z\nuC65DPfAQfhbtzm5tns86HbuCARz5Y8ud1vg/7dvR1eQ/8+yzZrBui2gKCe3TSGEEFXkSLuh+P2Y\nvv0a25TJGJcvA8CT3hv7nffgHjgI9HU0mbuqol+/DvO3czHN+wbj6j+rnvKcklZ5Idul+FK7Hh6o\nfj+6vXsCYbx920HBvB39jlx0u3eh+P3H3rxej/uCizCPeYj8bul1U1MjFarf8g+Q+rQv1GsM1fqO\ndaQtoV3fnE4sWbOwTn0Fw+YcAFwXX4L5sUfI79yz3o9Edbt2Ypr3DeZ5X2P87VcUrxcAX7v2uC+4\nCDxe9LnbAsG8cweK233YOlRFwd+qNb7EdvgT24HHjXHxb+jz9lYt4+2SgnPYcJzXDEVt0SJkP0wH\nC/UapT7t01KNSnkZEbffjDPzBtyXDa7Ra7RU34mQ7vEgUIqLsL47Heubr6PL34dqNOK47gYco0bj\n69wlsFMa4M3mb9MW5y234bzlNpSSYkw/fo/p268x/fg91unT/lkuLg5v9x6VwdweX2I7fAmJ+Nu1\nw9cmAcXtwvzFZ1hmfljVU+CPjMJ11TU4M6/Hm5YuXeFCiFqzfPQB5u/nY/j7LwovvBjM5mA3qVGS\n0K5jup07sL4xFesH76LYK/BHRGK/614cI0bib9kqqG1To6JxDcnANSQDXC4Mq1ehRkTgS0iE8PDD\nX+D3Y/ztV2z/fQHz11+iOByoioL77HNxZg7HdcllYLU2fCFCiNDi92OpPIjQ79mN5ZOZOG+4Kbht\naqQktOuC349+7d/Y/vcq5i9mo3i9+Fq1xvHQIzhvuBE1IjLYLTyc2Yy3T98jPqXbvg3Lxx9h+WQm\n+tztAPjad8A57Hqc12bib5vQkC0VQoQ404IfMGzdguuCizD9shDbK5NwZg4Hg0TUoeRfpKZUFd2+\nPPRbNh/+s20LisMBgDclFfuo0YGjWS3dL223Y547B8usGZgW/QKAagsLBHXmcDyn95PubyFEvbC8\n9QYA9rHj8LdNwPrudMyff4orY1iQW9b41Cq0PR4PY8aMYffu3ej1ep5//nkSEqoffWVnZ/PII48A\ncP7553PHHXfU6HVBpaoo+/dXhnEO+q2b0W/ZUhXOuoryw19iC8PbKRlfUhKuazNxn3+RdsJNVTEs\nW4rl4xmYv/gMXXngHLv7jP44h12P6/Irj9xtLoQQdUS/JQfzj9/j6XM63h69sN95D5YP3sU2eSKu\nq6+V0R4PUavQnjt3LpGRkUycOJFFixYxceJEXn755WrLjBs3jvHjx5OamsoDDzyAw+Fg3rx5x31d\nQ1CKCqsfKW898P9b0JWWHLa8arXia98RT8dO+A758TdvoZ2QrqTbsxvzJzOxzJpRdUW7r01bKm4b\nifPa62RccyFEgzlwLtsxYiQA/sR2uDKGBXr9vv4K9+VXBLN5jU6tQnvJkiVceeWVAPTr16/qiPqA\ngoIC7HY73bp1A2DSpEk1el19C3v2KSwfvIOusPCw51SzGV/7Dnj6nXl4MLdspf1vey4X5nlfB67+\nXvgTit+PajbjHHINzmHD8Qw4u+7uFRdCiBpQysuwzJyBr1VrXIMur3rcPvo+zB9/hO3l/wZu/9LY\ngVF9qlVoFxQUEBsbC4BOp0NRFNxuN6bKc7i7du0iKiqKMWPGsG3bNgYOHMhNN9103NcdSUyMDYOh\njsLE44D4eDjjDEhOrvajJCRg0Osb9CT/se7FqxOqCitXwjvvwEcfQeVQp/TpA//6F8qwYViio6nh\nGGwnrN7rawRCvUapT/sadY2fvA/lZfDwQ8S3jv3n8fhT4dprMX78MfHLF8GgQUddRaOurx4cN6Oy\nsrLIysqq9tjq1aur/X7o+CyqqrJz506mTJmCxWJh6NCh9O/f/7B112Rcl6Ii+3GXqbEnJ8CTR3mu\nsA63UwP1OSiAUlCA5dNZWGbOwLB+LQD++OY4R43GOex6fCmpgQU91Nu94qE66MHBQr1GqU/7GnWN\nqkrM5FfQm0zsH3Id6iHt1I+8m9iPP8bzxFMUn3bmEY+2G3V9J+GkBlfJyMggIyOj2mNjxowhPz+f\nlJQUPB4PqqpWO1pu1qwZycnJxMQEJr1IT09n06ZNNG/e/JivEyfB48H04/dYZn6I6ft5KF4vqsGA\na9DlODOH4z7vAjAag91KIYQAwPjzAgybNuLMGIYaH3/Y875u3XENHIR53jcYf/s1MIOhoFYnavv3\n78+8efMAWLBgAX37Vr/fNyEhgYqKCoqLi/H7/axfv56OHTse93XixOmz1xP2xKM065VC1P8Nw/zt\nXHydUygf/zz712yk9N0ZuC++RAJbCNGoWN96HQDHrbcfdRn7PQ8AYHvpPw3SJi2o1SncQYMGsXjx\nYjIzMzGZTEyYMAGAadOm0bt3b9LS0hg7diwjRoxAURQGDBhASkoKycnJR3ydODFKcRHmz2djmfUh\nxj9XAuCPicFxy204M4fj7dFLLtwQQjRaum1bMX0/H09678AQyEfhPfU03Gefi+nnBRj+WIq3txzo\nyYQhQXLC52J8Poy/LMQy60PM38xFcblQdTrc510Q6P6+6JJGNVZvqJ5rOlio1yj1aV9jrTHs8Uew\nvf4apf97K3Av9jEYl/xG9BWX4LrwYkpnVL++qrHWd7JkwhAN023ZjOXjGVg+nol+9y4AvEnJOIcN\nx3XtsKCPZy6EECekogLLzA/xNW8RGMDpODxn9MfT94zAZCJ/rQ70JDZhEtqNkFJehvnLLzDPmoHp\n98UA+MMjcNxwE85h1+M9rY90fwshNMny6cfoSoqpeGBMjYd6rrj3QaKHDcH28kRKp79fzy1s3CS0\nGwtVxbjkNywzP8T81RwUewUA7gFnB4YUvXQw2GxBbqQQQpwEVcU6/Q1UgwHnjTfX+GWec8/H0ysN\n09w56DduwNe5Sz02snGT0A4y3c4dgRm1Zs1Av30bAL7EdjiHjsY59Dr8ie2C20AhhKgjxkW/YMhe\nj3NIBv4WLWv+QkXBfu+DRN10HbbJEymbMq3+GtnISWgHg8MBH31F1BtvYfx1IYqqolqtODOGBWbU\n6nem9odNFUKIQ1grZ/M61m1eR+MeOAhvSirmz7KoeHAs/vYd6rp5miCh3VBUFcPK5VhmzsD8xWwo\nLcEEeHr3xZk5HNcVVzXOebeFEKIO6HbkYpr/DZ5T0vCm967FCnTY73mAyJG3YHv1ZconTq77RmqA\nhHY9U/LysGTNwjLrQwwbNwDga9kK7hhF4eBr8HVKDnILhRCi/lnfeQvF78dxy+21vpDWdcUQvC88\ni+XjGdjvfwjiU+q4lY2fhHZ9cLsxfTcPy6wPMf34PYrPh2oy4bxiCM7M6/GcfR7xLaPxheD9hUII\ncRi7HcuM9/DHxeG68urar0evx3H3/UTccwfWqa/AG1Prro0aIaFdh/R/rQncUz37E3T79wPg6ZUW\nuPp7yDWoMbHHWYMQQoQey2dZ6IqKqLj3gZMeBMp5zVBs/3ke6wfvwvgnQbHWSRu1QkL7JCmF+7HM\n/gTzzBkY/14DgD8uDvvtd+DMHI6va7cgt1AIIYJIVbG+9QaqXo/zpltPfn0mE/Y77yFi7APw0ktw\n3yMnv04NkdCuDa8X04IfsMycgWn+NygeD6pej2vgIJzDhuO+4KIaDxoghBChzPj7Ygzr/sZ5xRD8\nrVrXyTqd191A2KQX0U2ZgnLzv1GjY+pkvVogoX0C9Js2BgY/yZqFPm8vAN6UVJzDhuO8Zihq8+ZB\nbqEQQjQuVbd53XLit3kdfaVW7KNGE/7UY1jfegP7A2Pqbt2NnIT2cSilJZi/+AzLzA8xrvgDAH9U\nNI6bbgnMqHXKqTKkqBBCHIFu105M33yFp3tPvH1Pr9N1O268mfBXJ2F98384Rt6BGn70STZCiYT2\nkfj9GBf9Ejiq/uYrFIcDVVFwn3t+4J7qgZeCxRLsVgohRKNmee9tFJ8P5621v83rqMLD4Z570D3+\nOJZ338Zx5911u/5GSqbmPIhu+zYss2Zg+WQm+h25AHg7dMSVORzntZn4W7eps22F6pRyB4R6fRD6\nNUp92hfUGp1OmqWlgqqy/8/1YK37q7zjjb7AUM8WC/uX/1Uv2wgGmZrzWCoqMH/1BZaPP8L0268A\n+MPCcVx3A85hwwNdOtL9LYQQJ8T8xWx0+/djH31f/YVpdDTOm0dgmzwRy0fv46zL8+aNVNMMbVXF\nsPR3LLM+xDznc3QV5QC4+50ZuKf6sisCXS9CCCFO3IHbvHQ6HDfdUq+bst9+B9ZpU7G9NhnnDf8K\n+Tt3mlRoK/v2Yf3ofcyzZmDYshkAX9sEKm4fFZhRq0PHILdQCFFrFRWBXjGZwjboDH8sw7hmFa5L\nB+Nvm1Cv21Lj4nD837+wvTEVS9YsnNf/X71uL9iaVGhH3ZhZdQW4c0hGYEatAWfLjFpCaJhu+zas\n06ZinfEBvhYtKJ6/oEndt9sYWae/DtRuNq/acIwajfWdt7C+Mgnn0OvAELrR1qTSyj7qLvyVM2kp\n5WX4UlIlsIXQKMOqlUTcdhOxfU/B9ubrqHo9hq1biLjjNvD7g928Jku3dw/mr+bgTe0amGa4Afhb\ntcY5bDiGrVswz/msQbYZLE0qsdyXX0nRz0twn3Uu5u/mETOgD+bPsqBxX0AvhDjA78f0/TyirrqU\nmIvOwfLFZ/hSu1E69U32r83Bffa5mL+fj+3l/wa7pU2W5d3pKF4vjltHNuhFvPa77kHV67FNnhjS\nX9qaVGgD+NsmUJL1BWUvTEJxu4kceQuRt96IUlAQ7KYJIY7G5cI880Nizj6dqOuvxfTbr7jPOY/i\nrDkU/bQI1zVDwWKh9PW38bVpi+2FZzEu+DHYrW56XC6s77+DPzoa59XXNuim/e3a47r6WgzZ6zF9\n+3WDbrshNbnQBkBRcP7rVgoXLMbT9wzMX31B7Fl9MH0zN9gtE0IcRCkuwvrKJGJP60Hk3aPQb87B\nmTGMwgWLKfnkCzxnn1vtaE5t1ozS6e+D0Ujkv29BVznegmgY5i8/R1eQj/O6/wvKBYH2u+9HVZRA\nT0uI9qA2zdCu5O/QkeIvvqH8qedQysqIuuk6IkaNQCkuCnbThGjSdDtyCRs3hti0boQ/8yRKRQX2\nUaMp/GMNZVOm4evW/aiv9Z56GuXPvICusJDIW/8PXK6Ga3gTZ53+Bqqi4PhXHczmVQu+5M64Lr8S\n4+o/MS74IShtqG9NOrSBwKTq/76Toh8X4Uk7FcunHxNz1ukYf/o+2C0Toskx/LWaiJE3E9unF7Y3\npqJGRlL+xDMUrlpHxZPP4G/Ttkbrcd54M85rMzH+uZLwRx+u51YLAMOKPzCuXIH74kvwt2sftHbY\n73kAgLBJ/wnJo20J7Uq+zl0o/voHKh55HN3+AqKHXU34fXehlJUGu2lChDZVxfjT90RdPZiY8wdg\n+exTfJ1TKH31dQr/WIPjjtGokVEntk5FoezFl/B27Y71/bcxz5pRP20XVapm87p1ZFDb4eveA9dF\nAzEu+x3jkt+C2pb6IKF9MIMB+z0PUDR/Id5uPbB++B4x5/TDuOiXYLdMiNDjdmOeNYOYc84getjV\nmH5diPuscyme9RlFCxfjGnrdyY1uZbNR8vYH+COjiHjoXvR//1V3bRfVKHl5mL/8HG+XlMDYF0F2\n4Gjb9tJ/gtySuiehfQS+7j0omr+AivseRLd7F9FDLiPskQfBbg9204TQPKW0BOurLwcuLhv9b/Qb\nN+AckkHRj79S8ukcPOddUGe3Cvk7dqLstTdQnE6ibh6OUlJcJ+sV1Vk/eAfF48Fx822NYq4G72l9\ncA84B9PPCzCsXB7s5tQpCe2jMZmwjxlH8Tc/4O3cBdtbbxBzXn8My5YGu2VCaI+qYvh9CeH3jyb2\nlK6Ej38cpawM++13BC4ue3063h696mXT7oGDsN99P/ptW4m48/aQvoc3KNxuLO+9jT8yCmfGsGC3\npor9vgcBQu6efQnt4/CmpVP0w6/YR41Gv3UL0YMvJuypceB0BrtpQjR6um1bsf3neWL79CJm8MVY\nP3g3cHHZY08FLi4b/3y9j00NUDHmMdwDzsE8/1tsr0yq9+01Jeavv0Sftxdn5vWNaqIlT78z8fQ5\nHfO8b9Cv/TvYzakzEto1YbFQ8eQzFM+Zhz+xHbYpk4m58CwMq/8MdsuEaHSU0hIsH75H9OUX06xP\nL8L+8zy6/H04M4ZRnDWHwhV/4xh9L2pUdMM1Sq+n9I238bVug23CMxh/XtBw2w5x1jdfr7zNa0Sw\nm1KdomC/t/Lc9uTQOdqW0D4B3tPPoHDBYhw3j8CwIZvogedhe+FZcLuD3TQhgsvrxfTDfCJuu4lm\n3ZOJuO8uDMt+xz3gbEpf+R8Ff+dQNmVaYDAUvT4oTVTj4ih96z3Q64kceTPs2BGUdoQSw+o/MS5f\nhvuCi/B37BTs5hzGfd6FeHqegnnO5+hzNgW7OXVCQvtEhYVRPmEixZ9+ib9Va8ImvkD0JeejX7c2\n2C0TosHp//6LsMcfoVmvFKKuywiMBd42gfJHn6Bwxd+UzP4K17DG023qPa0P5U8/j27/fsjIkIFX\nTlLVbV63NMxsXidMUbDf8wCKqgbGJA8Biqo27rvP8/PLgt2Eo1LKSgl7/BGsM95HNRqpePhRHKNG\n12hauPj4iEZdW20p+/Zhe3UStuVL8aCAwYhqNIKx8r9H+B2jAdVoqnzMUPmYsfIxA6rhoOVNJnyd\nkvCmdgv6ZPehug8POFp9Sl4eltmfYPlkJoZ1gXOF/pgYXFddg/PaTLxp6Y3iCuKjUlUiRo3AMvsT\nHP+6lfIXQvccd32+R5WCApqlpeJrm0DRb8uDMmNijerz+4k5+3QMG7Lxx8XjTe2Gt2tXfKnd8Kak\n4u2SCmFhDdPgGoqPjzjqc6E76WgDUCMiKX/pNdyDLiP8vtGEP/Mk5m+/pmzKG/g6JgW7eQ1KKSnG\nOuUVbNOmotjtYDIF3lweD0o9fC9UzWa83XviOTUdb1o63lPT8XXo1LjDQsscDszzvsb8yUxMC35E\n8ftRjUZcl1yG89pM3BdeHPQvUTWmKJT9dzKWDeuwvvMWntP64GpEVz1rhfXDd1FcLhy33Na4pzjW\n6Sid+hZh/3kOw7p1mH5diOnXhVVPq4qCv137QJindsXbtRu+lK74OnZqlPNyy5F2HVGKCgkf+wCW\nzz5FtVopf/xpnP8acdQ3c8gcpVVUYJ3+BrZXX0ZXUoyvRUvs9z1ExD13kF9S2fXo8wXC2+MGjwc8\nXhSvp/Kxyv8e8vs/j3n/eZ3Xi+JwYMheh+HPlRjW/oXi9VY1xR8djfeUUyuD/DQ8aemozZvXW+kh\nsw+PIj4unOK532H+ZCbmOZ+jqxwd0JN2Ks5rM3FdeQ1qs2ZBbmXtxRfvxZ9+GorXQ9E3Px5zPHPN\n8XiwzHifiJbNKGqRgC8pGTUisk7XH9u7J0pJCYVrsut23SegNp9BpbwMffZ6DOvXoV+/FsP6dRjW\nr0VXWFhtOdVsxpvcBV9qV7yp3fClpuJN7Ya/Vet6Pzg41pG2hHYdM335OREP3YuusBD3gLMpmzz1\niLe0aP4PvtuN5YN3CJv0H3T5+/DHxGC/6z4cN48Am61h6nM6Mfy9BuOfKzCsXIHhzxUYtmyutoiv\nbQLetHQ8lUfjnp6n1Nn5Vc3vw6NQSkuwTp9G2KwPYetWAHyt2+DKGIYzYxi+zl2C3MK6ER8fQcl7\nM4m66Tq8HTpS/N3Chr2ivR5ZX5lE+DNPVnvM17IVvqTkwE9yZ7xJnfEld8bfus0JHymbvvycqFtv\nxH7r7VQ8F7xRx+rsM6iqKPv2YTgoxPXr12HYsB7lkNt7/dHReFO6VoW5N6Ur3tN61+lRuYR2A1Py\n8oh4YDTm+d/ij4ik/JkJgYtxDvp2ptk/+D4f5qxZhP13Avrc7fjDwnGMvAPHv++sNj50sOpTigox\nrPozEOR/rsC4Yjm6gvyq51WdDl+XlECIVwa5N6UrGI0nvC3N7sOjKS/H+vY0bK+9jK64GMLCcF46\nGOe1mXj6DwjaVd/15cD+Cxv/BLZXX8I18FJK3/tI86dYdLnbiR3QBzUsHN2TT2Bf/TeGnE3oczah\nP8JUparNhrdTMr6kJHyVQe5N6oyvUxJYrUfcRtTggZh+X0zhkhX4OiXXd0lHVe+fQZ8P/bYt6NcF\ngtyQvR79+rXot25BOWiQHvvtd1Ax/vk626yEdjCoKuaPPyL80YfRlZXiuvgSyv77CmqLFoAG/+Cr\nKqa5XxL2wjMYNm5ANZtx3HRrYP7auLjDFm809akqul07AwFeeTRuXPUnir3in0UslsD58X5nYh95\n5xHrOZJGU+PJcjiwvjsd26uT0BUU4I+OxjFqNGFjHiA/hMcQqtp/Xi9R116JadEvlD/2FI7R9wa7\naScl8oahmOd/S+lrbxB5x23V36MVFei3bMaQsxH9po3oczZi2LQJ/ZYcFIej2npURcGfkIgvKRlv\nUnJVoOPzEX3NYNznnk/Jx583cHXVBe0z6HBg2JgdOBrP2YTr0ssDF2DWEQntINLt3EHE3aMw/foz\n/thYyl58Cffgq7TzB19VMS78ibDnnsa4+k9UvR7ndTdgv++hY06T2Kjr8/nQb9xQvVt93d8oPh/+\nyCjsDzwcGEP5OBdWNeoaa8LlwvLhe9he/i/6vL34wyMCvSYj70CNjNJ+fcdxcH3Kvn3EXDAA3b48\nSrLmNIpJL2rD9O3XRN2Yibv/AEo+m0t888ia7UO/H92uneg3bawM9E3oDwT7vrwjvqRkxie4LxxY\nxxWcmFB9j0poB5vfj+WdNwl/+nEUhwPnVVdjeWsa+b4T75JtSIZlSwl77ilMixcB4LzqauwPPVKj\n7jDNfZjsdqwz3sP24vPoSorxdkqiYvzzuC+4+Kgv0VyNB3g8WD7+CNukF9Hv3IFqs+G4dST2UXeh\nxv5zYZlm66uhQ+szLFtK9JWXoEZHU/TDr4FzvVpSUUHsgD7o8vZStGAxvs5d6mQfKiXFga71nE2B\nbvZNG/HHxFA+8ZWgXzUequ9RCe1GQr8lh4g7R2JcvgxatqRk0qvHDIVg0f/9F2HPP435+/kAuC68\nmIox4/D16FnjdWj1w6QU7ifsxeewvDsdxe/Hfd4FlD/9/BEvvtJcjT4f5k8/DlyPsH0bqsUSOMVx\n172o8fGHLa65+k7QkeqzvPU6EY88hCe9N8VzvtXObWxQdW7efvf9VDz6BNA092EoOFZoN+Kb60KP\nr2MSxV/Np/yxp6CwkKjrMgi/7y6Uyltpgk2/JYeI2/9F7Hn9MX8/H/cZ/Sn66jtKZ2SdUGBrmRrb\njPIJEylasBj3Wedi+ukHYs4+nbBHH0IpKjz+Chojvx/zF7OJOasvkXeNRLd7F46bR1C4bDUVTz93\nxMBuqpy33I5zyDUYV/xB+BOPBLs5NabPXo/1f6/iS2xHxb0PBrs5oh5JaDc0vT5wocvy5Xi698T6\n4XvEnNMP42+/Bq1Jul07Cb9/NDH9e2P5fDaeXmkUf/w5JV98g7fv6UFrVzD5UrtSkvUFJe/PwpfY\nDtubrxN7ehqW6dPgoHvDGzVVxfTNXGLO7U/kbf9Cv2UzjhtuonDpKsonTMTfslWwW9j4KAplE1/F\nm5KKdfo0zLM/CXaLjk9VCX/4PhSvl/LnXgSbLdgtEvVIQjtYevSgeN5PVNz3ELrdu4i+6lLCHnsY\nDrmCsz4pBQWEjRtL7OlpWD/tuKQGAAAgAElEQVR4F1/HTpRM/4Di7xbiOfd8zd/6ctIUBffAQRT9\nspTyJ54Br4+IsQ8Qc15/jAt/Cnbrjk5VMf0wn+iLziHqpuvQb1iP89pMChevoHziKw0yFaamhYVR\n+vaH+MMjiLh/NPr164LdomMyf/wRpiW/4Rp4Ke6LLgl2c0Q9k3PaQXLwuRjDyuVE3DUSw6aNeJOS\nKXv1dbzpvetsW0px0T8XkmzOQb85B/3mTeg356C43fgSEql4cCyua4bW2QABoXiuScnPJ2zCeCwf\nvhcYmnXwYAofebLxDFmrqhh/WUjYC88GrpsAnFcOwf7gI4FbdU5QKO7Dgx2vPtNXc4i65Qa8nZIC\nA68EadSvY1GKContl47icFC46I/DvpA19X2oVXIhWiN02JvN4SDsuaexTpsamJnm7vuw3z+m5hfC\nuN3ot22tCmf9lpzAlZ6bNwVmNDqEPywcX3Iyzmszcd7wLzCb66iygFD9MAHo/1pD+LgxmBYvQjUa\ncYz4N/b7Hqw2uExDM/6+GNuEZ6qu9HcNupyKhx7B17VbrdcZyvsQalZf2JOPYZv6Cq5LB1P69geN\nrvcp/IF7sL7/NuXjnsZx1z2HPS/7UJsktBuho73ZjIsXETH63+hzt+Pt1oPS1974Z0xkVUWXt/ef\nYK48YjbkbEKXu73aCD0Aql6PL7FdYNjCTsn4OiVVDWPob96iXv8AheqHqYqqEv/r9/juuz8wMlxc\nHBVjH8d53Q0NOnKYYcUfhE14BtPPCwBwXXAR9ocfxdsr7aTXHer7sEb1eb1EXTMY0+JFVDw4FvuD\nYxumcTVgWPEH0YMuwNclhaIfFx1xVD/Zh9okod0IHevNppSXEfbEo1g/eBfVaMR9wcWBgQ8256Cr\nKD9seX9cHL5OlaMWdfwnmH3t2gftlpVQ/TAdLD4+gvwd+dhefw3byxNR7BV4uvek4pkJePqdWXcb\ncrvRb98W+JJW2Yty4FSHLn9fYJGzzqXi4Ufw9u5bZ5sN9X1Y0/qUffuIGXQ++tztlE6eiitzeAO0\n7ji8XqIvOgfj32so/nIentP7HXEx2YfaJKHdCNXkzWb68TvC77kTfd5eVIsFX4dOgSEFOyX9c9Tc\nKQk1OqaBWl1zofphOtjBNer27iHs2aewfPwRAK7LrqD8ifH427Wv2coO7kU5JJz1udtRfL7qi+t0\n+BMS8XbtjuP2UXX7JaFSqO/DE6lPv2kj0ZddiFJaSsmMT/Ccd2E9t+7YrNOmEv7YGJxDr6Ps1deP\nupzsQ22S0G6EavxmczrRFeTXaiaeYArVD9PBjlSj4c8VhD82BuMfSwPjs4+8E/vd96GGBz6ESnnZ\nP6FcdUHg5mP3onRMqt6L0ikJX/sOdX4dQk3qCyUnWp9h6e9EZwwGnZ7iOd/UySmI2tDt3UNMv9PA\noKdw8cpjjpUv+1CbjhXajW+Gb1GdxSK36GiINy09MAf1558S9vTj2CZPxDxrBr5OSYGQztt72GtU\nqxVfh054OiXhTUqqFs6NsRelqfL2PZ3SqW8RecsNRF2XQdE3P9S8J6UOhY0bi668jLL/Tq7x5DYi\ndEhoC1HXFAXXkAxcAy/FNmVyYKrLJb/hT0jEfe75lac3kquCWWu9KE2Z+7LBlD/7AhGPPETUsCEU\nf/19tfHa65txwY9Y5nyGJ703zuE3Nth2ReMhoS1EfbHZsD84FvsddwdC2WIJdotEHXDeOhL9rl3Y\npkwmavhQimd/ddR5p+t2w07Cx9yPqtNR9uJL8kWviZK9LkR9s9kksENMxbinAmOUL19G5Mhb4JAL\nBeuD7dWXMGzdgmPEyCYzF4A4nIS2EEKcKJ2Ossn/w33mWZi/nUv4ow9BPV7Tq9uyGdsrk/C1bIX9\nIe1MZCLqXq1C2+PxcP/995OZmcnw4cPZsWPHYctkZ2czZMgQhgwZwpQpUwDwer08/PDDZGZmcu21\n17J8+fKTa70QQgSL2UzpOx/iTe2K9e03sb42uX62o6pEjLkfxeWiYvzzjXI4VdFwahXac+fOJTIy\nkpkzZzJy5EgmTpx42DLjxo1j/PjxfPrpp2zevBmHw8GcOXOwWq3MnDmTZ599lgkTJpx0AUIIESxq\nVDQlM2fja92G8PGP18usYKavvsC08Cfc55yHa/BVdb5+oS21Cu0lS5Zw4YWBwQX69evHypUrqz1f\nUFCA3W6nW7du6HQ6Jk2ahNVqZfDgwYwdGxgGMDY2luLi4pNsvhBCBJe/dRtKZs7GHxlFxOh/Y/xl\nYZ2tWykrJfyxMahmM2UTJja6sc9Fw6tVaBcUFBAbGxtYgU6Hoii43e6q53ft2kVUVBRjxoxh2LBh\nvPvuuwAYjUbMlQNCvPfee1x22WUn2XwhhAg+X2pXSt/7CBSFyH8NR7/27zpZr+3F59Dv3YN99H34\nO3aqk3UKbTvuLV9ZWVlkZWVVe2z16tXVfj90UDVVVdm5cydTpkzBYrEwdOhQ+vfvT3JyMgAzZsxg\n7dq1vP760YffOyAmxobB0HATMDSkY416EwpCvT4I/RqlvhNw5SB47z2UzExir78Gfv8dEk5iYKRV\nq+DN1yEpibCnHyeslncgyD4MLccN7YyMDDIyMqo9NmbMGPLz80lJScHj8aCqKqaDJqZo1qwZycnJ\nxMQERnNKT09n06ZNJCcnk5WVxU8//cTUqVMxHmFWmkMVFdlPtCZNCNXh9w4I9fog9GuU+mrh/Eux\nPvEM4U89hveiiyn+aj5qVPSJr8fvJ/rW2zD6/RQ/+x88ZR4o85zwamQfatOxvojUqnu8f//+zJs3\nD4AFCxbQt2/1mYUSEhKoqKiguLgYv9/P+vXr6dixIzt27GDWrFm89tprVd3kQggRShyj7sI+YiSG\n7PVE3ngduFwnvA7LjPcxrvgD5xVD8Jx7fj20UmhVrUZEGzRoEIsXLyYzMxOTyVR1Ffi0adPo3bs3\naWlpjB07lhEjRqAoCgMGDCAlJYVJkyZRXFzMbbfdVrWu6dOnVztKF0IITVMUKp5+Hv2ePZjnziHi\nztspe+PtGo9gphQUEDb+cfzhEVSMf76eGyu0Rmb5CpJQ7dY5INTrg9CvUeo7SQ4H0RlXYFz2O/Z/\n30XFU8/W6GURo/+NZdYMyp+ZgOO2USfVBNmH2lTn3eNCCCGOw2ql5INZeJM7Y/vfq1inTT3uS4y/\nL8Yyawae7j1x3HzbcZcXTY+EthBC1BM1JjYw+ErzFoSNG4vpqy+OvrDHQ/hD96IqCuUvTgKDzOck\nDiehLYQQ9cif2I7SmZ+i2sKIHDUC4++Lj7ic9fUpGLLX4xx+E97T+jRwK4VWSGgLIUQ98/boRenb\nH4DPR+QNw9BvyK72vG7nDsImTsAfF0fFY08EqZVCCyS0hRCiAXjOPZ+ySa+iKykmKvNqdHv3VD0X\n/ujDKHY75Y+PR42JDWIrRWMnoS2EEA3ENex6KsaOQ79zB1GZ16CUlWL67lvM387FfUZ/XEOvC3YT\nRSMnVzoIIUQDst/zALpdu7C+/zaRNw1Hv30rqsFA+QuTZEIQcVwS2kII0ZAUhfIJ/0WXtwfz/G8B\nsN95D76U1CA3TGiBdI8LIURDMxgoff1t3GeehTe1GxX3PxzsFgmNkCNtIYQIhrAwSmZ/BX4/6ENz\nJkNR9+RIWwghgkVRJLDFCZHQFkIIITRCQlsIIYTQCAltIYQQQiMktIUQQgiNkNAWQgghNEJCWwgh\nhNAICW0hhBBCIyS0hRBCCI2Q0BZCCCE0QkJbCCGE0AgJbSGEEEIjJLSFEEIIjZDQFkIIITRCQlsI\nIYTQCAltIYQQQiMktIUQQgiNkNAWQgghNEJCWwghhNAICW0hhBBCIyS0hRBCCI2Q0BZCCCE0QkJb\nCCGE0AgJbSGEEEIjJLSFEEIIjZDQFkIIITRCQlsIIYTQCAltIYQQQiMktIUQQgiNkNAWQgghNEJC\nWwghhNAICW0hhBBCIyS0hRBCCI2Q0BZCCCE0QkJbCCGE0AgJbSGEEEIjJLSFEEIIjZDQFkIIITRC\nQlsIIYTQCAltIYQQQiMktIUQQgiNkNAWQgghNEJCWwghhNAICW0hhBBCIyS0hRBCCI2Q0BZCCCE0\nQkJbCCGE0IhahbbH4+H+++8nMzOT4cOHs2PHjsOWyc7OZsiQIQwZMoQpU6ZUe66goIDevXuzdOnS\n2rVaCCGEaIJqFdpz584lMjKSmTNnMnLkSCZOnHjYMuPGjWP8+PF8+umnbN68GYfDUfXciy++SEJC\nQu1bLYQQQjRBtQrtJUuWcOGFFwLQr18/Vq5cWe35goIC7HY73bp1Q6fTMWnSJKxWa9Vrw8LC6Ny5\n80k2XQghhGhaDLV5UUFBAbGxsQDodDoURcHtdmMymQDYtWsXUVFRjBkzhm3btjFw4EBuuukm3G43\nU6ZMYerUqTz33HM12lZMjA2DQV+bZjZ68fERwW5CvQr1+iD0a5T6tC/Uawz1+g513NDOysoiKyur\n2mOrV6+u9ruqqof9vnPnTqZMmYLFYmHo0KH079+f+fPnk5GRQWRkZI0bWFRkr/GyWhIfH0F+flmw\nm1FvQr0+CP0apT7tC/UaQ7W+Y30ROW5oZ2RkkJGRUe2xMWPGkJ+fT0pKCh6PB1VVq46yAZo1a0Zy\ncjIxMTEApKens2nTJhYtWoTf72fGjBnk5uayZs0aJk+eTHJycm1rE0IIIZqMWnWP9+/fn3nz5jFg\nwAAWLFhA3759qz2fkJBARUUFxcXFREZGsn79eoYOHcqsWbOqlhkzZgxXXXWVBLYQQghRQ7UK7UGD\nBrF48WIyMzMxmUxMmDABgGnTptG7d2/S0tIYO3YsI0aMQFEUBgwYQEpKSp02XAghhGhqFPXQE9KN\nTCier4DQPRdzQKjXB6Ffo9SnfaFeY6jWd6xz2jIimhBCCKEREtpCCCGERkhoCyGEEBohoS2EEEJo\nhIS2EEIIoRES2kIIIYRGSGgLIYQQGiGhLYQQQmiEhLYQQgihERLaQgghhEZIaAshhBAaIaEthBBC\naISEthBCCKEREtpCCCGERkhoCyGEEBohoS2EEEJohIS2EEIIoRES2kIIIYRGSGgLIYQQGiGhLYQQ\nQmiEhLYQQgihERLaQgghhEZIaAshhBAaIaEthBBCaISEthBCCKEREtpCCCGERkhoCyGEEBohoS2E\nEEJohIS2EEIIoRES2kIIIYRGSGgLIYQQGiGhLYQQQmiEhLYQQgihERLaQgghhEZIaAshhBAaIaEt\nhBBCaISEthBCCKEREtpCCCGERkhoCyGEEBohoS2EEEJohIS2EEIIoRES2kIIIYRGSGgLIYQQGiGh\nLYQQQmiEhLYQQgihERLaQgghhEZIaAshhBAaIaEthBBCaISEthBCCKEREtpCCCGERkhoCyGEEBoh\noS2EEEJohIS2EEIIoRES2kIIIYRGSGgLIYQQGiGhLYQQQmhErULb4/Fw//33k5mZyfDhw9mxY8dh\ny2RnZzNkyBCGDBnClClTqh6fPn06V1xxBVdffTVr1qypfcuFEEKIJqZWoT137lwiIyOZOXMmI0eO\nZOLEiYctM27cOMaPH8+nn37K5s2bcTgcbNq0ia+//prZs2fz9NNPs3DhwpNtvxBCCNFk1Cq0lyxZ\nwoUXXghAv379WLlyZbXnCwoKsNvtdOvWDZ1Ox6RJk7BarSxYsIBLLrkEg8FAt27dGD169MlXIIQQ\nQjQRtQrtgoICYmNjAyvQ6VAUBbfbXfX8rl27iIqKYsyYMQwbNox333236vE9e/Zwyy23cOONN5Kd\nnX3yFQghhBBNhOF4C2RlZZGVlVXtsdWrV1f7XVXVw37fuXMnU6ZMwWKxMHToUPr374+qqvh8Pt56\n6y1WrFjBo48+yuzZs4+5/ZgYGwaDvqb1aEp8fESwm1CvQr0+CP0apT7tC/UaQ72+Qx03tDMyMsjI\nyKj22JgxY8jPzyclJQWPx4OqqphMpqrnmzVrRnJyMjExMQCkp6ezadMm4uLi6NixI4qicNppp7Fr\n167jNrCoyH6iNWlCfHwE+fllwW5GvQn1+iD0a5T6tC/UawzV+o71RaRW3eP9+/dn3rx5ACxYsIC+\nfftWez4hIYGKigqKi4vx+/2sX7+ejh07ctZZZ7Fo0SIANm/eTKtWrWqzeSGEEKJJOu6R9pEMGjSI\nxYsXk5mZiclkYsKECQBMmzaN3r17k5aWxtixYxkxYgSKojBgwABSUlIA+OWXXxg6dCgAjz/+eB2V\nIYQQQoQ+RT30hHQjE4pdHxC63ToHhHp9EPo1Sn3aF+o1hmp9dd49LoQQQoiGV6vucaFtfr/Kxh3F\nrN1WSJv4MHp1isNqlreCEEI0dvKXuolQVZWte8pYui6PZdl5lJT/c1+9Qa/QvUMz0rvEc0pyHGEW\nYxBbKoQQ4mgktEPczvzyQFCvzyO/2AlAmMXAWb1a0Sspjh155SzfkM+qnAJW5RSg1ymktoshvUs8\naZ3jibSZjrMFIYQQDUVCOwTtK3awbF0eS9fnsSu/AgCzUc/pXVvQp2sLuneIxaAPXM6QlhzP4DM7\nkFdoZ/mGfSzfkM/fWwv5e2sh78/fQJeEaE5Lac6pneOJDjcHsywhhGjyJLRDRFGZiz+y97F0XR5b\n95QCgW7vtOQ4+nZtQa+kOMzGo48s1yLWxqVntOfSM9qTX+xgxYZ8VmzcR3ZuMdm5xcz4biNJbaNI\n79Kc07rEExtpaajShBBCVJLQ1rByh4flG/axbF0eG3KLUQGdotCtQyx9U1twauc4bLU4Px0fbWVg\n30QG9k2ksNTJyo35LN+Qz6YdxWzaWcKsHzfRoVUkp6XEk96lOc2jrXVfnBBCiMNIaGuMw+Vl1aYC\nlq7PY+3WQnz+wG32SW2j6Jvagt4pzYkMq7vz0LGRFi44LYELTkugpNzFyk0FrNiwj+ztxWzdU0rW\ngs0kNg8nPSVwBN6qWVidbVsIIUR1Etoa4PH6WLN5P0vX72NNTgFurx+AxBbh9O3agj4pLWgWVf/d\n1VHhZs5Na8O5aW0os7tZtamA5RvyWbetkNxftvD5L1toExdGepd4Lj2rE3INuhBC1C0J7UbK7fGx\ndmth5ZXd+ThcPgBaxtoCQZ3aPKhHtRE2EwN6tWZAr9bs2V/Bxz/lsGbzfnYVVLCroIIFf+5m8ugz\ng9Y+IYQIRRLajYjD5WX15gJWbshnzZb9uD2BI+rYSDNnn9KGvqktSGwRjqIoQW1nSYWbDblFZOcW\nsyG3iD37/5mJzWzSk9w2iotObx+8BgohRIiS0A6yA93MKzYGupm9vsA56hYxVtK7NCe9SzztW0YE\nNahLK9xs2FFM9vYisg8NaaOe7h1iSWkXQ5fEaNq1iMCg14XsmMBCCBFMEtpBUFTmYtmGfH5euZMN\nucX4K+dsSWgeTnrneE7tEk+buLCgBXWp3c3G3GLW5xaxIbeY3QUVVc+ZjDq6dYglJTGalMQY2rWM\nqLrnWwghRP2S0G4g+4odrKy893nzrtKqxzu1juTULvGc2jmeFjG2oLTtQEhvyC0mO7eIXYeGdPuY\nyiPpGNpLSAshRNBIaNcTVVXZXVDBio35rNiQz4595QAoCqQkRnN2egLJrSKCMkhJmd3Nxh3FlQOn\nFFWNmgZgMujo2j6GlMTAT/tWEtJCCNFYSGjXIVVV2ba3rHI0sXzyCgPnfvU6hZ6dmnFq58CEHJE2\nU4Oe8y13eNhQedFYdm4ROw8J6dR2gSPplMRoOrSKlJAWQohGSkK7DjhcXuYs2sryDfsoLHUBgW7l\n9C7xpHeOp2enOGyWhvunLnd4Ko+kA+ekd+4rR618znggpBOj6ZIYQ4dWkRgNEtJCCKEFEtonyevz\nM/Xzv1i7rQir2cAZ3VqQ3qU53TrEHnOs77pU4fSwsXKM8A25Rew4KKQNeh1dEqMrj6QlpIUQQssk\ntE+Cqqp89P1G1m4rolenZtwxpEeDdC3bnR427PjnwrEdeUcI6cTALVgdW0diNDTMlwchhBD1S0L7\nJHz/xw4WrtpNYvNwbr+iW70Ftt3pYeOOkqru7ty8soNCWqFzQnTVOWkJaSGECF0S2rX056Z8Pv4p\nh6hwE6Ov6YnFVHf/lHanl407i6tGHcvNK6PyVm4MeoXkhOiq+6Q7to7E1EDd8EIIIYJLQrsWtu8t\nY9qX6zAaddx9Tc+Tvm3L4fKy8aDu7u0HhbRep5DcJoouiYErvDtJSAshRJMloX2CispcvDJ7DW6P\njzuG9KB9y8gTXofD5WX5+jyW/rWbDblFbNtbPaSTKkM6NTGajm2iGuyCNiGEEI2bhPYJcLl9TP50\nNUVlLjLO7cSpneNr9DqHy0vOrpLKsbuL2b63rGroUr1OoVObqKru7k4S0kIIIY5CQruG/H6VaV+t\nJTevnLN6tWJgn8SjLut0e8nZWVI1dve2PdVDumPrSNJSmpMYH0ZS6yjMJglpIYQQxyehXUOfLtzM\nn5sKSG0Xw/CLulSbzMPpDhxJb8gNzIS1bW8ZPv8/Id2hdUTVsKBJbQIhLbNgCSGEOFES2jXw86pd\nzFuWS8tYG6Ou6o7Pp7Iht5DsymFBt+35J6R1ikKHVhGVF45Fk9Qmqk6vLBdCCNF0SZocx9pthbw3\nbwMAiS3CmZy1hq17SquFdPtWEXRJjCa18py01Sz/rEIIIeqepMsRuDw+Nu8qYcGfu1ixIb/q8WXr\n96FTFNq1jAhcONYu0N0tIS2EEKIhSNoA7sqQPjB295Y9pXh9arVlBvZNJCUxhuS2EtJCiJNXVOZi\n5g8bKShx0ie1BWd0b0lUmCnYzRKNXJNMH4/XR86u0qoRx7bsLqkKaUWBNnFhVdNXXnBaW667oHMw\nmyuECDFL1+Xx4XcbqHB6UYBte8v4dOFmenZqRv8ereiV1EymyBVH1KRCe3n2Pn5csZPNu0vx+vxA\nIKQTW0RUTVXZuW0UH36/kZ35FfRJbU7m+clBbrUQIlSUOzx8MH8Df2Tvw2TUccPFXeid0pyl6/JY\n9NceVuUUsCqngHCrkdO7teDMHq1IbBER7GaLRqRJhfbCVbvYsKO46nedotAntTk9OjUjuU0UzaIs\nfPXbNn5fm0enNpHccmlqtVu7hBCittZsLuCdb7IpqXCT1CaKWy5LpUWMDYDz09tyfnpbduwr57e/\n9rBk7V5+WL6TH5bvJLF5OP17tuL0ri2IsEn3eVOnqKqqHn+x4KnLe5mdbi/ZucVs3lXCpp0lbN1T\nisfrP+Ky92T0pGv72Hrrogr1+7RDvT4I/RqlvrrhdHv5+Kccfl61G71O4aqzOjKwTyI63dEPCLw+\nP2s27+e3v/awZvN+fH4VvU7hlKQ4+vdsRY+Oseh1x//bJPtQm+Ljj9670qSOtC0mA6ckxXFKUhwQ\n+GBszysjZ2cJ85blUlLurlr25aw1mIw6OraKJKltFEltoklqE4nNYgxW84UQGrNxRzHTv15HfrGT\ntvHh3HpZao26uw16Had2jufUzvGUVrhZsnYvi/7aw4qN+azYmE9kmIl+3VrSv2cr2sSFNUAlorFo\nUqF9KINeR6fWUUTaTHzz+3Z0isL1F3XGbNSRs7OETQdGOcstBrajAK3jw0huExUI8rbRxEdZpAtd\nHFV+sYPpX68nNsLMZf3a01r+wDYJHq+Pz3/dyvyluaDAoNPbccWZHTAaTrznLjLMxMV9ErmodwLb\n88pYtGYPS9flMW9ZLvOW5dKhVSRn9mxF39TmclDRBDSp7vEjsTs9PPvBCvbst3PDxV04N63NYc/n\n7ColZ1cxOTtL2LKnFLfnny71qDATSW2iSE6I5swerbBZavY9KFS7dQ4I9frg+DVu3VPK5KzVlNo9\nAChA79TmXN6vPW3iwxuolbUX6vuwvurLzSvjzbnr2JVfQfNoK7de1pWktlF1ug2P18eqnP0sWrOH\nv7fuR1UPHJ3HcWbPVnRtF4tOp8g+1KhjdY836dD2+vxMzlrN2m1FXNQ7gWE1uFLc6/OzY1951ZF4\nzs5iiiu71ZtFWhhxeVc6J0Qfdz2h+mY7INTrg2PX+OemfN74ci0er5/rLuhMbKSZOYu2kptXjgKk\npzRncP/2tG1k4e3x+lmxcR+//bWXcJuJnh1jOSUpLiTHJqjr96jP7+fb33OZs2grPr/KuWltyDi3\nU70PY1xU5mLx33v47a+97C20AxATYaZf95ZkXNgFv9tbr9sPplD9OyOhfQSqqvLB/A0sXLWbU5Li\nuHNIj2NeGHKs9ewvdfLzqt188/t24J+usGNdxBaqbzavz8+2PWXYwsw0jzSF9L2mR9uHP67YyUc/\nbMSo13H7Fd1ISw5M4aqqKqtz9jPnt61s3xt4XXqXeAb370BC8+CGd16RnZ9X7WbRmj2UOzzVnjPo\ndfTs1Iw+qc3p1SkuZGalq8vPYF6hnbfmrmPz7lKiw03cPCiV7h2b1cm6a0pVVTbvLmXRmj38kZ2H\nw+XDZNRz4WltuaRvuxr3AmpJqP4dldA+gu+W5TLrpxwSm4czZvipdfJteNPOYt78ah0FJU7at4zg\ntsHdaBlrO+KyofJm83j9bN0TGKhmw45icnaVVJ0+iLAZ6du1Bf27tyKxRXjInfs/dB/6VZWsBTnM\nX7aDSJuRuzN60aFV5GGvU1WVNZv38+VvW9m6pzK8O8dzef/2DXpPrtfnZ3VOAQv/3MXabUUAhFuN\nnNmzFWef0pqoKBvfLd7Ksux97C4IDDZkMujomRRHn5TArZJanvu9Lj6DflVlwcpdZC3Iwe31c3rX\nFlx/UWfCgnxu2eXxseTvvcxdso3CUhdhFgOX92vPuae2rdV59cYqVP6OHkpC+xB/bsrntdl/ERlu\nYtz/nUZspKXO1u1weZnx/UYW/70Xk1HHsPOTObtX68MCS6tvNrfHx5bdpWTnFrFxRzGbd1e/ba5N\nXBidE6MJs5pYuHJn1VFbm7gw+nVvyendWhITYQ5W8+vUwfvQ7fHx1tx1LN+QT8tYG/de24v4aOsx\nX6+qKn9tKeTL37ayZYTebVkAABnkSURBVHcpAGnJcQzu34F2LesvvPeXOPll9W5+WbO76o6JzgnR\nnJPWmvTOzav+qB9c3878cv5Yv49l2fvIq+yCNRv1nJIcR++U5vToGIvRoK0AP9nPYGGpk3e+Wc/a\nbUWEWQz838AUeqc0r8MWnryIKCuz5q3nm9+343D5aBZp4aqzOnB615a16lmsbz6/H52i1PgLvlb/\njh6PhPZBtu8tY8KMlaiojLn+VNq3PPxIqC4sW5/H+/M2YHd5SUuO48ZLUog8aGAErbzZXG4fObsD\nV9FvPGRcdgVoEx9eOZpcNMkJ0VU1xsdHsGdvCX9t2c/iv/eyOqcAr09FUaBr+1j6dW/Jqcnxmu5q\nPbAPy+xuXp39Fzm7SuicEM2dQ3oQbq35kZaqqqzdWsicRVvZXBnepyTFMfjM9nX2/vT7Vf7eup+F\nf+5m9eYCVBWsZgP9u7fk7LQ2R7xt6EjvUVVV2bGvnD+y97FsfR75xU4ArGY9pyTF0zu1Od071N/4\nBnWptp9BVVX5fW0eH36/EYfLS89OzbjpkhSiwxvfl9EDNZY7PMxdvI2fVu7E61NpGx9Oxrmd6N4h\nNug9YH6/ytpthfyyajercgpoGWvjvPS2nNGtxXF7QLXyd/RESWhXKipz8f/t3XtUlNe98PHvMNwE\nuQy34Q6KKDdRUOQW8RZTMWrTnNjoOtb6HtOkxsSaZWrQNNWuvK0x0bR5m6y2etJmNUmbHrUrtcZG\nE2OMCqKCgoAoeOHOcB3uMMzM8/4xMg0KCjgwM5z9+Y95Bti/tZ95fvPs/ezf/r9/voi6rYeNT04n\nfqq3yf72QJpau/nvI0UUl6txc7bnvx6PZPqdeS5LPdm6NVpKK1u4VqHmWrm63zakMhkE+xi2IZ0W\nZEjSgyWnu+Nr7+rlQnEdmQU13KgyJCYHezmzp3mTEuPHtGB3bKxs+Nzb24XC6yp+/T95qJq7mBPp\nw/rHo0Y8/ChJhovX4TO3Ka1qAWBGmCcrHpk04DD7ULS093A6v4ZTl6tpbDUk2El+rsyP82dOpPK+\nw9sPOkclSeJ2bRsXiuu4cLXO+PedHGyJm+rFnEglkSEKi03gI/kMtnZq+PDYNXKu1eNgL2f1onDm\nxvqZPfEN5u4YG1q6+PT0LbIKapGAiGB3Vi6YMuLz62E0tnRzOr+aM1dqaGrtAUCpmEBDSzc6vcQE\nB1vmxvqxMD4AH8X4nma8m0jad7z9P5cpuNnEygVhpCeGmOzv3o9ekjh+voJDp26g00ssig9k5YIw\nAvzdLeJk6+rRUlKpvrPDmZqy2jb00r/3Cg/xnci0IIXhTjrQ3SRL2lRNnWQW1JJVWEtDi+FC7+Hq\nQHK0Lykxvvh5Wsda5sbOXn6x/xztXb0sTQrhyXmTTfLFQ5IkisqaOXzmFiWVhuQdG+bJitRJTPZ/\n8MVVL0kUlzXz9aUqLpU0oNNLONjJSYpWMn9mwJCH3odzQZQkiZvVrYYEXlxHc5vhIuzsaMusad4k\nRCqJCHYfUhWvsTLcC/7lkgY++LyY1g4NUwPd+K9lUfg8YArE3AaLsaKunUOnbpB/oxGA2RE+/Efa\nZJSDPINjKlqdnsslDXyTX03hzSYkDF/ek6KUpM3wJ9TXhZYODV9fquLU5WpaOjTIgOlhniyaFUj0\nJI9+nzGRtC2QKTvk+PlyerR6liWHjPk343JVG384XEhNYyf+Xs68sjYBF3vzXMBaOjRkF9aSfbWO\n27Wt9J0BchsZoX4uxiT9MHuFD+XDpJckSirUZBbUcqG4jm6NDjDcCabE+JIYpRzWMPNYyrlWx/5/\nFtGr0/ODx6Yx/671/aYg3Um+/zh7m+t3auZPn+zJikdCCfO/d91ve1cvZ/JrOHW5ClVzFwCB3s4s\niAsgKdp32H050guiXpIorWzhQnEdF4vraOkwzJu7ONkxa5oPiZE+TA1yN/vd6VDja+nQcOjUDc7k\n12Arl/FkWhiPJQRZ5Jzw3R4UY3FZMwe+vsGtmlZsZDLmzfRnRWoobiYe6q9p7OB0fg2ZV2qMdQvC\nAlxJm+FPQoTPgMPgWp2+3yZPAEoPJxbGB/DIdD8mONiKpG2JxlOHaHp1HPj6BidyKv/94Z8TNCbD\nwr1aHZdKGsgsqKXgZhN6yVDLeLK/653hbgVTAtxMNsc83A9TT6+Oy33tu1MsQm4jIzbMk5QYy9qq\n8PiFCv52ogQHezk//m40sWFeo/4/i8ua+ceZW8YNb2ImebDikUmE+btSWtXC15equFBcj1anx1Zu\nw5xIH+bHBRDm7zri5GiSp6v1Etcr1IYEfq2OtjsX7CCfiaQnBZMQ4WO2u+8HxdfY0s3n58v5Jq+a\nXq2eYOVEnlkWZXFr6+9nKH0oSRI51+o59M1NVE2d2NvZ8J2EYJYkBj/U+vyeXh051+r45nI11++M\nGE2cYEdKjC9zY/2GVWDoVk0rJ3IqOX9VhVYn4WAvJzXGl6cenYajGU4frU5PWW0bJZUt3K5tJSna\n11ge2xRE0rYw+Tca+eDzYtRtPUQEu/PMsiiTPsHeR5IkSqtaOHvFcCfb1WMosjDJz4WUGD/mRPqM\n2q5BD3PBV7f3cK5QRWZBjXFfc2dHW+ZEKUmJ8WWy38gT0cPQ6yU+OVHClzmVuDnbs/PZZNwcxvZB\numvlhuRtKK1rKKLRNxSt9HBiwUx/Uqb7mWSEYjSKj1wrV/NNXjUXiuuQJPBycyQ9MZjU6X7Yj/Hy\nscHiq23q5Oi5MrIKatHpJTxdHVmSGMy8mf4W88VxqIbTh1qdnjP5NfzjzC1aOjRMnGDH8tRQFsQF\nDCvuclUb3+RVk1WoMl5zokIVpM3wJy7c+6GWnLV2aPgmr5qTl6qM5310qIJFs4KIDfMctdGPju5e\nSitbKK1qoaRCza3atn6rZp5Mm8yylFCT/T+RtC2Q/QR79nx4kculDTg52LJ2yTTmRCpN8rfr1V2G\nOeOCWurUhmFShYthzjg5xndMNhgw1QW/XNVGZkEt54pUtN4ZZvVRTCAxUklilHLMann39OrYd7iQ\nSyUN+Hs5s3llLJFTfMx2fl6vUPOPM7corWph5hQv5scFEBFs2iHn0Rx6rGvu5Nj5Ck7n16DV6XF1\nsmNxQhAL4gLGrH723fGVq9r4LKuMi8V1SICvhxOPJ4eQGKW0umTdZyR92KPRcfxiBf86V0a3RoeX\nmyNPzpvMnEjloKOCXT1asotUnMqrNhYOcp9ozyOxfjwS62/yuX+dXs+l6w2cyq+h8KZhXt7LzZGF\n8YHMneH3UOvkJUmioaWbkkpD6eqSyhaq7tQpAMOqmUCfiUwJdCM80I3wAHc83Ux70yWStgXy9nah\nrq6VU3nVfHKiBE2vnpQYX/5z8dQRDUl1dmu5eK2OzCs1xqEoezsbZk31IWW6L5HBijGdgxuNu7TC\nW81kFtRwubTBWMAl2GciiVFK5kQqTf7B6dPaoeH/HcrnZnUrEcGGJV1Ojnbjdj6tz1jE19Kh4cuL\nFXyVW0lXjw5Heznz4wJYPDto1Nfz98VXWtXCkczbxoeygpUTWZYcSvxUb6uYt76fh+nDtk4NRzLL\n+Cq3Ep1eIlg5kZXzpxA9yQP490he38iJptewxjo2zJO0Gf5MDxva9qEPw9vbhZyCar7KreRcoQqN\nVo+9rQ3JMb4sig8kcAiVBnV6Q2nqkgpDaeqSSnW/HR/7dnsMD3QnPNCNyf5uo15dTiRtC/TtD1Nt\nUyf7Dhdyu7YNLzdD/fLwwAfXL9fp9RTdbubslRoulTTQq9UjAyJCFKTE+DJrmveo1z0ezGhe8Ls1\nWi6XNpBdqKLgVpNxSVp4oBuJUUpmR/j0WxP/MGoaO/jNgTzq1d0kRyv5P0sjjXddImmbTme3llOX\nqzh+oYKWDg22chkpMX6kJwaPyhPNkiRRre7m439dNU41hAe6sSwl1CLWLpuKKfqwXt3Fp6dvcq5Q\nhYRhqDsyREFmQS01jYZCO15ujqTN8Cd1ut+YFk/6dnztXb2czq/mZG6VcVVKRLA7C+MDiZvqZfwC\n0dWj5UZ1i/Eu+mZ1Kz29OuPfdHO2v3MXbUjSQT4Tx3ykRSRtC3T3h0mr03P47C0+yzLUL388OZQV\nqaEDniwVde1kFtRwrlBlfDJX6eFEaowvydG+o3bHORxjdcFv7+ol51od2UUqrpWrkTAsVYsKVZAY\npSR+qveIH6a5XqHmt4fy6ejWsiwllO/NndTvYi6Stun1anVkFtTyr+xy6pq7DJurTPMmPSnEJGuJ\n9ZLE5ZIGPsu6bSwhGzPJg2UpoUPa6MfamLIPy1VtHDx1g4KbTQDYymXET/UmbYY/ESEKs9RZGCg+\nvV4ir7SBE7mVFN0pz+vh6kBUqAfltW1U1Lfz7azn7+VMeKCbcbdGS9huWSRtCzTYh+l6haF+eWNr\nN5P8XHl2eRRKDyfjMq3MglrK69oBy3g4azDmuOA3t/Vw4aqK7Ksq4wXZztaw2UVipJIZUzyHXGrz\n/FUV/33kKnq9xA+XTGPuDP973iOS9ujR6yVyrtdzNKuMMpWhDVGhCtKTQogKUQz7XNfp9Zy/WsfR\nrDLj/GTydD8WzwoYtaqIlmA0+vBaeTN1zV3ETfU2+5LMB8VX3dDBidxKMq/U0tOrw1ZuwyQ/F8ID\n3ZlyJ1GbO4aBiKRtge53snV2a/n4i2tkFapwsJMzJcCVq2Vq4zItwzIoX2LDvCy2+L+5E5qquZPs\nIhXZRSrjEJ6jvZxZU71JjFISGaoYcL5NkiQ+P1/OgZM3cLCXs/GJmEF3azJ3jKPNEuLrKzRzNKuM\nq2WGu6YQXxceTwoZ0pxzr1bP2YIa/nWujHp1NzYyGUnRStKTQpgZ6Wv2+EabJfThaBpqfJ3dWurV\nXfh7OVvsNfPbRNK2QEM52bKLVHx4zFC/PNTXhZQYX+ZEKU02XzuaLOVi0VcrO7tIxfmrKhrvlEt0\ncbIjIcKHxCglYQFu2Mhk6PR6/vJFCScvVaFwceAnT8Xed9ctS4lxtFhafLdqWjl6rozca/VIGEpe\npieFkBzte8+FuEej49TlKj4/X466XYOt3Ia5sX4sSQw2buRiafGNhvEe43iNTyRtCzT0b4i9dHRr\nH7hjlKWxxA+TXpK4UdVCdpGKC8X/LvTh6erAnEglVQ0d5N9oJNDbmc0rZzxw7bwlxmhKlhpfTWMH\nx86Xc/aKYR2120R7HksIYv7MACRJ4kROJV9cNOww52AnZ0FcAI/NCbpnQw9Ljc+UxnuM4zU+kbQt\n0Hg92fpYenw6vZ6rt5vJLlKRc73eWEI1KlTB809MH9KSDkuP8WFZenzNbT18caGCk5er6NHomOBg\niyRJdGt0ODvasmhWII/ODhrypjbj0XiPcbzGd7+kPaLHant7e8nIyKC6uhq5XM6uXbsICgrq957i\n4mK2b98OwKJFi9i4cSMqlYrt27ej0WjQ6/Vs27aNmJiYkTRBEB6K3MaGmMmexEz2ZK1WR15pI81t\nPSyIH171J8F8FC4OfH/hFB5PCeGr3Cq+vFiBTGbD8tRQ5s8MeKgSnIJgqUZ0Vh85cgRXV1f27t3L\nmTNn2Lt3L7/5zW/6vee1117j9ddfJzIykpdffpmuri4++OADFi9ezKpVq8jNzeXXv/4177//vkkC\nEYSRsrOVMzvCx9zNEEbI2dGO5SmhZtkISBDG2ohuKbKysli8eDEAKSkp5Obm9jve0NBAZ2cn0dHR\n2NjY8PbbbzNhwgQUCgVqtaGQQWtrKwqF4iGbLwiCYCAStvC/wYjutBsaGvDwMJSys7GxQSaTodFo\nsLc3PNVcVVWFm5sbGRkZ3L59myVLlrBu3TrWrVvHU089xaeffkp7ezt//etfTReJIAiCIIxzD0za\nBw4c4MCBA/1ey8vL6/fz3c+ySZJEZWUl7733Ho6Ojjz99NOkpqbyxRdfkJ6ezoYNGzh58iS7d+/m\n3Xffve//VyicsB1iQQxrc7+HDcaD8R4fjP8YRXzWb7zHON7ju9sDk/bKlStZuXJlv9cyMjKor68n\nIiKC3t5eJEky3mUDeHp6Eh4ebhz+njVrFiUlJeTm5rJ582YAUlNT+cUvfvHABjY3dw4rIGsxXp96\n7DPe44PxH6OIz/qN9xjHa3z3+yIyojnt1NRUPv/8cwBOnjxJYmJiv+NBQUF0dHSgVqvR6/VcvXqV\nyZMnExISYrxLz8/PJyQkZCT/XhAEQRD+VxrRnPbSpUvJzMxk9erV2Nvb88YbbwCwb98+EhISiIuL\nY9u2bfzoRz9CJpMxd+5cIiIieO6553j11VeNCf/VV181XSSCIAiCMM6J4ipmMl6HdfqM9/hg/Mco\n4rN+4z3G8RqfyYfHBUEQBEEYeyJpC4IgCIKVEElbEARBEKyESNqCIAiCYCVE0hYEQRAEK2HxT48L\ngiAIgmAg7rQFQRAEwUqIpC0IgiAIVkIkbUEQBEGwEiJpC4IgCIKVEElbEARBEKyESNqCIAiCYCVG\ntMuXMHRvvvkmOTk5aLVannvuOR577DHjsYULF+Lr64tcLgdgz549KJVKczV1RLKzs/nJT35CeHg4\nAFOnTuW1114zHs/MzOTtt99GLpeTlpbGxo0bzdXUETlw4ACHDx82/lxQUMClS5eMP0dHRxMfH2/8\n+YMPPjD2p6W7fv06zz//POvWrWPNmjXU1NSwdetWdDod3t7evPXWW9jb2/f7nV/96lfk5eUhk8nY\nvn07sbGxZmr9gw0U37Zt29Bqtdja2vLWW2/h7e1tfP+DzmVLdHeMGRkZFBYW4u7uDsD69euZP39+\nv9+x5j7ctGkTzc3NAKjVambOnMnrr79ufP/f//533nnnHYKDgwFISUlhw4YNZmn7qJGEUZOVlSU9\n88wzkiRJUlNTkzRv3rx+xxcsWCC1t7eboWWmc+7cOenFF18c9Hh6erpUXV0t6XQ6afXq1VJJSckY\nts60srOzpZ07d/Z7bc6cOWZqzcPp6OiQ1qxZI/3sZz+TPvzwQ0mSJCkjI0M6evSoJEmStHfvXunj\njz/u9zvZ2dnSs88+K0mSJJWWlkrf//73x7bRwzBQfFu3bpU+++wzSZIk6aOPPpJ2797d73cedC5b\nmoFifOWVV6Svvvpq0N+x9j78toyMDCkvL6/fa4cOHZLeeOONsWqiWYjh8VGUkJDAO++8A4Crqytd\nXV3odDozt2rsVFRU4Obmhp+fHzY2NsybN4+srCxzN2vE3nvvPZ5//nlzN8Mk7O3t2b9/Pz4+PsbX\nsrOzWbRoEQALFiy4p6+ysrJ49NFHAQgLC6OlpYX29vaxa/QwDBTfjh07+M53vgOAQqFArVabq3km\nMVCMD2Ltfdjn5s2btLW1WfQowWgRSXsUyeVynJycADh48CBpaWn3DJ3u2LGD1atXs2fPHiQrLU5X\nWlrKj3/8Y1avXs3Zs2eNr9fX1+Ph4WH82cPDg/r6enM08aHl5+fj5+fXbzgVQKPRsGXLFlatWsWf\n/vQnM7Vu+GxtbXF0dOz3WldXl3E43NPT856+amhoQKFQGH+25P4cKD4nJyfkcjk6nY6//OUvLF++\n/J7fG+xctkQDxQjw0UcfsXbtWl566SWampr6HbP2Puzz5z//mTVr1gx47Pz586xfv54f/vCHFBUV\njWYTzULMaY+BL7/8koMHD/LHP/6x3+ubNm1i7ty5uLm5sXHjRo4dO8aSJUvM1MqRCQ0N5YUXXiA9\nPZ2KigrWrl3L8ePH75kLtXYHDx7ke9/73j2vb926lRUrViCTyVizZg2zZ89m+vTpZmihaQ3lC6Q1\nfsnU6XRs3bqVpKQkkpOT+x0bD+fyd7/7Xdzd3YmMjGTfvn28++67/PznPx/0/dbYhxqNhpycHHbu\n3HnPsRkzZuDh4cH8+fO5dOkSr7zyCv/85z/HvpGjSNxpj7LTp0/z+9//nv379+Pi4tLv2BNPPIGn\npye2trakpaVx/fp1M7Vy5JRKJUuXLkUmkxEcHIyXlxcqlQoAHx8fGhoajO9VqVTDGsqzJNnZ2cTF\nxd3z+urVq3F2dsbJyYmkpCSr7MM+Tk5OdHd3AwP31d39WVdXd8/Ig6Xbtm0bISEhvPDCC/ccu9+5\nbC2Sk5OJjIwEDA+63n0+joc+vHDhwqDD4mFhYcYH7+Li4mhqahp3U5IiaY+itrY23nzzTf7whz8Y\nn+b89rH169ej0WgAw4nY99SqNTl8+DDvv/8+YBgOb2xsND4BHxgYSHt7O5WVlWi1Wk6ePElqaqo5\nmzsiKpUKZ2fne+64bt68yZYtW5AkCa1WS25urlX2YZ+UlBSOHTsGwPHjx5k7d26/46mpqcbjhYWF\n+Pj4MHHixDFv50gdPnwYOzs7Nm3aNOjxwc5la/Hiiy9SUVEBGL5o3n0+WnsfAly5coWIiIgBj+3f\nv58jR44AhifPPTw8rGY1x1CJ4fFRdPToUZqbm9m8ebPxtcTERKZNm8bixYtJS0vj6aefxsHBgaio\nKKsbGgfDt/mXX36ZEydO0Nvby86dOzly5AguLi4sXryYnTt3smXLFgCWLl3KpEmTzNzi4bt7bn7f\nvn0kJCQQFxeHr68vTz31FDY2NixcuNBqHowpKChg9+7dVFVVYWtry7Fjx9izZw8ZGRn87W9/w9/f\nnyeeeAKAl156iV27dhEfH090dDSrVq1CJpOxY8cOM0cxuIHia2xsxMHBgR/84AeA4a5s586dxvgG\nOpcteWh8oBjXrFnD5s2bmTBhAk5OTuzatQsYP33429/+lvr6euOSrj4bNmzgd7/7HcuXL+enP/0p\nn3zyCVqtll/+8pdmav3oEVtzCoIgCIKVEMPjgiAIgmAlRNIWBEEQBCshkrYgCIIgWAmRtAVBEATB\nSoikLQiCIAhWQiRtQRAEQbASImkLgiAIgpUQSVsQBEEQrMT/B2mjlpB6tGUYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}