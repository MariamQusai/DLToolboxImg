{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NoduleSegmentationModel8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/x110/DLToolboxImg/blob/master/NoduleSegmentationModel8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "W6ljz0jskI2x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Configuration"
      ]
    },
    {
      "metadata": {
        "id": "z5MS9CSfkCPt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Remove CUDA 9 completely\n",
        "\n",
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "\n",
        "!apt-get update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQt0wZRLkM62",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install CUDA 8\n",
        "\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb\n",
        "!dpkg -i --force-overwrite cuda-repo-ubuntu1604_8.0.61-1_amd64.deb\n",
        "!apt-get update\n",
        "!apt-get install cuda-8-0\n",
        "\n",
        "# install will fail, need to force dpkg to overwrite the configuration file\n",
        "\n",
        "!wget http://archive.ubuntu.com/ubuntu/pool/main/m/mesa/libglx-mesa0_18.0.5-0ubuntu0~18.04.1_amd64.deb\n",
        "!dpkg -i --force-overwrite libglx-mesa0_18.0.5-0ubuntu0~18.04.1_amd64.deb\n",
        "\n",
        "!wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/nvidia-410_410.48-0ubuntu1_amd64.deb\n",
        "!dpkg -i --force-overwrite nvidia-410_410.48-0ubuntu1_amd64.deb\n",
        "\n",
        "!apt --fix-broken install\n",
        "!apt-get install cuda-8-0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFAXDR9Gvw8S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip uninstall -y scipy\n",
        "!pip install turicreate\n",
        "# The worng version of MXNET will be installed.\n",
        "!pip uninstall -y mxnet\n",
        "!pip install scipy\n",
        "# Instal CUDA8-compatible version of mxnet 1.1.0\n",
        "!pip install mxnet-cu80==1.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2nWGr82Ik3t_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-A_IctC4ABII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Settings"
      ]
    },
    {
      "metadata": {
        "id": "TWY_-L4qDQXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/My Drive/Datasets/Dataset5/processed/.'\n",
        "model_path = \"drive/My Drive/x110/model/model8/\"\n",
        "#model details\n",
        "prefix = \"nov8\"\n",
        "model_epoch=40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7oArm9XTEWk-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "load_model = True#False\n",
        "find_stats = False#True\n",
        "bs = 34#100#64#34"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hreX2n06B5dg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  Load Data"
      ]
    },
    {
      "metadata": {
        "id": "LS-j2uGt_h64",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = \"x110/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7hmz4sRBd40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "b64c2054-4f7f-42d3-f052-ed159342d4e3"
      },
      "cell_type": "code",
      "source": [
        "!mkdir {PATH}\n",
        "!mkdir {PATH+\"Datasets\"}\n",
        "!mkdir {PATH+\"Datasets/Dataset1/\"}\n",
        "!mkdir {PATH+\"Datasets/Dataset1/processed/\"}\n",
        "!mkdir {PATH+\"model\"}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘x110/’: File exists\n",
            "mkdir: cannot create directory ‘x110/Datasets’: File exists\n",
            "mkdir: cannot create directory ‘x110/Datasets/Dataset1/’: File exists\n",
            "mkdir: cannot create directory ‘x110/Datasets/Dataset1/processed/’: File exists\n",
            "mkdir: cannot create directory ‘x110/model’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ic0tSCrnFk9-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -a \"{dataset_path}\" {PATH+\"Datasets/Dataset1/processed/\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ITGUgg7UB6BJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if load_model:\n",
        "  drivefile = model_path+prefix+\"-\"+\"{:04d}\".format(model_epoch)+\".params\"\n",
        "  drivefile2 = model_path+prefix+\"-symbol.json\"\n",
        "  colabfile = PATH+\"model/\"+prefix+\"-\"+\"{:04d}\".format(model_epoch)+\".params\"\n",
        "  colabfile2 = PATH+\"model/\"+prefix+\"-symbol.json\"\n",
        "\n",
        "  !cp  \"{drivefile}\" {colabfile}\n",
        "  !cp  \"{drivefile2}\" {colabfile2}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HT3hdPbNk6zy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Dataset Path \n",
        "interm_dir4 = PATH + \"Datasets/Dataset1/processed/\"\n",
        "s = \"2018_11_25\"\n",
        "train_data_path=interm_dir4+'train'+s+'pos.rec'\n",
        "train_idx_path=interm_dir4+'train'+s+'pos.idx'\n",
        "valid_data_path=interm_dir4+'valid'+s+'pos.rec'\n",
        "valid_idx_path=interm_dir4+'valid'+s+'pos.idx'\n",
        "test_data_path=interm_dir4+'test'+s+'pos.rec'\n",
        "test_idx_path=interm_dir4+'test'+s+'pos.idx'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W5Ajv0yqyY9c",
        "colab_type": "code",
        "outputId": "d6c262ba-aa5a-497f-b9a0-5704058444cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir x110/DLToolboxImg\n",
        "!git clone https://github.com/x110/DLToolboxImg.git x110/DLToolboxImg"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘x110/DLToolboxImg’: File exists\n",
            "fatal: destination path 'x110/DLToolboxImg' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "toc": true,
        "id": "EIFzslyej3R8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Configuration</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-mean-of-images\" data-toc-modified-id=\"Find-mean-of-images-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Find mean of images</a></span></li><li><span><a href=\"#Find-variance-of-images\" data-toc-modified-id=\"Find-variance-of-images-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Find variance of images</a></span></li></ul></li><li><span><a href=\"#Data-Iterator\" data-toc-modified-id=\"Data-Iterator-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Iterator</a></span></li><li><span><a href=\"#Evaluation-Metric\" data-toc-modified-id=\"Evaluation-Metric-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation Metric</a></span></li><li><span><a href=\"#Model-Architecture\" data-toc-modified-id=\"Model-Architecture-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Architecture</a></span></li><li><span><a href=\"#Optimizer\" data-toc-modified-id=\"Optimizer-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Optimizer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find--learning-rate\" data-toc-modified-id=\"Find--learning-rate-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Find  learning rate</a></span></li><li><span><a href=\"#Optimizer-Parameters\" data-toc-modified-id=\"Optimizer-Parameters-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Optimizer Parameters</a></span></li></ul></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Train Model</a></span></li><li><span><a href=\"#Evaluate-Model\" data-toc-modified-id=\"Evaluate-Model-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluate Model</a></span></li></ul></div>"
      ]
    },
    {
      "metadata": {
        "id": "fRuO7y9fj3R3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Code"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "F7JkqZ0mj3SM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,\"x110/DLToolboxImg/src/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "2yYRVHIdj3SU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import mynnet7 as nn\n",
        "import pickle\n",
        "import mxnet as mx\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xe-Fv5N2a9Ra"
      },
      "cell_type": "markdown",
      "source": [
        "# Nodule Segmentation: Model"
      ]
    },
    {
      "metadata": {
        "id": "GWkyDSB2j3S_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "T_OZbL4Mj3TC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Find mean of images"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "To2ssEIvj3TG",
        "colab_type": "code",
        "outputId": "5586de76-e741-4839-e50e-7edc532144a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "if find_stats:\n",
        "    BATCH_SIZE=1\n",
        "    train_iter=nn.FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_augment=True,mean_image=0,std_image=1)\n",
        "    train_iter.reset()\n",
        "    x_mean = np.zeros((32,32,32))\n",
        "    for i,batch in enumerate(train_iter):\n",
        "        X =  batch.data[0][0][0].asnumpy()\n",
        "        x_mean+=X\n",
        "    x_mean=np.mean(x_mean/i)\n",
        "    # Saving the objects:\n",
        "    with open(interm_dir4+'x_mean.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "        pickle.dump([x_mean], f)\n",
        "\n",
        "else:\n",
        "    with open(interm_dir4+'x_mean.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
        "        x_mean = pickle.load(f)\n",
        "x_mean#x_mean=0.2826227159416579"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28262271594165789]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "eRUFk9Juj3TT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_mean=0.28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "raNj5rVmj3Td",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Find variance of images"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "z7p4QBZKj3Tg",
        "colab_type": "code",
        "outputId": "0e2d555c-0b0a-435f-995d-b29b5deaa974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "if find_stats: \n",
        "    BATCH_SIZE=1\n",
        "    train_iter=nn.FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_augment=True,mean_image=0,std_image = 1)\n",
        "    train_iter.reset()\n",
        "    x_var = np.zeros((32,32,32))\n",
        "    for i,batch in enumerate(train_iter):\n",
        "        X =  (batch.data[0][0][0].asnumpy()-x_mean)**2\n",
        "        x_var+=X\n",
        "    #x_var=x_var/(i-1)\n",
        "    #x_var#x_mean=.2815\n",
        "    N = i*32*32*32\n",
        "    x_var = np.sum(x_var)/(N-1)\n",
        "    x_var#x_var = .07877\n",
        "    x_std = np.sqrt(x_var)#x_std=.2807\n",
        "    with open(interm_dir4+'x_std.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "        pickle.dump([x_std], f)\n",
        "else:\n",
        "    with open(interm_dir4+'x_std.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
        "        x_std = pickle.load(f)\n",
        "x_std#x_std=0.2817920662435274"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28179206624352737]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "yXzLyS3Lj3To",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_std = 0.28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nIpXpHQxj3Tw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Iterator"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "cb3ZRqqWj3Ty",
        "colab_type": "code",
        "outputId": "ca337fde-db59-4908-e836-52eef46c6a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=bs\n",
        "train_iter=nn.FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,random_flip=True,do_augment=False,mean_image=x_mean,std_image = x_std,do_shuffle=True)\n",
        "input_shapes = dict(train_iter.provide_data+train_iter.provide_label)\n",
        "print(input_shapes)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': (34, 1, 32, 32, 32), 'softmax_label': (34, 32768)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "39QY_Ip9j3T8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=bs\n",
        "valid_iter=nn.FileIter(valid_data_path,valid_idx_path,batch_size=BATCH_SIZE,do_augment=False,mean_image=x_mean,std_image = x_std,do_shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "EO0l_t4Ej3UC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_iter.reset()\n",
        "valid_iter.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MKxlY8J9j3UH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metric"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "LIeANhbqj3UJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_coef2(label, y):\n",
        "    smooth = 1.\n",
        "    label=mx.nd.array(label).as_in_context(mx.gpu(0))\n",
        "    y=mx.nd.array(y).as_in_context(mx.gpu(0))\n",
        "    intersection = mx.nd.sum(label*y)\n",
        "    return ((2. * intersection + smooth) / (mx.nd.sum(label) +mx.nd.sum(mx.nd.abs(y)) + smooth))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z7Cb9A9_PP4f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def logloss2(label, y,w=[.9,.1]):\n",
        "    smooth = 1.\n",
        "    label=mx.nd.array(label).as_in_context(mx.gpu(0))\n",
        "    y=mx.nd.array(y).as_in_context(mx.gpu(0))\n",
        "    eps=1e-12\n",
        "    return mx.nd.mean(-(w[0]*label*mx.nd.log(y+eps)+w[1]*(1-label)*mx.nd.log(1-y+eps)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aVZdy14Zc8V2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ===============Evaluation metric(s)================= \n",
        "eval_metrics_1 =  mx.metric.CustomMetric(feval=logloss2)\n",
        "eval_metrics_2 = mx.metric.CustomMetric(feval=nn.dice_coef2)\n",
        "metric= mx.metric.CompositeEvalMetric()\n",
        "for child_metric in [eval_metrics_1, eval_metrics_2]:\n",
        "  metric.add(child_metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9Lb-RuGj3Uc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "pt98E9Faj3Uf",
        "colab_type": "code",
        "outputId": "2fd8d914-0733-43f9-b447-2a9286567c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "load_model"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "mTiJEEydj3Uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if load_model:\n",
        "    network, arg_params, aux_params = mx.model.load_checkpoint(model_path+prefix , model_epoch)\n",
        "\n",
        "    # Binding\n",
        "    exe = network.simple_bind(ctx=mx.gpu(0), **input_shapes)\n",
        "\n",
        "\n",
        "    exe.copy_params_from(arg_params, aux_params)\n",
        "    \n",
        "    # get handle to input arrays\n",
        "    arg_arrays = dict(zip(network.list_arguments(), exe.arg_arrays))\n",
        "    data = arg_arrays[train_iter.provide_data[0][0]]\n",
        "    label = arg_arrays[train_iter.provide_label[0][0]]\n",
        "else:\n",
        "\n",
        "    network = nn.get_net_319()\n",
        "    init = mx.init.Normal(0.01) #note biases and gamma/beta are not affected\n",
        "\n",
        "    # Binding\n",
        "    exe = network.simple_bind(ctx=mx.gpu(), **input_shapes)\n",
        "    # get handle to input arrays\n",
        "    arg_arrays = dict(zip(network.list_arguments(), exe.arg_arrays))\n",
        "    data = arg_arrays[train_iter.provide_data[0][0]]\n",
        "    label = arg_arrays[train_iter.provide_label[0][0]]\n",
        "    for name, arr in arg_arrays.items():\n",
        "        if name not in input_shapes:\n",
        "            init(name, arr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "p36aWzqzbH75"
      },
      "cell_type": "markdown",
      "source": [
        "# Nodule Segmentation: Model"
      ]
    },
    {
      "metadata": {
        "id": "_VAcRTIBj3VB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "aw1eUaNVj3VJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Find  learning rate"
      ]
    },
    {
      "metadata": {
        "id": "17MM3ZvwYbBV",
        "colab_type": "code",
        "outputId": "cd69acc2-4468-432a-ab9d-bb43f94158f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "find_learning_rate = True\n",
        "\n",
        "nb=train_iter.num_data//train_iter.batch_size\n",
        "\n",
        "if find_learning_rate:\n",
        "\n",
        "  lrs = []\n",
        "  loss = []\n",
        "  \n",
        "  sched=nn.lr_find(1e-5,nb,end_lr=1e-4)\n",
        "  # We also need to create an optimizer for updating weights\n",
        "  opt = mx.optimizer.SGD(\n",
        "      learning_rate=1e-5,\n",
        "      momentum=0.9,\n",
        "      wd=0.00001,\n",
        "      lr_scheduler=sched)\n",
        "\n",
        "  updater = mx.optimizer.get_updater(opt)\n",
        "  for epoch in range(0,1):\n",
        "\n",
        "      start = time.time()\n",
        "\n",
        "      metric.reset()\n",
        "\n",
        "      train_iter.reset()\n",
        "\n",
        "      valid_iter.reset()\n",
        "\n",
        "      sched.reset()\n",
        "\n",
        "      sched.on_train_begin()\n",
        "\n",
        "\n",
        "      for batch in train_iter:\n",
        "          # Copy data to executor input. Note the [:].\n",
        "          data[:] = batch.data[0]\n",
        "          label[:] = batch.label[0]\n",
        "\n",
        "          # Forward\n",
        "          outputs=exe.forward(is_train=True)\n",
        "          # Backward\n",
        "          exe.backward()\n",
        "\n",
        "          # Update\n",
        "          for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
        "              weight, grad = pair\n",
        "              updater(i, grad, weight)   \n",
        "          #metric.update(batch.label[0], exe.outputs[0])#\n",
        "          metric.update(batch.label[0], exe.outputs[0])\n",
        "\n",
        "          e=metric.get()\n",
        "          e = dict(zip(e[0], e[1]))\n",
        "  \n",
        "          err_train=-e['dice_coef2'].asnumpy()[0]\n",
        "          sched.on_batch_end(err_train)\n",
        "\n",
        "      if epoch % 100== 0:       \n",
        "          #print(\"do_checkpoint\")\n",
        "          arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
        "          aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
        "          mx.model.save_checkpoint(prefix, epoch, network, arg, aux)\n",
        "\n",
        "\n",
        "      #compute valid loss per epoch    \n",
        "      metric.reset()\n",
        "      for batch in valid_iter:        \n",
        "          data[:] = batch.data[0]       \n",
        "          label[:] = batch.label[0]\n",
        "          # predict\n",
        "          outputs = exe.forward(is_train=False)\n",
        "          metric.update(batch.label[0], exe.outputs[0])\n",
        "      e0=metric.get()\n",
        "      e = dict(zip(e0[0], e0[1]))\n",
        "      err_valid=-e['dice_coef2'].asnumpy()[0]\n",
        "      end = time.time()\n",
        "      print('time:',end-start,'Epoch:',epoch,'trainloss:',err_train,'validloss:',err_valid,'CE',outputs[1].asnumpy())\n",
        "      for x,y in zip(e0[0],e0[1]):\n",
        "        print(x,y[0].asnumpy()[0], end=\", \", flush=True)\n",
        "  lrs.extend(sched.lrs)\n",
        "  loss.extend(sched.losses)\n",
        "\n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 136.57926440238953 Epoch: 0 trainloss: -0.700098 validloss: -0.627427 CE [-0.68972367]\n",
            "logloss2 0.272537, dice_coef2 0.627427, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "luPrenJ2sZTv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  plt.figure()\n",
        "  plt.plot(lrs, loss,'*-')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ScwvyY2Hj3WA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizer Parameters"
      ]
    },
    {
      "metadata": {
        "id": "QQMspdjFl1eQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#logfile = model_path+\"errorlogmodel8.csv\"\n",
        "logfile = \"errorlogmodel8.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3KrV7AO1i62v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "col_names = ['epoch',\n",
        "             'lr',\n",
        "             'loss',\n",
        "             'E1train',\n",
        "             'E1valid',\n",
        "             'E2train',\n",
        "             'E2valid']\n",
        "df = pd.DataFrame(columns=col_names)\n",
        "\n",
        "if False:\n",
        "  df.to_csv(logfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eMbv0lVruIIK",
        "colab_type": "code",
        "outputId": "d4440660-b6c0-40b4-e480-c36da657c7c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(logfile, index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>lr</th>\n",
              "      <th>loss</th>\n",
              "      <th>E1train</th>\n",
              "      <th>E1valid</th>\n",
              "      <th>E2train</th>\n",
              "      <th>E2valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [epoch, lr, loss, E1train, E1valid, E2train, E2valid]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "id": "I2EXT_W9Wz3y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "lr =1.5e-6\n",
        "\n",
        "# We also need to create an optimizer for updating weights\n",
        "# ===============Optimizer=================                        \n",
        "opt = mx.optimizer.SGD(\n",
        "    learning_rate=lr,momentum=0.99,wd=0.000001)\n",
        "\n",
        "updater = mx.optimizer.get_updater(opt)\n",
        "\n",
        "updater.optimizer.lr_scheduler=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UD-lD0cfVRv6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#epoch = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c7EogiUVnm1X",
        "colab_type": "code",
        "outputId": "0dd7526a-024e-4707-b783-5d89918861cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "cell_type": "code",
      "source": [
        "epoch_r  =epoch\n",
        "epoch_r\n",
        "Es_train=[]\n",
        "Es_valid=[]\n",
        "for epoch in range(epoch_r,epoch_r+epochs+1):\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    metric.reset()\n",
        "\n",
        "    train_iter.reset()\n",
        "    \n",
        "    valid_iter.reset()\n",
        "    \n",
        "\n",
        "    for batch in train_iter:\n",
        "        # Copy data to executor input. Note the [:].\n",
        "        data[:] = batch.data[0]\n",
        "        label[:] = batch.label[0]\n",
        "\n",
        "        # Forward\n",
        "        outputs=exe.forward(is_train=True)\n",
        "        Es_train.append(outputs[1].asnumpy()[0])\n",
        "        # Backward\n",
        "        exe.backward()\n",
        "\n",
        "        # Update\n",
        "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
        "            weight, grad = pair\n",
        "            updater(i, grad, weight)   \n",
        "        metric.update(batch.label[0], exe.outputs[0])#metric.update(label,p)\n",
        "        \n",
        "    e=metric.get()\n",
        "    ed={}\n",
        "    e_key,e_val = e\n",
        "    for k,v in zip(e_key,e_val):\n",
        "      ed[k]=v.asnumpy()[0]\n",
        "    err_train=-ed['dice_coef2']\n",
        "    err_train2=ed['logloss2']\n",
        "    \n",
        "    loss = outputs[1].asnumpy()[0] \n",
        "    \n",
        "    if epoch % 10== 0:       \n",
        "        #print(\"do_checkpoint\")\n",
        "        arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
        "        aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
        "        mx.model.save_checkpoint(model_path+prefix, epoch, network, arg, aux)\n",
        "        \n",
        "        \n",
        "    #compute valid loss per epoch    \n",
        "    metric.reset()\n",
        "    for batch in valid_iter:        \n",
        "        data[:] = batch.data[0]       \n",
        "        label[:] = batch.label[0]\n",
        "        # predict\n",
        "        outputs = exe.forward(is_train=False)\n",
        "        Es_valid.append(outputs[1].asnumpy()[0])\n",
        "        metric.update(batch.label[0], exe.outputs[0])\n",
        "    e=metric.get()\n",
        "    ed={}\n",
        "    e_key,e_val = e\n",
        "    for k,v in zip(e_key,e_val):\n",
        "      ed[k]=v.asnumpy()[0]\n",
        "    err_valid=-ed['dice_coef2']\n",
        "    err_valid2=ed['logloss2']\n",
        "    \n",
        "\n",
        "    end = time.time()\n",
        "    print('time:',end-start,'Epoch:',epoch,\"loss\",loss,'trainloss:',err_train,'validloss:',err_valid,'trainloss2:',err_train2,'validloss2:',err_valid2)\n",
        "    myCsvRow = [(epoch,updater.optimizer.lr,loss,err_train,err_valid,err_train2,err_valid2)]\n",
        "    df = pd.DataFrame.from_records(myCsvRow,columns = col_names)\n",
        "    df.to_csv(logfile, mode='a', header=False)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 127.34674715995789 Epoch: 0 loss -0.828995 trainloss: -0.701235 validloss: -0.625702 trainloss2: 0.148374 validloss2: 0.275829\n",
            "time: 127.47548079490662 Epoch: 1 loss -0.818138 trainloss: -0.700671 validloss: -0.625982 trainloss2: 0.151173 validloss2: 0.271487\n",
            "time: 127.36842203140259 Epoch: 2 loss -0.798766 trainloss: -0.699154 validloss: -0.625186 trainloss2: 0.151434 validloss2: 0.274558\n",
            "time: 127.3768539428711 Epoch: 3 loss -0.829086 trainloss: -0.701596 validloss: -0.626525 trainloss2: 0.151459 validloss2: 0.277077\n",
            "time: 127.30716514587402 Epoch: 4 loss -0.75531 trainloss: -0.701706 validloss: -0.627477 trainloss2: 0.149634 validloss2: 0.268524\n",
            "time: 127.37158155441284 Epoch: 5 loss -0.818288 trainloss: -0.700803 validloss: -0.625203 trainloss2: 0.149884 validloss2: 0.282096\n",
            "time: 127.38550424575806 Epoch: 6 loss -0.836303 trainloss: -0.701213 validloss: -0.628335 trainloss2: 0.150136 validloss2: 0.269832\n",
            "time: 127.32765626907349 Epoch: 7 loss -0.770677 trainloss: -0.698557 validloss: -0.626569 trainloss2: 0.150223 validloss2: 0.276214\n",
            "time: 127.35778880119324 Epoch: 8 loss -0.823276 trainloss: -0.698197 validloss: -0.625207 trainloss2: 0.153095 validloss2: 0.278717\n",
            "time: 127.34031891822815 Epoch: 9 loss -0.796683 trainloss: -0.699687 validloss: -0.626814 trainloss2: 0.151372 validloss2: 0.271781\n",
            "time: 127.3872287273407 Epoch: 10 loss -0.812519 trainloss: -0.699798 validloss: -0.626233 trainloss2: 0.150855 validloss2: 0.274545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ygzfh9KhU9uk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(logfile, index_col=0)\n",
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XYSx0E069i7F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure()\n",
        "plt.plot(df['epoch'],df['lr'])\n",
        "plt.title('Learning Rate')\n",
        "plt.figure()\n",
        "plt.plot(df['epoch'],df['E1train'])\n",
        "plt.plot(df['epoch'],df['E1valid'],'r')\n",
        "plt.title('E1')\n",
        "plt.figure()\n",
        "plt.plot(df['epoch'],df['E2train'])\n",
        "plt.plot(df['epoch'],df['E2valid'],'r')\n",
        "plt.title('E2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nBw3WCXgU3zf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp logfile mode_path"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}