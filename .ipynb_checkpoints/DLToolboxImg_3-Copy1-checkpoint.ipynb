{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLToolboxImg: Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Define File Iterator](#fileiter)\n",
    "- [Define Evaluation Metric](#metric)\n",
    "- [Define Model Architecture](#arch)\n",
    "- [Select Learning Rate](#lrfind)\n",
    "- [Select Initial weights](#weights)\n",
    "- [Train Model](#train)\n",
    "- [Save Model](#save)\n",
    "- [Evaluate Model](#eval)\n",
    "- [Modify Learnig Parameters](#train2)\n",
    "- [Resume Training](#resume)\n",
    "- [Compare Models](#compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mynnet7 as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define File Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import sys, os\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import re\n",
    "from mxnet.io import DataIter\n",
    "from mxnet.io import DataBatch\n",
    "import pandas as pd\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "BATCH_SIZE,INPUT_SIZE_z,INPUT_SIZE_y, INPUT_SIZE_x = 8,32,32,32\n",
    "def print_inferred_shape(net):\n",
    "    ar, ou, au = net.infer_shape(data=(BATCH_SIZE, 1, INPUT_SIZE_z,INPUT_SIZE_y, INPUT_SIZE_x))\n",
    "    print(net.name,ou)\n",
    "class FileIter(DataIter):\n",
    "    def __init__(self, path,\n",
    "                 data_name=\"data\",\n",
    "                 label_name=\"softmax_label\",\n",
    "                 batch_size=1,\n",
    "                 do_augment=False,\n",
    "                 mean_image=.2815,\n",
    "                 std_image = .2807):\n",
    "\n",
    "        \n",
    "        self.epoch = 0\n",
    "        self.mean_image = mean_image\n",
    "        self.std_image = std_image\n",
    "        \n",
    "        super(FileIter, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.do_augment=do_augment\n",
    "\n",
    "\n",
    "        #self.mean = cv2.imread(mean_image, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        self.data_name = data_name\n",
    "        self.label_name = label_name\n",
    "\n",
    "        self.record = mx.recordio.MXRecordIO(path, 'r')\n",
    "\n",
    "        \n",
    "        def readrecord(record):\n",
    "            record.reset()\n",
    "            num_data=0\n",
    "            while True:\n",
    "                item = record.read()\n",
    "                num_data+=1\n",
    "                if not item:\n",
    "                    break\n",
    "            return num_data-1\n",
    "        \n",
    "        \n",
    "        self.num_data = readrecord(self.record)#len(open(self.flist_name, 'r').readlines())\n",
    "        \n",
    "        self.cursor = -1\n",
    "        self.record.reset()\n",
    "\n",
    "        self.data, self.label = self._read()\n",
    "        self.reset()\n",
    "\n",
    "    def _read(self):\n",
    "        \"\"\"get two list, each list contains two elements: name and nd.array value\"\"\"\n",
    "                \n",
    "        data = {}\n",
    "        label = {}\n",
    "\n",
    "        dd = []\n",
    "        ll = []\n",
    "        for i in range(0, self.batch_size):\n",
    "            \n",
    "            item = self.record.read()            \n",
    "            header, l = mx.recordio.unpack_img(item)\n",
    "            \n",
    "            d=header.label\n",
    "\n",
    "            d=d.reshape((32,32,32))- self.mean_image\n",
    "            d = d/self.std_image\n",
    "            d = np.expand_dims(d, axis=0) \n",
    "            d = np.expand_dims(d, axis=0)\n",
    "            \n",
    "\n",
    "            l=l.reshape((32*32*32))\n",
    "            l = np.expand_dims(l, axis=0)\n",
    "            l=l.astype(float)\n",
    "\n",
    "            dd.append(d)\n",
    "            ll.append(l)\n",
    "\n",
    "        d = np.vstack(dd)\n",
    "        l = np.vstack(ll)\n",
    "        data[self.data_name] = d\n",
    "        label[self.label_name] = l\n",
    "        res = list(data.items()), list(label.items())\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def provide_data(self):\n",
    "        \"\"\"The name and shape of data provided by this iterator\"\"\"\n",
    "        res = [(k, tuple(list(v.shape[0:]))) for k, v in self.data]\n",
    "        # print \"data : \" + str(res)\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def provide_label(self):\n",
    "        \"\"\"The name and shape of label provided by this iterator\"\"\"\n",
    "        res = [(k, tuple(list(v.shape[0:]))) for k, v in self.label]\n",
    "        return res\n",
    "    \n",
    "\n",
    "    def reset(self):\n",
    "        self.cursor = -1\n",
    "        self.record.reset()\n",
    "        self.epoch += 1\n",
    "\n",
    "    def getpad(self):\n",
    "        return 0\n",
    "\n",
    "    def iter_next(self):\n",
    "        self.cursor += self.batch_size\n",
    "        if self.cursor < self.num_data:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def eof(self):\n",
    "        res = self.cursor >= self.num_data\n",
    "        return res\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"return one dict which contains \"data\" and \"label\" \"\"\"\n",
    "        if self.iter_next():\n",
    "            self.data, self.label = self._read()\n",
    " \n",
    "            res = DataBatch(data=[mx.nd.array(self.data[0][1])], label=[mx.nd.array(self.label[0][1])], pad=self.getpad(), index=None)\n",
    "\n",
    "            return res\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interm_dir4='/home/mas/x110/data'\n",
    "train_data_path=interm_dir4+'/Train6Oct2018augment.rec'\n",
    "BATCH_SIZE=1\n",
    "train_iter=FileIter(train_data_path,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_iter.next()\n",
    "X =  batch.data[0][0][0].asnumpy()\n",
    "Y = batch.label[0].reshape((32,32,32)).asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 32), (32, 32, 32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zs=32\n",
    "\n",
    "X2,Z2 = X,Y\n",
    "Z2 = np.ma.masked_where(Z2 ==0 , Z2)\n",
    "\n",
    "num_rows=6\n",
    "num_cols=6\n",
    "\n",
    "f, plots = plt.subplots(num_rows, num_cols, sharex='col', sharey='row', figsize=(10,10))\n",
    "\n",
    "ind=np.arange(0,32)\n",
    "for i in range(zs):\n",
    "    ii=ind[i]\n",
    "    plots[i // num_cols, i % num_cols].axis('off')\n",
    "    plots[i // num_cols, i % num_cols].imshow(X2[ii],'gray',vmin=0,vmax=1)\n",
    "\n",
    "    plots[i // num_cols, i % num_cols].imshow(Z2[ii],alpha=0.5,vmin=0,vmax=1)\n",
    "    plots[i // num_cols, i % num_cols].set_title(str(ii))\n",
    "      \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find mean of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2815327279660965"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interm_dir4='/home/mas/x110/data'\n",
    "train_data_path=interm_dir4+'/Train6Oct2018augment.rec'\n",
    "BATCH_SIZE=1\n",
    "train_iter=FileIter(train_data_path,batch_size=BATCH_SIZE,do_augment=True,mean_image=0,std_image=1)\n",
    "train_iter.reset()\n",
    "x_mean = np.zeros((32,32,32))\n",
    "for i,batch in enumerate(train_iter):\n",
    "    X =  batch.data[0][0][0].asnumpy()\n",
    "    x_mean+=X\n",
    "x_mean=np.mean(x_mean/i)\n",
    "x_mean#x_mean=.2815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean=.2815"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find variance of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28066587175585705"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interm_dir4='/home/mas/x110/data'\n",
    "train_data_path=interm_dir4+'/Train6Oct2018augment.rec'\n",
    "BATCH_SIZE=1\n",
    "train_iter=FileIter(train_data_path,batch_size=BATCH_SIZE,do_augment=True,mean_image=0,std_image = 1)\n",
    "train_iter.reset()\n",
    "x_var = np.zeros((32,32,32))\n",
    "for i,batch in enumerate(train_iter):\n",
    "    X =  (batch.data[0][0][0].asnumpy()-x_mean)**2\n",
    "    x_var+=X\n",
    "#x_var=x_var/(i-1)\n",
    "#x_var#x_mean=.2815\n",
    "N = i*32*32*32\n",
    "x_var = np.sum(x_var)/(N-1)\n",
    "x_var#x_var = .07877\n",
    "x_std = np.sqrt(x_var)#x_std=.2807\n",
    "x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std=.2807"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': (32, 1, 32, 32, 32), 'softmax_label': (32, 32768)}\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=32\n",
    "train_iter=FileIter(train_data_path,batch_size=BATCH_SIZE,do_augment=False,mean_image=x_mean,std_image = x_std)\n",
    "input_shapes = dict(train_iter.provide_data+train_iter.provide_label)\n",
    "print(input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': (32, 1, 32, 32, 32), 'softmax_label': (32, 32768)}\n"
     ]
    }
   ],
   "source": [
    "print(input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "valid_iter=FileIter(train_data_path,batch_size=BATCH_SIZE,do_augment=False,mean_image=x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter.reset()\n",
    "valid_iter.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============Optimizer=================                        \n",
    "# We also need to create an optimizer for updating weights\n",
    "opt = mx.optimizer.SGD(\n",
    "    learning_rate=.001,momentum=0.99,wd=0.000001)\n",
    "    \n",
    "updater = mx.optimizer.get_updater(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============Evaluation metric(s)================= \n",
    "metric = mx.metric.CustomMetric(feval=nn.dice_coef2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nn.get_net_315()\n",
    "init = mx.init.Normal(0.01) #note biases and gamma/beta are not affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Binding\n",
    "exe = network.simple_bind(ctx=mx.gpu(0), **input_shapes)\n",
    "# get handle to input arrays\n",
    "arg_arrays = dict(zip(network.list_arguments(), exe.arg_arrays))\n",
    "data = arg_arrays[train_iter.provide_data[0][0]]\n",
    "label = arg_arrays[train_iter.provide_label[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mas/.virtualenvs/colab/lib/python3.5/site-packages/ipykernel_launcher.py:3: DeprecationWarning: \u001b[91mCalling initializer with init(str, NDArray) has been deprecated.please use init(mx.init.InitDesc(...), NDArray) instead.\u001b[0m\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for name, arr in arg_arrays.items():\n",
    "    if name not in input_shapes:\n",
    "        init(name, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/mas/x110/model’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/mas/x110/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"/home/mas/x110/model/oct14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### import time\n",
    "\n",
    "for epoch in range(0,500):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    metric.reset()\n",
    "\n",
    "    train_iter.reset()\n",
    "    \n",
    "    valid_iter.reset()\n",
    "    \n",
    "\n",
    "    for batch in train_iter:\n",
    "        # Copy data to executor input. Note the [:].\n",
    "        data[:] = batch.data[0]\n",
    "        label[:] = batch.label[0]\n",
    "\n",
    "        # Forward\n",
    "        outputs=exe.forward(is_train=True)\n",
    "        # Backward\n",
    "        exe.backward()\n",
    "\n",
    "        # Update\n",
    "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
    "            weight, grad = pair\n",
    "            updater(i, grad, weight)   \n",
    "        metric.update(batch.label[0], exe.outputs[0])#metric.update(label,p)\n",
    "        \n",
    "    e=metric.get()\n",
    "    err_train=-e[1].asnumpy()[0]\n",
    "    \n",
    "    if epoch % 100== 0:       \n",
    "        #print(\"do_checkpoint\")\n",
    "        arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
    "        aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
    "        mx.model.save_checkpoint(prefix, epoch, network, arg, aux)\n",
    "        \n",
    "        \n",
    "    #compute valid loss per epoch    \n",
    "    metric.reset()\n",
    "    for batch in valid_iter:        \n",
    "        data[:] = batch.data[0]       \n",
    "        label[:] = batch.label[0]\n",
    "        # predict\n",
    "        outputs = exe.forward(is_train=False)\n",
    "        metric.update(batch.label[0], exe.outputs[0])\n",
    "    e=metric.get()\n",
    "    err_valid=-e[1].asnumpy()[0]\n",
    "    end = time.time()\n",
    "    print('time:',end-start,'Epoch:',epoch,'trainloss:',err_train,'validloss:',err_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4997afe8e65e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mupdater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#metric.update(label,p)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/colab/lib/python3.5/site-packages/mxnet/metric.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, labels, preds)\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0mreval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/colab/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1970\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1972\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1973\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### import time\n",
    "\n",
    "for epoch in range(200):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    metric.reset()\n",
    "\n",
    "    train_iter.reset()\n",
    "    \n",
    "    valid_iter.reset()\n",
    "    \n",
    "\n",
    "    for batch in train_iter:\n",
    "        # Copy data to executor input. Note the [:].\n",
    "        data[:] = batch.data[0]\n",
    "        label[:] = batch.label[0]\n",
    "\n",
    "        # Forward\n",
    "        outputs=exe.forward(is_train=True)\n",
    "        # Backward\n",
    "        exe.backward()\n",
    "\n",
    "        # Update\n",
    "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
    "            weight, grad = pair\n",
    "            updater(i, grad, weight)   \n",
    "        metric.update(batch.label[0], exe.outputs[0])#metric.update(label,p)\n",
    "        \n",
    "    e=metric.get()\n",
    "    err_train=-e[1].asnumpy()[0]\n",
    "    \n",
    "    if epoch % 100== 0:       \n",
    "        #print(\"do_checkpoint\")\n",
    "        arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
    "        aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
    "        mx.model.save_checkpoint(prefix, epoch, network, arg, aux)\n",
    "        \n",
    "        \n",
    "    #compute valid loss per epoch    \n",
    "    metric.reset()\n",
    "    for batch in valid_iter:        \n",
    "        data[:] = batch.data[0]       \n",
    "        label[:] = batch.label[0]\n",
    "        # predict\n",
    "        outputs = exe.forward(is_train=False)\n",
    "        metric.update(batch.label[0], exe.outputs[0])\n",
    "    e=metric.get()\n",
    "    err_valid=-e[1].asnumpy()[0]\n",
    "    end = time.time()\n",
    "    print('time:',end-start,'Epoch:',epoch,'trainloss:',err_train,'validloss:',err_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem. through the training and validation datasets are exacty the same. the trainloss of each dataset are very different. After some research (https://github.com/apache/incubator-mxnet/issues/960), it seems that batch normalization is off when training is false. i verified that, when train was kept on, both scores were almost identical.\n",
    "\n",
    "now i need to find a way, how to turn on batch normizaliztion when training is on. Lets do that!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "??mx.sym.BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.29866457 0.29593503 0.2816147  ... 0.29454064 0.28689206 0.26300156]]\n",
       "<NDArray 1x32768 @gpu(0)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exe.outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.29866457 0.29593503 0.2816147  ... 0.29454064 0.28689206 0.26300156]]\n",
       "<NDArray 1x32768 @gpu(0)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exe.outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [[0.29866457 0.29593503 0.2816147  ... 0.29454064 0.28689206 0.26300156]]\n",
       " <NDArray 1x32768 @gpu(0)>, \n",
       " [-0.05469904]\n",
       " <NDArray 1 @gpu(0)>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [[0.29866457 0.29593503 0.2816147  ... 0.29454064 0.28689206 0.26300156]]\n",
       " <NDArray 1x32768 @gpu(0)>, \n",
       " [-0.05469904]\n",
       " <NDArray 1 @gpu(0)>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = exe.forward(is_train=False)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [[0.00160489 0.00169011 0.00173485 ... 0.00175406 0.00178375 0.00178953]]\n",
       " <NDArray 1x32768 @gpu(0)>, \n",
       " [-0.8770253]\n",
       " <NDArray 1 @gpu(0)>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exe.forward(is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [[0.00172558 0.00170667 0.00174532 ... 0.00173335 0.00172738 0.0017705 ]]\n",
       " <NDArray 1x32768 @gpu(0)>, \n",
       " [-0.38141048]\n",
       " <NDArray 1 @gpu(0)>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exe.forward(is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.516444444656372 Epoch: 2500 trainloss: -0.70236623 validloss: -0.29707864\n",
      "time: 4.621006965637207 Epoch: 2501 trainloss: -0.70234936 validloss: -0.2971371\n",
      "time: 4.6672749519348145 Epoch: 2502 trainloss: -0.7023562 validloss: -0.2959454\n",
      "time: 4.579547166824341 Epoch: 2503 trainloss: -0.7023623 validloss: -0.29439247\n",
      "time: 4.555369138717651 Epoch: 2504 trainloss: -0.702376 validloss: -0.30203053\n",
      "time: 4.551843643188477 Epoch: 2505 trainloss: -0.70235974 validloss: -0.2942735\n",
      "time: 4.524325609207153 Epoch: 2506 trainloss: -0.7023142 validloss: -0.29789343\n",
      "time: 4.527269124984741 Epoch: 2507 trainloss: -0.7023604 validloss: -0.29580623\n",
      "time: 4.513974666595459 Epoch: 2508 trainloss: -0.7023506 validloss: -0.29714355\n",
      "time: 4.5370800495147705 Epoch: 2509 trainloss: -0.7023281 validloss: -0.29687744\n",
      "time: 4.520667791366577 Epoch: 2510 trainloss: -0.7023124 validloss: -0.29854307\n",
      "time: 4.564080476760864 Epoch: 2511 trainloss: -0.70233303 validloss: -0.297167\n",
      "time: 4.614370346069336 Epoch: 2512 trainloss: -0.7023285 validloss: -0.29117548\n",
      "time: 4.567943572998047 Epoch: 2513 trainloss: -0.7023136 validloss: -0.29881695\n",
      "time: 4.580925464630127 Epoch: 2514 trainloss: -0.70236695 validloss: -0.29281017\n",
      "time: 4.567919492721558 Epoch: 2515 trainloss: -0.70237154 validloss: -0.2980554\n",
      "time: 4.577297925949097 Epoch: 2516 trainloss: -0.7023795 validloss: -0.29727492\n",
      "time: 4.567946910858154 Epoch: 2517 trainloss: -0.7023828 validloss: -0.29085568\n",
      "time: 4.565935850143433 Epoch: 2518 trainloss: -0.7023645 validloss: -0.29773888\n",
      "time: 4.573970317840576 Epoch: 2519 trainloss: -0.70237094 validloss: -0.2995125\n",
      "time: 4.5573036670684814 Epoch: 2520 trainloss: -0.70236886 validloss: -0.29285648\n",
      "time: 4.590823411941528 Epoch: 2521 trainloss: -0.7023705 validloss: -0.30256763\n",
      "time: 4.567898273468018 Epoch: 2522 trainloss: -0.70233834 validloss: -0.29468304\n",
      "time: 4.566702842712402 Epoch: 2523 trainloss: -0.7023505 validloss: -0.29758757\n",
      "time: 4.568902015686035 Epoch: 2524 trainloss: -0.70233625 validloss: -0.29410994\n",
      "time: 4.589973449707031 Epoch: 2525 trainloss: -0.7023319 validloss: -0.2966269\n",
      "time: 4.5663909912109375 Epoch: 2526 trainloss: -0.7023328 validloss: -0.2967988\n",
      "time: 4.575597047805786 Epoch: 2527 trainloss: -0.7023458 validloss: -0.29798144\n",
      "time: 4.575370788574219 Epoch: 2528 trainloss: -0.70232916 validloss: -0.29028365\n",
      "time: 4.5706870555877686 Epoch: 2529 trainloss: -0.7023332 validloss: -0.29755968\n",
      "time: 4.575990915298462 Epoch: 2530 trainloss: -0.702305 validloss: -0.2963971\n",
      "time: 4.55956244468689 Epoch: 2531 trainloss: -0.7022935 validloss: -0.29321736\n",
      "time: 4.59139084815979 Epoch: 2532 trainloss: -0.70225453 validloss: -0.29880917\n",
      "time: 4.569045543670654 Epoch: 2533 trainloss: -0.7022727 validloss: -0.29586664\n",
      "time: 4.570318222045898 Epoch: 2534 trainloss: -0.70221156 validloss: -0.3008594\n",
      "time: 4.587849140167236 Epoch: 2535 trainloss: -0.7022423 validloss: -0.29423124\n",
      "time: 4.563790321350098 Epoch: 2536 trainloss: -0.7022713 validloss: -0.29730403\n",
      "time: 4.579657316207886 Epoch: 2537 trainloss: -0.7022315 validloss: -0.30102235\n",
      "time: 4.595233917236328 Epoch: 2538 trainloss: -0.70224994 validloss: -0.29356655\n",
      "time: 4.57925009727478 Epoch: 2539 trainloss: -0.7022594 validloss: -0.296068\n",
      "time: 4.569670677185059 Epoch: 2540 trainloss: -0.70225215 validloss: -0.29533997\n",
      "time: 4.5686585903167725 Epoch: 2541 trainloss: -0.7022422 validloss: -0.29516375\n",
      "time: 4.56119966506958 Epoch: 2542 trainloss: -0.70224786 validloss: -0.3003357\n",
      "time: 4.57418966293335 Epoch: 2543 trainloss: -0.70223266 validloss: -0.29068774\n",
      "time: 4.577542543411255 Epoch: 2544 trainloss: -0.70216554 validloss: -0.30128077\n",
      "time: 4.579204559326172 Epoch: 2545 trainloss: -0.7022007 validloss: -0.2997847\n",
      "time: 4.574904918670654 Epoch: 2546 trainloss: -0.7021853 validloss: -0.29165533\n",
      "time: 4.5758044719696045 Epoch: 2547 trainloss: -0.70215887 validloss: -0.30333763\n",
      "time: 4.5817389488220215 Epoch: 2548 trainloss: -0.7022083 validloss: -0.2981414\n",
      "time: 4.5582568645477295 Epoch: 2549 trainloss: -0.7021802 validloss: -0.29609144\n",
      "time: 4.571209192276001 Epoch: 2550 trainloss: -0.70226294 validloss: -0.29407322\n",
      "time: 4.569714784622192 Epoch: 2551 trainloss: -0.7022702 validloss: -0.299108\n",
      "time: 4.56989860534668 Epoch: 2552 trainloss: -0.7022961 validloss: -0.29682773\n",
      "time: 4.56330418586731 Epoch: 2553 trainloss: -0.7022896 validloss: -0.29672122\n",
      "time: 4.581475734710693 Epoch: 2554 trainloss: -0.70228255 validloss: -0.29711005\n",
      "time: 4.560522079467773 Epoch: 2555 trainloss: -0.7022482 validloss: -0.2955364\n",
      "time: 4.572124242782593 Epoch: 2556 trainloss: -0.70222247 validloss: -0.30270675\n",
      "time: 4.562808990478516 Epoch: 2557 trainloss: -0.7022423 validloss: -0.29473704\n",
      "time: 4.573055267333984 Epoch: 2558 trainloss: -0.70219475 validloss: -0.29523543\n",
      "time: 4.5637266635894775 Epoch: 2559 trainloss: -0.7022197 validloss: -0.3028471\n",
      "time: 4.560750722885132 Epoch: 2560 trainloss: -0.7021809 validloss: -0.2963333\n",
      "time: 4.577836513519287 Epoch: 2561 trainloss: -0.7022057 validloss: -0.29373857\n",
      "time: 4.560987710952759 Epoch: 2562 trainloss: -0.7022284 validloss: -0.29853934\n",
      "time: 4.569507598876953 Epoch: 2563 trainloss: -0.7021575 validloss: -0.29949594\n",
      "time: 4.584834098815918 Epoch: 2564 trainloss: -0.70223796 validloss: -0.297646\n",
      "time: 4.580082893371582 Epoch: 2565 trainloss: -0.70221233 validloss: -0.30047837\n",
      "time: 4.554674386978149 Epoch: 2566 trainloss: -0.702301 validloss: -0.29762116\n",
      "time: 4.567526578903198 Epoch: 2567 trainloss: -0.7022588 validloss: -0.30022928\n",
      "time: 4.58025050163269 Epoch: 2568 trainloss: -0.70225877 validloss: -0.29641545\n",
      "time: 4.556068181991577 Epoch: 2569 trainloss: -0.70222557 validloss: -0.29969215\n",
      "time: 4.597233295440674 Epoch: 2570 trainloss: -0.7022375 validloss: -0.30043992\n",
      "time: 4.584656238555908 Epoch: 2571 trainloss: -0.7022762 validloss: -0.29546985\n",
      "time: 4.574567794799805 Epoch: 2572 trainloss: -0.7022548 validloss: -0.2966743\n",
      "time: 4.569724798202515 Epoch: 2573 trainloss: -0.7022988 validloss: -0.30048415\n",
      "time: 4.572439193725586 Epoch: 2574 trainloss: -0.7022598 validloss: -0.29432938\n",
      "time: 4.582193613052368 Epoch: 2575 trainloss: -0.7023072 validloss: -0.29739016\n",
      "time: 4.561392068862915 Epoch: 2576 trainloss: -0.70230937 validloss: -0.29800987\n",
      "time: 4.568477392196655 Epoch: 2577 trainloss: -0.7022774 validloss: -0.2991725\n",
      "time: 4.577874183654785 Epoch: 2578 trainloss: -0.7023268 validloss: -0.29517785\n",
      "time: 4.552703142166138 Epoch: 2579 trainloss: -0.7023138 validloss: -0.29891098\n",
      "time: 4.563798189163208 Epoch: 2580 trainloss: -0.70234275 validloss: -0.30106592\n",
      "time: 4.582033395767212 Epoch: 2581 trainloss: -0.70236313 validloss: -0.29130438\n",
      "time: 4.556964635848999 Epoch: 2582 trainloss: -0.70236266 validloss: -0.30126363\n",
      "time: 4.583890914916992 Epoch: 2583 trainloss: -0.70234936 validloss: -0.29573804\n",
      "time: 4.5610671043396 Epoch: 2584 trainloss: -0.7023711 validloss: -0.29898375\n",
      "time: 4.573390245437622 Epoch: 2585 trainloss: -0.7023965 validloss: -0.2944178\n",
      "time: 4.57041072845459 Epoch: 2586 trainloss: -0.7023886 validloss: -0.2926617\n",
      "time: 4.561927080154419 Epoch: 2587 trainloss: -0.70237887 validloss: -0.30142528\n",
      "time: 4.577665090560913 Epoch: 2588 trainloss: -0.7023688 validloss: -0.2948434\n",
      "time: 4.560776233673096 Epoch: 2589 trainloss: -0.7023737 validloss: -0.2974605\n",
      "time: 4.5709381103515625 Epoch: 2590 trainloss: -0.70236796 validloss: -0.29856533\n",
      "time: 4.601932048797607 Epoch: 2591 trainloss: -0.70237315 validloss: -0.2984138\n",
      "time: 4.562798023223877 Epoch: 2592 trainloss: -0.70237195 validloss: -0.29558998\n",
      "time: 4.561415433883667 Epoch: 2593 trainloss: -0.7023788 validloss: -0.29563305\n",
      "time: 4.583448648452759 Epoch: 2594 trainloss: -0.7023755 validloss: -0.29281905\n",
      "time: 4.57590913772583 Epoch: 2595 trainloss: -0.7023599 validloss: -0.3012278\n",
      "time: 4.5621559619903564 Epoch: 2596 trainloss: -0.7023617 validloss: -0.29762593\n",
      "time: 4.57573676109314 Epoch: 2597 trainloss: -0.7023711 validloss: -0.29430884\n",
      "time: 4.571983337402344 Epoch: 2598 trainloss: -0.7023544 validloss: -0.30304724\n",
      "time: 4.565134525299072 Epoch: 2599 trainloss: -0.7023216 validloss: -0.29112765\n",
      "time: 4.570045709609985 Epoch: 2600 trainloss: -0.7022766 validloss: -0.29726613\n",
      "time: 4.568212032318115 Epoch: 2601 trainloss: -0.70230335 validloss: -0.2983166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.561078310012817 Epoch: 2602 trainloss: -0.70230144 validloss: -0.2944454\n",
      "time: 4.57177996635437 Epoch: 2603 trainloss: -0.70229954 validloss: -0.2965946\n",
      "time: 4.567963123321533 Epoch: 2604 trainloss: -0.7022533 validloss: -0.29560578\n",
      "time: 4.561437368392944 Epoch: 2605 trainloss: -0.7022405 validloss: -0.2972637\n",
      "time: 4.573138236999512 Epoch: 2606 trainloss: -0.70221305 validloss: -0.29315424\n",
      "time: 4.56632924079895 Epoch: 2607 trainloss: -0.702189 validloss: -0.3018634\n",
      "time: 4.575967073440552 Epoch: 2608 trainloss: -0.70219076 validloss: -0.29333794\n",
      "time: 4.566251516342163 Epoch: 2609 trainloss: -0.7021766 validloss: -0.29651532\n",
      "time: 4.573865175247192 Epoch: 2610 trainloss: -0.70221496 validloss: -0.2973286\n",
      "time: 4.568834066390991 Epoch: 2611 trainloss: -0.70218056 validloss: -0.29632455\n",
      "time: 4.571171760559082 Epoch: 2612 trainloss: -0.70219785 validloss: -0.2990767\n",
      "time: 4.572324275970459 Epoch: 2613 trainloss: -0.70220643 validloss: -0.29387426\n",
      "time: 4.578159332275391 Epoch: 2614 trainloss: -0.7022624 validloss: -0.29955226\n",
      "time: 4.571280002593994 Epoch: 2615 trainloss: -0.7022628 validloss: -0.2971874\n",
      "time: 4.566177606582642 Epoch: 2616 trainloss: -0.70233154 validloss: -0.29918835\n",
      "time: 4.6043381690979 Epoch: 2617 trainloss: -0.7023038 validloss: -0.2941856\n",
      "time: 4.561234712600708 Epoch: 2618 trainloss: -0.7023609 validloss: -0.2959995\n",
      "time: 4.5695788860321045 Epoch: 2619 trainloss: -0.7023306 validloss: -0.29460356\n",
      "time: 4.567326545715332 Epoch: 2620 trainloss: -0.70234376 validloss: -0.30071715\n",
      "time: 4.565606594085693 Epoch: 2621 trainloss: -0.7023643 validloss: -0.29469338\n",
      "time: 4.546269416809082 Epoch: 2622 trainloss: -0.70233786 validloss: -0.29849958\n",
      "time: 4.566141128540039 Epoch: 2623 trainloss: -0.7023786 validloss: -0.29274678\n",
      "time: 4.5712807178497314 Epoch: 2624 trainloss: -0.7023665 validloss: -0.29863563\n",
      "time: 4.55824875831604 Epoch: 2625 trainloss: -0.7023813 validloss: -0.29342243\n",
      "time: 4.569186210632324 Epoch: 2626 trainloss: -0.70240396 validloss: -0.29690292\n",
      "time: 4.575430870056152 Epoch: 2627 trainloss: -0.70236886 validloss: -0.2940838\n",
      "time: 4.552614212036133 Epoch: 2628 trainloss: -0.70238495 validloss: -0.2968955\n",
      "time: 4.566864490509033 Epoch: 2629 trainloss: -0.70238525 validloss: -0.2979311\n",
      "time: 4.573482990264893 Epoch: 2630 trainloss: -0.7023133 validloss: -0.2936555\n",
      "time: 4.552871465682983 Epoch: 2631 trainloss: -0.702311 validloss: -0.29968572\n",
      "time: 4.570700168609619 Epoch: 2632 trainloss: -0.7023018 validloss: -0.29964182\n",
      "time: 4.561850070953369 Epoch: 2633 trainloss: -0.70230347 validloss: -0.2933451\n",
      "time: 4.575420618057251 Epoch: 2634 trainloss: -0.7022823 validloss: -0.2983766\n",
      "time: 4.55962347984314 Epoch: 2635 trainloss: -0.702307 validloss: -0.29531744\n",
      "time: 4.575441122055054 Epoch: 2636 trainloss: -0.7022764 validloss: -0.2983103\n",
      "time: 4.5776238441467285 Epoch: 2637 trainloss: -0.7022992 validloss: -0.29822627\n",
      "time: 4.561616897583008 Epoch: 2638 trainloss: -0.7022695 validloss: -0.29636595\n",
      "time: 4.562889814376831 Epoch: 2639 trainloss: -0.7022581 validloss: -0.297319\n",
      "time: 4.571734189987183 Epoch: 2640 trainloss: -0.70223534 validloss: -0.30022138\n",
      "time: 4.5529186725616455 Epoch: 2641 trainloss: -0.7021737 validloss: -0.29913005\n",
      "time: 4.566702365875244 Epoch: 2642 trainloss: -0.70220906 validloss: -0.2933021\n",
      "time: 4.58931040763855 Epoch: 2643 trainloss: -0.7021607 validloss: -0.29603696\n",
      "time: 4.575551271438599 Epoch: 2644 trainloss: -0.70216066 validloss: -0.3031509\n",
      "time: 4.571584463119507 Epoch: 2645 trainloss: -0.70215046 validloss: -0.29565337\n",
      "time: 4.5525007247924805 Epoch: 2646 trainloss: -0.70215046 validloss: -0.29632753\n",
      "time: 4.569383382797241 Epoch: 2647 trainloss: -0.70220697 validloss: -0.30142385\n",
      "time: 4.568249940872192 Epoch: 2648 trainloss: -0.70222425 validloss: -0.2933612\n",
      "time: 4.570924520492554 Epoch: 2649 trainloss: -0.7022762 validloss: -0.29456237\n",
      "time: 4.579343557357788 Epoch: 2650 trainloss: -0.70230407 validloss: -0.2989511\n",
      "time: 4.568512678146362 Epoch: 2651 trainloss: -0.7022861 validloss: -0.29757443\n",
      "time: 4.555586576461792 Epoch: 2652 trainloss: -0.70229965 validloss: -0.29764774\n",
      "time: 4.581550121307373 Epoch: 2653 trainloss: -0.70229626 validloss: -0.296226\n",
      "time: 4.568812608718872 Epoch: 2654 trainloss: -0.70227927 validloss: -0.29688862\n",
      "time: 4.569766998291016 Epoch: 2655 trainloss: -0.7022976 validloss: -0.29761016\n",
      "time: 4.5747740268707275 Epoch: 2656 trainloss: -0.70233285 validloss: -0.29681462\n",
      "time: 4.570988655090332 Epoch: 2657 trainloss: -0.7024127 validloss: -0.29726025\n",
      "time: 4.567580699920654 Epoch: 2658 trainloss: -0.70238274 validloss: -0.29537055\n",
      "time: 4.5628697872161865 Epoch: 2659 trainloss: -0.702426 validloss: -0.29916883\n",
      "time: 4.579758882522583 Epoch: 2660 trainloss: -0.7024198 validloss: -0.29267797\n",
      "time: 4.564079523086548 Epoch: 2661 trainloss: -0.70244473 validloss: -0.29887384\n",
      "time: 4.571091651916504 Epoch: 2662 trainloss: -0.7024561 validloss: -0.29434526\n",
      "time: 4.580377817153931 Epoch: 2663 trainloss: -0.702448 validloss: -0.2972641\n",
      "time: 4.551179647445679 Epoch: 2664 trainloss: -0.70245606 validloss: -0.29683316\n",
      "time: 4.574992895126343 Epoch: 2665 trainloss: -0.70243186 validloss: -0.2899755\n",
      "time: 4.5825583934783936 Epoch: 2666 trainloss: -0.70244545 validloss: -0.29956684\n",
      "time: 4.581850528717041 Epoch: 2667 trainloss: -0.70244884 validloss: -0.29315835\n",
      "time: 4.562705993652344 Epoch: 2668 trainloss: -0.7024193 validloss: -0.29761168\n",
      "time: 4.587440013885498 Epoch: 2669 trainloss: -0.70241237 validloss: -0.29427272\n",
      "time: 4.5889060497283936 Epoch: 2670 trainloss: -0.70239216 validloss: -0.29194084\n",
      "time: 4.569189071655273 Epoch: 2671 trainloss: -0.702381 validloss: -0.29694054\n",
      "time: 4.5678324699401855 Epoch: 2672 trainloss: -0.70239484 validloss: -0.2971481\n",
      "time: 4.571725845336914 Epoch: 2673 trainloss: -0.702376 validloss: -0.2927686\n",
      "time: 4.574453592300415 Epoch: 2674 trainloss: -0.70238864 validloss: -0.29928195\n",
      "time: 4.555547714233398 Epoch: 2675 trainloss: -0.7023887 validloss: -0.29976463\n",
      "time: 4.55663800239563 Epoch: 2676 trainloss: -0.7023974 validloss: -0.2978177\n",
      "time: 4.57077431678772 Epoch: 2677 trainloss: -0.70238775 validloss: -0.29425895\n",
      "time: 4.569689750671387 Epoch: 2678 trainloss: -0.7023844 validloss: -0.29384091\n",
      "time: 4.574446201324463 Epoch: 2679 trainloss: -0.7023882 validloss: -0.29937515\n",
      "time: 4.574226379394531 Epoch: 2680 trainloss: -0.7023528 validloss: -0.29489934\n",
      "time: 4.575263500213623 Epoch: 2681 trainloss: -0.7023846 validloss: -0.29516962\n",
      "time: 4.562959432601929 Epoch: 2682 trainloss: -0.702356 validloss: -0.30115157\n",
      "time: 4.576396942138672 Epoch: 2683 trainloss: -0.70237905 validloss: -0.29526088\n",
      "time: 4.569896936416626 Epoch: 2684 trainloss: -0.70237315 validloss: -0.29820326\n",
      "time: 4.572187900543213 Epoch: 2685 trainloss: -0.7023303 validloss: -0.29398718\n",
      "time: 4.566401243209839 Epoch: 2686 trainloss: -0.70235884 validloss: -0.29888108\n",
      "time: 4.560838222503662 Epoch: 2687 trainloss: -0.7023366 validloss: -0.29339418\n",
      "time: 4.561448097229004 Epoch: 2688 trainloss: -0.70233196 validloss: -0.29830477\n",
      "time: 4.572962522506714 Epoch: 2689 trainloss: -0.7023585 validloss: -0.2992381\n",
      "time: 4.57147741317749 Epoch: 2690 trainloss: -0.7023443 validloss: -0.29305688\n",
      "time: 4.573888063430786 Epoch: 2691 trainloss: -0.702333 validloss: -0.29831657\n",
      "time: 4.595690965652466 Epoch: 2692 trainloss: -0.70232713 validloss: -0.29384032\n",
      "time: 4.554475784301758 Epoch: 2693 trainloss: -0.70224184 validloss: -0.29688707\n",
      "time: 4.563436508178711 Epoch: 2694 trainloss: -0.70227665 validloss: -0.2951796\n",
      "time: 4.574906587600708 Epoch: 2695 trainloss: -0.70230055 validloss: -0.29420352\n",
      "time: 4.611775159835815 Epoch: 2696 trainloss: -0.7023304 validloss: -0.30127293\n",
      "time: 4.572825193405151 Epoch: 2697 trainloss: -0.70235294 validloss: -0.29424965\n",
      "time: 4.554398059844971 Epoch: 2698 trainloss: -0.70230997 validloss: -0.29424992\n",
      "time: 4.5682337284088135 Epoch: 2699 trainloss: -0.7022989 validloss: -0.30047482\n",
      "time: 4.559551239013672 Epoch: 2700 trainloss: -0.7022529 validloss: -0.29597914\n",
      "time: 4.569775581359863 Epoch: 2701 trainloss: -0.70224047 validloss: -0.2943389\n",
      "time: 4.5749640464782715 Epoch: 2702 trainloss: -0.70229304 validloss: -0.29683644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.583647727966309 Epoch: 2703 trainloss: -0.7022745 validloss: -0.29594755\n",
      "time: 4.568508625030518 Epoch: 2704 trainloss: -0.70232296 validloss: -0.2967181\n",
      "time: 4.570454835891724 Epoch: 2705 trainloss: -0.70234734 validloss: -0.29470587\n",
      "time: 4.582773447036743 Epoch: 2706 trainloss: -0.70236033 validloss: -0.29693913\n",
      "time: 4.570705413818359 Epoch: 2707 trainloss: -0.70241 validloss: -0.29352164\n",
      "time: 4.564424991607666 Epoch: 2708 trainloss: -0.7024118 validloss: -0.2993722\n",
      "time: 4.582105398178101 Epoch: 2709 trainloss: -0.7024057 validloss: -0.29419726\n",
      "time: 4.567351341247559 Epoch: 2710 trainloss: -0.70237905 validloss: -0.2941742\n",
      "time: 4.563815593719482 Epoch: 2711 trainloss: -0.7023808 validloss: -0.3016219\n",
      "time: 4.575193405151367 Epoch: 2712 trainloss: -0.70239687 validloss: -0.2884622\n",
      "time: 4.560975551605225 Epoch: 2713 trainloss: -0.702416 validloss: -0.29619002\n",
      "time: 4.57065224647522 Epoch: 2714 trainloss: -0.7024284 validloss: -0.2974574\n",
      "time: 4.570815086364746 Epoch: 2715 trainloss: -0.70242524 validloss: -0.29293668\n",
      "time: 4.569873571395874 Epoch: 2716 trainloss: -0.7024305 validloss: -0.2960549\n",
      "time: 4.573011636734009 Epoch: 2717 trainloss: -0.7023953 validloss: -0.2977848\n",
      "time: 4.570470333099365 Epoch: 2718 trainloss: -0.702395 validloss: -0.29253247\n",
      "time: 4.575334310531616 Epoch: 2719 trainloss: -0.7023783 validloss: -0.29324177\n",
      "time: 4.570358991622925 Epoch: 2720 trainloss: -0.7023905 validloss: -0.29755726\n",
      "time: 4.554068088531494 Epoch: 2721 trainloss: -0.7023767 validloss: -0.29840213\n",
      "time: 4.619758367538452 Epoch: 2722 trainloss: -0.70241 validloss: -0.293767\n",
      "time: 4.565491199493408 Epoch: 2723 trainloss: -0.70242393 validloss: -0.2992453\n",
      "time: 4.576913356781006 Epoch: 2724 trainloss: -0.7024295 validloss: -0.29500884\n",
      "time: 4.557325601577759 Epoch: 2725 trainloss: -0.7024246 validloss: -0.29832703\n",
      "time: 4.571467876434326 Epoch: 2726 trainloss: -0.70242524 validloss: -0.293477\n",
      "time: 4.559585332870483 Epoch: 2727 trainloss: -0.702388 validloss: -0.2953612\n",
      "time: 4.560898780822754 Epoch: 2728 trainloss: -0.702429 validloss: -0.29511136\n",
      "time: 4.582248210906982 Epoch: 2729 trainloss: -0.7024206 validloss: -0.29649633\n",
      "time: 4.573827266693115 Epoch: 2730 trainloss: -0.70242345 validloss: -0.29246035\n",
      "time: 4.57345724105835 Epoch: 2731 trainloss: -0.702397 validloss: -0.2982194\n",
      "time: 4.575671911239624 Epoch: 2732 trainloss: -0.70238966 validloss: -0.29448885\n",
      "time: 4.550086736679077 Epoch: 2733 trainloss: -0.7023325 validloss: -0.29488784\n",
      "time: 4.5701987743377686 Epoch: 2734 trainloss: -0.7023581 validloss: -0.29553378\n",
      "time: 4.575430870056152 Epoch: 2735 trainloss: -0.70230544 validloss: -0.294445\n",
      "time: 4.5764429569244385 Epoch: 2736 trainloss: -0.7023197 validloss: -0.29779652\n",
      "time: 4.563612937927246 Epoch: 2737 trainloss: -0.7022933 validloss: -0.2964622\n",
      "time: 4.571946144104004 Epoch: 2738 trainloss: -0.7023378 validloss: -0.29631022\n",
      "time: 4.568268537521362 Epoch: 2739 trainloss: -0.70233595 validloss: -0.29098487\n",
      "time: 4.5611419677734375 Epoch: 2740 trainloss: -0.7023715 validloss: -0.29739457\n",
      "time: 4.56936502456665 Epoch: 2741 trainloss: -0.7023877 validloss: -0.29138607\n",
      "time: 4.588816165924072 Epoch: 2742 trainloss: -0.70240724 validloss: -0.2974376\n",
      "time: 4.567767381668091 Epoch: 2743 trainloss: -0.70237786 validloss: -0.29997715\n",
      "time: 4.557922124862671 Epoch: 2744 trainloss: -0.7023998 validloss: -0.29161215\n",
      "time: 4.584758996963501 Epoch: 2745 trainloss: -0.7024034 validloss: -0.29809722\n",
      "time: 4.571826219558716 Epoch: 2746 trainloss: -0.7024124 validloss: -0.29570946\n",
      "time: 4.562328815460205 Epoch: 2747 trainloss: -0.7024137 validloss: -0.2933876\n",
      "time: 4.595829963684082 Epoch: 2748 trainloss: -0.70243466 validloss: -0.29748592\n",
      "time: 4.5861005783081055 Epoch: 2749 trainloss: -0.70246613 validloss: -0.29685417\n",
      "time: 4.568985462188721 Epoch: 2750 trainloss: -0.70249104 validloss: -0.2928604\n",
      "time: 4.573951959609985 Epoch: 2751 trainloss: -0.7024878 validloss: -0.29923278\n",
      "time: 4.5785908699035645 Epoch: 2752 trainloss: -0.7024815 validloss: -0.29689676\n",
      "time: 4.572962522506714 Epoch: 2753 trainloss: -0.7024884 validloss: -0.29475883\n",
      "time: 4.5512659549713135 Epoch: 2754 trainloss: -0.70247924 validloss: -0.2968468\n",
      "time: 4.5714263916015625 Epoch: 2755 trainloss: -0.7024765 validloss: -0.29190102\n",
      "time: 4.564562559127808 Epoch: 2756 trainloss: -0.7024847 validloss: -0.29794922\n",
      "time: 4.575749397277832 Epoch: 2757 trainloss: -0.7024948 validloss: -0.29347798\n",
      "time: 4.57986855506897 Epoch: 2758 trainloss: -0.70247185 validloss: -0.29893544\n",
      "time: 4.577874183654785 Epoch: 2759 trainloss: -0.70246357 validloss: -0.2951505\n",
      "time: 4.548439025878906 Epoch: 2760 trainloss: -0.7024615 validloss: -0.29411632\n",
      "time: 4.563550233840942 Epoch: 2761 trainloss: -0.7024184 validloss: -0.29932758\n",
      "time: 4.5768187046051025 Epoch: 2762 trainloss: -0.70241874 validloss: -0.2890457\n",
      "time: 4.54978609085083 Epoch: 2763 trainloss: -0.70242894 validloss: -0.2978996\n",
      "time: 4.558335065841675 Epoch: 2764 trainloss: -0.7024301 validloss: -0.294367\n",
      "time: 4.578176736831665 Epoch: 2765 trainloss: -0.70241696 validloss: -0.29243046\n",
      "time: 4.5756847858428955 Epoch: 2766 trainloss: -0.70242304 validloss: -0.29676992\n",
      "time: 4.583864212036133 Epoch: 2767 trainloss: -0.70242566 validloss: -0.2960234\n",
      "time: 4.574518442153931 Epoch: 2768 trainloss: -0.70242274 validloss: -0.29420555\n",
      "time: 4.5702972412109375 Epoch: 2769 trainloss: -0.70246524 validloss: -0.29382318\n",
      "time: 4.574650764465332 Epoch: 2770 trainloss: -0.7024498 validloss: -0.2969041\n",
      "time: 4.570684909820557 Epoch: 2771 trainloss: -0.7024412 validloss: -0.2962903\n",
      "time: 4.5719733238220215 Epoch: 2772 trainloss: -0.702395 validloss: -0.2922455\n",
      "time: 4.5636115074157715 Epoch: 2773 trainloss: -0.7024133 validloss: -0.29669002\n",
      "time: 4.581916332244873 Epoch: 2774 trainloss: -0.70239496 validloss: -0.29298386\n",
      "time: 4.581945180892944 Epoch: 2775 trainloss: -0.70241076 validloss: -0.2946431\n",
      "time: 4.571504592895508 Epoch: 2776 trainloss: -0.7023604 validloss: -0.29807746\n",
      "time: 4.562633991241455 Epoch: 2777 trainloss: -0.7023807 validloss: -0.29443425\n",
      "time: 4.576824903488159 Epoch: 2778 trainloss: -0.7024274 validloss: -0.29178464\n",
      "time: 4.564605236053467 Epoch: 2779 trainloss: -0.7024306 validloss: -0.2971695\n",
      "time: 4.571022987365723 Epoch: 2780 trainloss: -0.70243835 validloss: -0.29576883\n",
      "time: 4.582045555114746 Epoch: 2781 trainloss: -0.7024171 validloss: -0.2941695\n",
      "time: 4.564028978347778 Epoch: 2782 trainloss: -0.7024188 validloss: -0.2920699\n",
      "time: 4.563248634338379 Epoch: 2783 trainloss: -0.7024192 validloss: -0.29646647\n",
      "time: 4.569058895111084 Epoch: 2784 trainloss: -0.70242786 validloss: -0.29267114\n",
      "time: 4.567444086074829 Epoch: 2785 trainloss: -0.7024342 validloss: -0.2954032\n",
      "time: 4.566377639770508 Epoch: 2786 trainloss: -0.7024484 validloss: -0.29958227\n",
      "time: 4.560327529907227 Epoch: 2787 trainloss: -0.7024198 validloss: -0.29165375\n",
      "time: 4.575138807296753 Epoch: 2788 trainloss: -0.7024418 validloss: -0.29547676\n",
      "time: 4.577015161514282 Epoch: 2789 trainloss: -0.70243704 validloss: -0.29569322\n",
      "time: 4.5990376472473145 Epoch: 2790 trainloss: -0.70243937 validloss: -0.29283696\n",
      "time: 4.570257186889648 Epoch: 2791 trainloss: -0.70242786 validloss: -0.29369032\n",
      "time: 4.572630405426025 Epoch: 2792 trainloss: -0.70243347 validloss: -0.2960263\n",
      "time: 4.569288969039917 Epoch: 2793 trainloss: -0.70244455 validloss: -0.29404247\n",
      "time: 4.581172704696655 Epoch: 2794 trainloss: -0.7024247 validloss: -0.2961417\n",
      "time: 4.58452582359314 Epoch: 2795 trainloss: -0.70239556 validloss: -0.291675\n",
      "time: 4.570510625839233 Epoch: 2796 trainloss: -0.70240724 validloss: -0.2968892\n",
      "time: 4.575358629226685 Epoch: 2797 trainloss: -0.70240605 validloss: -0.29399294\n",
      "time: 4.587168216705322 Epoch: 2798 trainloss: -0.70240015 validloss: -0.29189563\n",
      "time: 4.5687339305877686 Epoch: 2799 trainloss: -0.7024188 validloss: -0.2926733\n",
      "time: 4.56634783744812 Epoch: 2800 trainloss: -0.70241654 validloss: -0.29412887\n",
      "time: 4.620810031890869 Epoch: 2801 trainloss: -0.70244676 validloss: -0.291393\n",
      "time: 4.560084342956543 Epoch: 2802 trainloss: -0.702461 validloss: -0.29516247\n",
      "time: 4.578432321548462 Epoch: 2803 trainloss: -0.70247024 validloss: -0.29450566\n",
      "time: 4.574486017227173 Epoch: 2804 trainloss: -0.7024437 validloss: -0.29389763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.579254865646362 Epoch: 2805 trainloss: -0.7024528 validloss: -0.28893304\n",
      "time: 4.574340105056763 Epoch: 2806 trainloss: -0.70243853 validloss: -0.29832736\n",
      "time: 4.573396921157837 Epoch: 2807 trainloss: -0.7023933 validloss: -0.29854703\n",
      "time: 4.576547145843506 Epoch: 2808 trainloss: -0.7024137 validloss: -0.28720343\n",
      "time: 4.568594932556152 Epoch: 2809 trainloss: -0.70241934 validloss: -0.29760045\n",
      "time: 4.570388317108154 Epoch: 2810 trainloss: -0.7023631 validloss: -0.29377264\n",
      "time: 4.588615894317627 Epoch: 2811 trainloss: -0.7023813 validloss: -0.294179\n",
      "time: 4.55847430229187 Epoch: 2812 trainloss: -0.7023512 validloss: -0.29439148\n",
      "time: 4.575485944747925 Epoch: 2813 trainloss: -0.70241916 validloss: -0.29551017\n",
      "time: 4.577100992202759 Epoch: 2814 trainloss: -0.70241183 validloss: -0.29946712\n",
      "time: 4.568663120269775 Epoch: 2815 trainloss: -0.7024496 validloss: -0.2910438\n",
      "time: 4.572206497192383 Epoch: 2816 trainloss: -0.7024538 validloss: -0.2975362\n",
      "time: 4.565402030944824 Epoch: 2817 trainloss: -0.70243734 validloss: -0.29529637\n",
      "time: 4.578608989715576 Epoch: 2818 trainloss: -0.70248383 validloss: -0.29681724\n",
      "time: 4.564316034317017 Epoch: 2819 trainloss: -0.7024747 validloss: -0.29377806\n",
      "time: 4.573001384735107 Epoch: 2820 trainloss: -0.70244795 validloss: -0.29733065\n",
      "time: 4.571215867996216 Epoch: 2821 trainloss: -0.70247865 validloss: -0.29570174\n",
      "time: 4.577670574188232 Epoch: 2822 trainloss: -0.7024284 validloss: -0.2942267\n",
      "time: 4.573105335235596 Epoch: 2823 trainloss: -0.7024697 validloss: -0.29360324\n",
      "time: 4.5858399868011475 Epoch: 2824 trainloss: -0.7024045 validloss: -0.2953787\n",
      "time: 4.577601671218872 Epoch: 2825 trainloss: -0.7024622 validloss: -0.29553315\n",
      "time: 4.5650634765625 Epoch: 2826 trainloss: -0.70243466 validloss: -0.2972853\n",
      "time: 4.602927923202515 Epoch: 2827 trainloss: -0.70242494 validloss: -0.29140866\n",
      "time: 4.569525241851807 Epoch: 2828 trainloss: -0.702423 validloss: -0.29644412\n",
      "time: 4.5744640827178955 Epoch: 2829 trainloss: -0.7024547 validloss: -0.29367185\n",
      "time: 4.5825324058532715 Epoch: 2830 trainloss: -0.7024654 validloss: -0.2975123\n",
      "time: 4.57250714302063 Epoch: 2831 trainloss: -0.7024741 validloss: -0.29139692\n",
      "time: 4.566523790359497 Epoch: 2832 trainloss: -0.702468 validloss: -0.29673153\n",
      "time: 4.565241098403931 Epoch: 2833 trainloss: -0.7024715 validloss: -0.29465\n",
      "time: 4.583712339401245 Epoch: 2834 trainloss: -0.7024809 validloss: -0.2931391\n",
      "time: 4.574899673461914 Epoch: 2835 trainloss: -0.70245826 validloss: -0.29777429\n",
      "time: 4.570721626281738 Epoch: 2836 trainloss: -0.7024973 validloss: -0.29377055\n",
      "time: 4.582873106002808 Epoch: 2837 trainloss: -0.70247173 validloss: -0.2923506\n",
      "time: 4.568867921829224 Epoch: 2838 trainloss: -0.70248413 validloss: -0.29932028\n",
      "time: 4.578595399856567 Epoch: 2839 trainloss: -0.702483 validloss: -0.2923871\n",
      "time: 4.568017244338989 Epoch: 2840 trainloss: -0.702525 validloss: -0.29386517\n",
      "time: 4.584360361099243 Epoch: 2841 trainloss: -0.702498 validloss: -0.29448617\n",
      "time: 4.573676109313965 Epoch: 2842 trainloss: -0.70249975 validloss: -0.29948533\n",
      "time: 4.561192274093628 Epoch: 2843 trainloss: -0.70250314 validloss: -0.29556924\n",
      "time: 4.570810079574585 Epoch: 2844 trainloss: -0.70249003 validloss: -0.29046303\n",
      "time: 4.5603227615356445 Epoch: 2845 trainloss: -0.70248425 validloss: -0.29960373\n",
      "time: 4.57659125328064 Epoch: 2846 trainloss: -0.70247394 validloss: -0.29027054\n",
      "time: 4.569286823272705 Epoch: 2847 trainloss: -0.7024744 validloss: -0.2951864\n",
      "time: 4.628487586975098 Epoch: 2848 trainloss: -0.702516 validloss: -0.29744622\n",
      "time: 4.575946807861328 Epoch: 2849 trainloss: -0.70251584 validloss: -0.29379857\n",
      "time: 4.57525110244751 Epoch: 2850 trainloss: -0.7025011 validloss: -0.29799655\n",
      "time: 4.572213888168335 Epoch: 2851 trainloss: -0.70249456 validloss: -0.2905219\n",
      "time: 4.570505619049072 Epoch: 2852 trainloss: -0.7024706 validloss: -0.2938016\n",
      "time: 4.5984413623809814 Epoch: 2853 trainloss: -0.7025092 validloss: -0.30058813\n",
      "time: 4.621093034744263 Epoch: 2854 trainloss: -0.7024423 validloss: -0.29071054\n",
      "time: 4.558681488037109 Epoch: 2855 trainloss: -0.7025006 validloss: -0.292644\n",
      "time: 4.571994304656982 Epoch: 2856 trainloss: -0.70246804 validloss: -0.29919288\n",
      "time: 4.576147794723511 Epoch: 2857 trainloss: -0.7024758 validloss: -0.29317805\n",
      "time: 4.564472913742065 Epoch: 2858 trainloss: -0.7024456 validloss: -0.29639748\n",
      "time: 4.568226337432861 Epoch: 2859 trainloss: -0.7024879 validloss: -0.2949672\n",
      "time: 4.576107978820801 Epoch: 2860 trainloss: -0.70247686 validloss: -0.29092357\n",
      "time: 4.5791802406311035 Epoch: 2861 trainloss: -0.70248973 validloss: -0.30031556\n",
      "time: 4.558658599853516 Epoch: 2862 trainloss: -0.70250887 validloss: -0.29249454\n",
      "time: 4.560712575912476 Epoch: 2863 trainloss: -0.7025138 validloss: -0.2931167\n",
      "time: 4.5769312381744385 Epoch: 2864 trainloss: -0.7024872 validloss: -0.30078647\n",
      "time: 4.5685224533081055 Epoch: 2865 trainloss: -0.70246285 validloss: -0.2925071\n",
      "time: 4.579394578933716 Epoch: 2866 trainloss: -0.70242864 validloss: -0.2958145\n",
      "time: 4.577822208404541 Epoch: 2867 trainloss: -0.7023951 validloss: -0.28964227\n",
      "time: 4.562565088272095 Epoch: 2868 trainloss: -0.7023949 validloss: -0.29710704\n",
      "time: 4.555102825164795 Epoch: 2869 trainloss: -0.70239073 validloss: -0.29586792\n",
      "time: 4.584985256195068 Epoch: 2870 trainloss: -0.70240957 validloss: -0.28873506\n",
      "time: 4.5590598583221436 Epoch: 2871 trainloss: -0.70244765 validloss: -0.2980641\n",
      "time: 4.563437223434448 Epoch: 2872 trainloss: -0.7024521 validloss: -0.29315\n",
      "time: 4.57841944694519 Epoch: 2873 trainloss: -0.7024679 validloss: -0.2973173\n",
      "time: 4.580923795700073 Epoch: 2874 trainloss: -0.7024717 validloss: -0.29202348\n",
      "time: 4.5714428424835205 Epoch: 2875 trainloss: -0.7024891 validloss: -0.2971326\n",
      "time: 4.584340572357178 Epoch: 2876 trainloss: -0.7025182 validloss: -0.2981808\n",
      "time: 4.558298587799072 Epoch: 2877 trainloss: -0.7025042 validloss: -0.29457995\n",
      "time: 4.562376260757446 Epoch: 2878 trainloss: -0.70252633 validloss: -0.294463\n",
      "time: 4.595599889755249 Epoch: 2879 trainloss: -0.70252 validloss: -0.29415935\n",
      "time: 4.59321141242981 Epoch: 2880 trainloss: -0.70254284 validloss: -0.29728827\n",
      "time: 4.560636758804321 Epoch: 2881 trainloss: -0.70254064 validloss: -0.29408202\n",
      "time: 4.568495273590088 Epoch: 2882 trainloss: -0.702502 validloss: -0.29379565\n",
      "time: 4.569829225540161 Epoch: 2883 trainloss: -0.7024955 validloss: -0.29570243\n",
      "time: 4.5683066844940186 Epoch: 2884 trainloss: -0.7025164 validloss: -0.29192212\n",
      "time: 4.571341037750244 Epoch: 2885 trainloss: -0.7025176 validloss: -0.29618737\n",
      "time: 4.571312427520752 Epoch: 2886 trainloss: -0.70252484 validloss: -0.29344308\n",
      "time: 4.578555345535278 Epoch: 2887 trainloss: -0.7025473 validloss: -0.29236007\n",
      "time: 4.57094407081604 Epoch: 2888 trainloss: -0.702545 validloss: -0.2954273\n",
      "time: 4.571927785873413 Epoch: 2889 trainloss: -0.7025388 validloss: -0.2938406\n",
      "time: 4.576622486114502 Epoch: 2890 trainloss: -0.70250934 validloss: -0.29539195\n",
      "time: 4.564443588256836 Epoch: 2891 trainloss: -0.7024808 validloss: -0.29695675\n",
      "time: 4.559292316436768 Epoch: 2892 trainloss: -0.7024988 validloss: -0.2936761\n",
      "time: 4.579190015792847 Epoch: 2893 trainloss: -0.70247567 validloss: -0.2981772\n",
      "time: 4.564971446990967 Epoch: 2894 trainloss: -0.7025113 validloss: -0.29090238\n",
      "time: 4.570119619369507 Epoch: 2895 trainloss: -0.7025092 validloss: -0.29539272\n",
      "time: 4.570910930633545 Epoch: 2896 trainloss: -0.7025142 validloss: -0.2931514\n",
      "time: 4.570117950439453 Epoch: 2897 trainloss: -0.7025336 validloss: -0.29672647\n",
      "time: 4.560596227645874 Epoch: 2898 trainloss: -0.7024982 validloss: -0.29289103\n",
      "time: 4.574940919876099 Epoch: 2899 trainloss: -0.7025187 validloss: -0.29370335\n",
      "time: 4.5852766036987305 Epoch: 2900 trainloss: -0.70253193 validloss: -0.29651326\n",
      "time: 4.57010817527771 Epoch: 2901 trainloss: -0.7024921 validloss: -0.29213795\n",
      "time: 4.572630405426025 Epoch: 2902 trainloss: -0.7025247 validloss: -0.29727665\n",
      "time: 4.579155206680298 Epoch: 2903 trainloss: -0.70248437 validloss: -0.29092044\n",
      "time: 4.563711404800415 Epoch: 2904 trainloss: -0.7025184 validloss: -0.29910508\n",
      "time: 4.572164535522461 Epoch: 2905 trainloss: -0.70249933 validloss: -0.29262012\n",
      "time: 4.597558498382568 Epoch: 2906 trainloss: -0.70250833 validloss: -0.29553598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.566769361495972 Epoch: 2907 trainloss: -0.70250195 validloss: -0.29473305\n",
      "time: 4.573697328567505 Epoch: 2908 trainloss: -0.70247173 validloss: -0.29449788\n",
      "time: 4.570273160934448 Epoch: 2909 trainloss: -0.7024419 validloss: -0.29733792\n",
      "time: 4.649867296218872 Epoch: 2910 trainloss: -0.702444 validloss: -0.29415658\n",
      "time: 4.719085454940796 Epoch: 2911 trainloss: -0.7024358 validloss: -0.29516274\n",
      "time: 4.763303279876709 Epoch: 2912 trainloss: -0.70247155 validloss: -0.2960867\n",
      "time: 4.713476657867432 Epoch: 2913 trainloss: -0.7024604 validloss: -0.29579356\n",
      "time: 4.711040735244751 Epoch: 2914 trainloss: -0.70248145 validloss: -0.29529268\n",
      "time: 4.635579347610474 Epoch: 2915 trainloss: -0.70244116 validloss: -0.29542756\n",
      "time: 4.592002868652344 Epoch: 2916 trainloss: -0.702455 validloss: -0.29583907\n",
      "time: 4.579737901687622 Epoch: 2917 trainloss: -0.702401 validloss: -0.29371566\n",
      "time: 4.5509192943573 Epoch: 2918 trainloss: -0.70245504 validloss: -0.2945195\n",
      "time: 4.587364673614502 Epoch: 2919 trainloss: -0.70241076 validloss: -0.29555482\n",
      "time: 4.555701017379761 Epoch: 2920 trainloss: -0.7023963 validloss: -0.29646996\n",
      "time: 4.569007158279419 Epoch: 2921 trainloss: -0.7023809 validloss: -0.2941106\n",
      "time: 4.578217267990112 Epoch: 2922 trainloss: -0.7023508 validloss: -0.292279\n",
      "time: 4.581686496734619 Epoch: 2923 trainloss: -0.70236826 validloss: -0.29903397\n",
      "time: 4.571936845779419 Epoch: 2924 trainloss: -0.7023645 validloss: -0.29544857\n",
      "time: 4.5685155391693115 Epoch: 2925 trainloss: -0.70237565 validloss: -0.2930531\n",
      "time: 4.5638511180877686 Epoch: 2926 trainloss: -0.7023511 validloss: -0.29942182\n",
      "time: 4.565073490142822 Epoch: 2927 trainloss: -0.70236635 validloss: -0.3002509\n",
      "time: 4.57956862449646 Epoch: 2928 trainloss: -0.7023915 validloss: -0.2938128\n",
      "time: 4.588752746582031 Epoch: 2929 trainloss: -0.70244765 validloss: -0.29510438\n",
      "time: 4.576296329498291 Epoch: 2930 trainloss: -0.70244855 validloss: -0.30125955\n",
      "time: 4.589501142501831 Epoch: 2931 trainloss: -0.70245135 validloss: -0.2924285\n",
      "time: 4.61287784576416 Epoch: 2932 trainloss: -0.70249003 validloss: -0.2970961\n",
      "time: 4.573055267333984 Epoch: 2933 trainloss: -0.70246243 validloss: -0.29532784\n",
      "time: 4.5757904052734375 Epoch: 2934 trainloss: -0.70243156 validloss: -0.2973911\n",
      "time: 4.567349195480347 Epoch: 2935 trainloss: -0.70239866 validloss: -0.29697183\n",
      "time: 4.5771520137786865 Epoch: 2936 trainloss: -0.70236415 validloss: -0.2941846\n",
      "time: 4.5599446296691895 Epoch: 2937 trainloss: -0.7023863 validloss: -0.29313022\n",
      "time: 4.5632545948028564 Epoch: 2938 trainloss: -0.70237964 validloss: -0.30098835\n",
      "time: 4.568865060806274 Epoch: 2939 trainloss: -0.7024004 validloss: -0.29213685\n",
      "time: 4.565873861312866 Epoch: 2940 trainloss: -0.70237756 validloss: -0.29306474\n",
      "time: 4.5647923946380615 Epoch: 2941 trainloss: -0.7023826 validloss: -0.29722047\n",
      "time: 4.575844049453735 Epoch: 2942 trainloss: -0.7024264 validloss: -0.29406494\n",
      "time: 4.5770792961120605 Epoch: 2943 trainloss: -0.7024178 validloss: -0.29324985\n",
      "time: 4.568225622177124 Epoch: 2944 trainloss: -0.7024273 validloss: -0.30056462\n",
      "time: 4.578745603561401 Epoch: 2945 trainloss: -0.7024005 validloss: -0.29098108\n",
      "time: 4.565522909164429 Epoch: 2946 trainloss: -0.70244193 validloss: -0.295287\n",
      "time: 4.567845344543457 Epoch: 2947 trainloss: -0.70241714 validloss: -0.2972669\n",
      "time: 4.568136215209961 Epoch: 2948 trainloss: -0.70242405 validloss: -0.2911743\n",
      "time: 4.5734968185424805 Epoch: 2949 trainloss: -0.7024201 validloss: -0.2977888\n",
      "time: 4.57329535484314 Epoch: 2950 trainloss: -0.70245075 validloss: -0.2961023\n",
      "time: 4.564310073852539 Epoch: 2951 trainloss: -0.7024584 validloss: -0.29203123\n",
      "time: 4.578167676925659 Epoch: 2952 trainloss: -0.7024587 validloss: -0.29777116\n",
      "time: 4.567332029342651 Epoch: 2953 trainloss: -0.7024422 validloss: -0.2892464\n",
      "time: 4.569270133972168 Epoch: 2954 trainloss: -0.70244235 validloss: -0.2981435\n",
      "time: 4.5670013427734375 Epoch: 2955 trainloss: -0.7024811 validloss: -0.2942842\n",
      "time: 4.61769700050354 Epoch: 2956 trainloss: -0.7024976 validloss: -0.2962913\n",
      "time: 4.976343631744385 Epoch: 2957 trainloss: -0.7024795 validloss: -0.2985719\n",
      "time: 4.9209301471710205 Epoch: 2958 trainloss: -0.702521 validloss: -0.29234332\n",
      "time: 4.933210611343384 Epoch: 2959 trainloss: -0.70251703 validloss: -0.29602793\n",
      "time: 4.891407251358032 Epoch: 2960 trainloss: -0.7025169 validloss: -0.2927146\n",
      "time: 5.03455114364624 Epoch: 2961 trainloss: -0.7025255 validloss: -0.2940651\n",
      "time: 4.700438499450684 Epoch: 2962 trainloss: -0.7025158 validloss: -0.29305595\n",
      "time: 4.647987365722656 Epoch: 2963 trainloss: -0.7025276 validloss: -0.29323527\n",
      "time: 4.612087965011597 Epoch: 2964 trainloss: -0.70251495 validloss: -0.29421148\n",
      "time: 4.614691972732544 Epoch: 2965 trainloss: -0.7024714 validloss: -0.2955363\n",
      "time: 4.639475584030151 Epoch: 2966 trainloss: -0.70247847 validloss: -0.2912756\n",
      "time: 5.334638595581055 Epoch: 2967 trainloss: -0.70243 validloss: -0.2958655\n",
      "time: 5.074203252792358 Epoch: 2968 trainloss: -0.70244443 validloss: -0.29467636\n",
      "time: 4.950617074966431 Epoch: 2969 trainloss: -0.7024669 validloss: -0.29245168\n",
      "time: 4.922929048538208 Epoch: 2970 trainloss: -0.7024444 validloss: -0.29593837\n",
      "time: 5.2244672775268555 Epoch: 2971 trainloss: -0.7024587 validloss: -0.29529417\n",
      "time: 4.818454027175903 Epoch: 2972 trainloss: -0.702433 validloss: -0.29623684\n",
      "time: 4.698940753936768 Epoch: 2973 trainloss: -0.70245904 validloss: -0.2922855\n",
      "time: 4.845360994338989 Epoch: 2974 trainloss: -0.702418 validloss: -0.2939219\n",
      "time: 4.825149297714233 Epoch: 2975 trainloss: -0.7023943 validloss: -0.2950029\n",
      "time: 4.724874019622803 Epoch: 2976 trainloss: -0.7024257 validloss: -0.29518068\n",
      "time: 4.573134660720825 Epoch: 2977 trainloss: -0.70242786 validloss: -0.29474312\n",
      "time: 4.544979095458984 Epoch: 2978 trainloss: -0.702449 validloss: -0.29753032\n",
      "time: 4.528940677642822 Epoch: 2979 trainloss: -0.70244837 validloss: -0.29457757\n",
      "time: 4.559185266494751 Epoch: 2980 trainloss: -0.70247436 validloss: -0.2967682\n",
      "time: 4.6429524421691895 Epoch: 2981 trainloss: -0.7024824 validloss: -0.29552603\n",
      "time: 4.6823742389678955 Epoch: 2982 trainloss: -0.70245606 validloss: -0.2946262\n",
      "time: 4.557300329208374 Epoch: 2983 trainloss: -0.7024129 validloss: -0.29630768\n",
      "time: 4.533808946609497 Epoch: 2984 trainloss: -0.7024049 validloss: -0.295939\n",
      "time: 4.513658046722412 Epoch: 2985 trainloss: -0.70244926 validloss: -0.29687855\n",
      "time: 4.546915292739868 Epoch: 2986 trainloss: -0.70240843 validloss: -0.29612902\n",
      "time: 4.530309200286865 Epoch: 2987 trainloss: -0.7024629 validloss: -0.29472342\n",
      "time: 4.5312933921813965 Epoch: 2988 trainloss: -0.70245236 validloss: -0.29540578\n",
      "time: 4.527599811553955 Epoch: 2989 trainloss: -0.70248157 validloss: -0.2975644\n",
      "time: 4.544196844100952 Epoch: 2990 trainloss: -0.70245445 validloss: -0.29561535\n",
      "time: 4.542089939117432 Epoch: 2991 trainloss: -0.7024702 validloss: -0.29363123\n",
      "time: 4.548856019973755 Epoch: 2992 trainloss: -0.7024492 validloss: -0.29833212\n",
      "time: 4.718136548995972 Epoch: 2993 trainloss: -0.7024416 validloss: -0.29597634\n",
      "time: 4.650972127914429 Epoch: 2994 trainloss: -0.70245576 validloss: -0.2934597\n",
      "time: 4.636493921279907 Epoch: 2995 trainloss: -0.702431 validloss: -0.2990202\n",
      "time: 4.632194757461548 Epoch: 2996 trainloss: -0.7024704 validloss: -0.29558238\n",
      "time: 4.5206828117370605 Epoch: 2997 trainloss: -0.70249385 validloss: -0.2951316\n",
      "time: 4.613666534423828 Epoch: 2998 trainloss: -0.7025128 validloss: -0.2924046\n",
      "time: 4.964691400527954 Epoch: 2999 trainloss: -0.7024738 validloss: -0.29408392\n",
      "time: 4.896257162094116 Epoch: 3000 trainloss: -0.70250297 validloss: -0.29973823\n",
      "time: 4.705104827880859 Epoch: 3001 trainloss: -0.7024524 validloss: -0.28893298\n",
      "time: 4.53694224357605 Epoch: 3002 trainloss: -0.7024936 validloss: -0.29782176\n",
      "time: 4.813005685806274 Epoch: 3003 trainloss: -0.70251024 validloss: -0.2950874\n",
      "time: 4.593816518783569 Epoch: 3004 trainloss: -0.702519 validloss: -0.2920597\n",
      "time: 4.719567060470581 Epoch: 3005 trainloss: -0.70254445 validloss: -0.29532185\n",
      "time: 5.082395553588867 Epoch: 3006 trainloss: -0.70250434 validloss: -0.293239\n",
      "time: 4.626352071762085 Epoch: 3007 trainloss: -0.70254993 validloss: -0.29740816\n",
      "time: 4.595390319824219 Epoch: 3008 trainloss: -0.70250356 validloss: -0.29264128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.631779193878174 Epoch: 3009 trainloss: -0.70252204 validloss: -0.29532117\n",
      "time: 4.503279447555542 Epoch: 3010 trainloss: -0.7024915 validloss: -0.29536164\n",
      "time: 4.757777214050293 Epoch: 3011 trainloss: -0.7024901 validloss: -0.29460043\n",
      "time: 4.792490482330322 Epoch: 3012 trainloss: -0.70241505 validloss: -0.29695764\n",
      "time: 4.842281341552734 Epoch: 3013 trainloss: -0.7023927 validloss: -0.29271594\n",
      "time: 4.604650020599365 Epoch: 3014 trainloss: -0.70232344 validloss: -0.30037168\n",
      "time: 4.514425992965698 Epoch: 3015 trainloss: -0.70238346 validloss: -0.29642534\n",
      "time: 4.563166379928589 Epoch: 3016 trainloss: -0.7023616 validloss: -0.28881383\n",
      "time: 4.7684853076934814 Epoch: 3017 trainloss: -0.7023941 validloss: -0.3019551\n",
      "time: 4.84251856803894 Epoch: 3018 trainloss: -0.7024532 validloss: -0.29494545\n",
      "time: 4.5323100090026855 Epoch: 3019 trainloss: -0.70247185 validloss: -0.29672715\n",
      "time: 4.525135040283203 Epoch: 3020 trainloss: -0.70255244 validloss: -0.29361525\n",
      "time: 4.505648612976074 Epoch: 3021 trainloss: -0.70258665 validloss: -0.29552984\n",
      "time: 4.529266834259033 Epoch: 3022 trainloss: -0.70255923 validloss: -0.2977342\n",
      "time: 4.537765264511108 Epoch: 3023 trainloss: -0.70259976 validloss: -0.29331017\n",
      "time: 4.525988340377808 Epoch: 3024 trainloss: -0.70257914 validloss: -0.29784277\n",
      "time: 4.543435335159302 Epoch: 3025 trainloss: -0.70259243 validloss: -0.29399884\n",
      "time: 4.540165185928345 Epoch: 3026 trainloss: -0.70261914 validloss: -0.2954026\n",
      "time: 4.523132562637329 Epoch: 3027 trainloss: -0.70260864 validloss: -0.29771376\n",
      "time: 4.5285115242004395 Epoch: 3028 trainloss: -0.702597 validloss: -0.29588538\n",
      "time: 4.546514987945557 Epoch: 3029 trainloss: -0.70257044 validloss: -0.2978064\n",
      "time: 4.53501033782959 Epoch: 3030 trainloss: -0.70257753 validloss: -0.29221654\n",
      "time: 4.532018184661865 Epoch: 3031 trainloss: -0.7025748 validloss: -0.2975463\n",
      "time: 4.5424323081970215 Epoch: 3032 trainloss: -0.7025923 validloss: -0.29485828\n",
      "time: 4.508291482925415 Epoch: 3033 trainloss: -0.7026111 validloss: -0.29994786\n",
      "time: 4.558672904968262 Epoch: 3034 trainloss: -0.70259464 validloss: -0.29349053\n",
      "time: 4.549727201461792 Epoch: 3035 trainloss: -0.7026061 validloss: -0.2954446\n",
      "time: 4.532633304595947 Epoch: 3036 trainloss: -0.7025968 validloss: -0.2959174\n",
      "time: 4.5170018672943115 Epoch: 3037 trainloss: -0.70259964 validloss: -0.29028177\n",
      "time: 4.536983013153076 Epoch: 3038 trainloss: -0.70258963 validloss: -0.2990524\n",
      "time: 4.51626992225647 Epoch: 3039 trainloss: -0.7025946 validloss: -0.29512966\n",
      "time: 4.534447193145752 Epoch: 3040 trainloss: -0.7025767 validloss: -0.29459035\n",
      "time: 4.509795188903809 Epoch: 3041 trainloss: -0.7025758 validloss: -0.29388475\n",
      "time: 4.53296422958374 Epoch: 3042 trainloss: -0.7025751 validloss: -0.29427817\n",
      "time: 4.527599096298218 Epoch: 3043 trainloss: -0.7025543 validloss: -0.29517683\n",
      "time: 4.537562608718872 Epoch: 3044 trainloss: -0.7025485 validloss: -0.29348364\n",
      "time: 4.51981520652771 Epoch: 3045 trainloss: -0.7025465 validloss: -0.29859674\n",
      "time: 4.51232385635376 Epoch: 3046 trainloss: -0.70255023 validloss: -0.29514983\n",
      "time: 4.513205051422119 Epoch: 3047 trainloss: -0.70251215 validloss: -0.29638535\n",
      "time: 4.518128871917725 Epoch: 3048 trainloss: -0.70249736 validloss: -0.29101288\n",
      "time: 4.5611865520477295 Epoch: 3049 trainloss: -0.70250016 validloss: -0.2988305\n",
      "time: 4.523655652999878 Epoch: 3050 trainloss: -0.70246935 validloss: -0.2939306\n",
      "time: 4.513323545455933 Epoch: 3051 trainloss: -0.70241237 validloss: -0.29584527\n",
      "time: 4.520578861236572 Epoch: 3052 trainloss: -0.7024426 validloss: -0.29486865\n",
      "time: 4.529921770095825 Epoch: 3053 trainloss: -0.7023847 validloss: -0.2957185\n",
      "time: 4.5221874713897705 Epoch: 3054 trainloss: -0.70244133 validloss: -0.29777712\n",
      "time: 4.516798257827759 Epoch: 3055 trainloss: -0.7024446 validloss: -0.290402\n",
      "time: 4.545726299285889 Epoch: 3056 trainloss: -0.7024118 validloss: -0.29664966\n",
      "time: 4.528500318527222 Epoch: 3057 trainloss: -0.7024371 validloss: -0.29914743\n",
      "time: 4.535411357879639 Epoch: 3058 trainloss: -0.70240515 validloss: -0.29017246\n",
      "time: 4.738146066665649 Epoch: 3059 trainloss: -0.7024404 validloss: -0.30021584\n",
      "time: 4.86812949180603 Epoch: 3060 trainloss: -0.7024372 validloss: -0.29422438\n",
      "time: 5.021038293838501 Epoch: 3061 trainloss: -0.7024607 validloss: -0.30017918\n",
      "time: 4.9803056716918945 Epoch: 3062 trainloss: -0.7025025 validloss: -0.29157206\n",
      "time: 4.612948179244995 Epoch: 3063 trainloss: -0.70249027 validloss: -0.2946121\n",
      "time: 4.537919282913208 Epoch: 3064 trainloss: -0.7025175 validloss: -0.29541287\n",
      "time: 4.6730797290802 Epoch: 3065 trainloss: -0.702525 validloss: -0.2983212\n",
      "time: 4.555923223495483 Epoch: 3066 trainloss: -0.7025082 validloss: -0.294507\n",
      "time: 4.56180477142334 Epoch: 3067 trainloss: -0.7025388 validloss: -0.29428405\n",
      "time: 4.532170057296753 Epoch: 3068 trainloss: -0.7025422 validloss: -0.29612187\n",
      "time: 4.601977109909058 Epoch: 3069 trainloss: -0.70257246 validloss: -0.29664674\n",
      "time: 4.509999513626099 Epoch: 3070 trainloss: -0.70256525 validloss: -0.2943944\n",
      "time: 4.53900146484375 Epoch: 3071 trainloss: -0.7025321 validloss: -0.29600185\n",
      "time: 4.532464027404785 Epoch: 3072 trainloss: -0.70250696 validloss: -0.2968074\n",
      "time: 4.5292885303497314 Epoch: 3073 trainloss: -0.70246136 validloss: -0.28772154\n",
      "time: 4.541197776794434 Epoch: 3074 trainloss: -0.7024328 validloss: -0.3016105\n",
      "time: 4.529866456985474 Epoch: 3075 trainloss: -0.7024334 validloss: -0.29452452\n",
      "time: 4.528132438659668 Epoch: 3076 trainloss: -0.702496 validloss: -0.29488727\n",
      "time: 4.549448728561401 Epoch: 3077 trainloss: -0.7024678 validloss: -0.29635495\n",
      "time: 4.6116554737091064 Epoch: 3078 trainloss: -0.70246786 validloss: -0.2990302\n",
      "time: 4.531812906265259 Epoch: 3079 trainloss: -0.7024671 validloss: -0.29472896\n",
      "time: 4.514102935791016 Epoch: 3080 trainloss: -0.7024734 validloss: -0.2966727\n",
      "time: 4.537046432495117 Epoch: 3081 trainloss: -0.70248735 validloss: -0.29722428\n",
      "time: 4.859036922454834 Epoch: 3082 trainloss: -0.7024429 validloss: -0.29594335\n",
      "time: 4.535760879516602 Epoch: 3083 trainloss: -0.7025114 validloss: -0.29731345\n",
      "time: 4.537214040756226 Epoch: 3084 trainloss: -0.70248127 validloss: -0.29480717\n",
      "time: 4.532987356185913 Epoch: 3085 trainloss: -0.70248353 validloss: -0.2966194\n",
      "time: 4.628207206726074 Epoch: 3086 trainloss: -0.7024878 validloss: -0.29620048\n",
      "time: 4.611324071884155 Epoch: 3087 trainloss: -0.70252776 validloss: -0.29344836\n",
      "time: 4.769576072692871 Epoch: 3088 trainloss: -0.70249414 validloss: -0.3005949\n",
      "time: 4.504103183746338 Epoch: 3089 trainloss: -0.70251447 validloss: -0.29672077\n",
      "time: 4.523529529571533 Epoch: 3090 trainloss: -0.7025155 validloss: -0.29496467\n",
      "time: 4.5188469886779785 Epoch: 3091 trainloss: -0.70250946 validloss: -0.29755852\n",
      "time: 4.5531675815582275 Epoch: 3092 trainloss: -0.7025133 validloss: -0.2983989\n",
      "time: 4.540485858917236 Epoch: 3093 trainloss: -0.70251906 validloss: -0.29585838\n",
      "time: 4.515973329544067 Epoch: 3094 trainloss: -0.70249546 validloss: -0.29664314\n",
      "time: 4.5774312019348145 Epoch: 3095 trainloss: -0.70248723 validloss: -0.2954165\n",
      "time: 4.5958335399627686 Epoch: 3096 trainloss: -0.7024817 validloss: -0.29903686\n",
      "time: 4.606443881988525 Epoch: 3097 trainloss: -0.70248634 validloss: -0.29706255\n",
      "time: 4.620717763900757 Epoch: 3098 trainloss: -0.7024605 validloss: -0.29138604\n",
      "time: 4.532261610031128 Epoch: 3099 trainloss: -0.70248175 validloss: -0.297807\n",
      "time: 4.6054322719573975 Epoch: 3100 trainloss: -0.7024467 validloss: -0.2980463\n",
      "time: 4.567647457122803 Epoch: 3101 trainloss: -0.7024591 validloss: -0.28787833\n",
      "time: 4.540711164474487 Epoch: 3102 trainloss: -0.7024564 validloss: -0.30206323\n",
      "time: 4.496048450469971 Epoch: 3103 trainloss: -0.7024416 validloss: -0.29226676\n",
      "time: 4.671316862106323 Epoch: 3104 trainloss: -0.7025055 validloss: -0.29754886\n",
      "time: 4.634114980697632 Epoch: 3105 trainloss: -0.702509 validloss: -0.29565698\n",
      "time: 4.6679441928863525 Epoch: 3106 trainloss: -0.70254654 validloss: -0.29583076\n",
      "time: 4.927249431610107 Epoch: 3107 trainloss: -0.7025843 validloss: -0.29708764\n",
      "time: 4.802250623703003 Epoch: 3108 trainloss: -0.7025708 validloss: -0.29387376\n",
      "time: 4.710521459579468 Epoch: 3109 trainloss: -0.7026018 validloss: -0.29253396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.846503973007202 Epoch: 3110 trainloss: -0.7025773 validloss: -0.29694322\n",
      "time: 4.947929859161377 Epoch: 3111 trainloss: -0.7025747 validloss: -0.29527032\n",
      "time: 4.877893686294556 Epoch: 3112 trainloss: -0.7026059 validloss: -0.29547116\n",
      "time: 4.964417219161987 Epoch: 3113 trainloss: -0.7026034 validloss: -0.29173008\n",
      "time: 4.987437963485718 Epoch: 3114 trainloss: -0.7026086 validloss: -0.2978007\n",
      "time: 4.961521148681641 Epoch: 3115 trainloss: -0.70261776 validloss: -0.2948762\n",
      "time: 4.9673802852630615 Epoch: 3116 trainloss: -0.70260364 validloss: -0.2914176\n",
      "time: 5.047821283340454 Epoch: 3117 trainloss: -0.7025982 validloss: -0.2984437\n",
      "time: 5.045430898666382 Epoch: 3118 trainloss: -0.7025845 validloss: -0.29256546\n",
      "time: 4.9691596031188965 Epoch: 3119 trainloss: -0.7025989 validloss: -0.29394004\n",
      "time: 4.580515384674072 Epoch: 3120 trainloss: -0.70259416 validloss: -0.29222482\n",
      "time: 4.541719198226929 Epoch: 3121 trainloss: -0.70261043 validloss: -0.29580808\n",
      "time: 4.677261114120483 Epoch: 3122 trainloss: -0.702618 validloss: -0.29720038\n",
      "time: 4.781341075897217 Epoch: 3123 trainloss: -0.7026067 validloss: -0.29352647\n",
      "time: 4.998489618301392 Epoch: 3124 trainloss: -0.7026143 validloss: -0.2924565\n",
      "time: 5.198513507843018 Epoch: 3125 trainloss: -0.7025981 validloss: -0.295485\n",
      "time: 5.0398945808410645 Epoch: 3126 trainloss: -0.7026075 validloss: -0.29594305\n",
      "time: 4.791332483291626 Epoch: 3127 trainloss: -0.70259786 validloss: -0.28992373\n",
      "time: 4.532586574554443 Epoch: 3128 trainloss: -0.70259726 validloss: -0.29775697\n",
      "time: 4.554203748703003 Epoch: 3129 trainloss: -0.7026064 validloss: -0.29238695\n",
      "time: 4.554226398468018 Epoch: 3130 trainloss: -0.7026136 validloss: -0.29077965\n",
      "time: 4.53450083732605 Epoch: 3131 trainloss: -0.7026335 validloss: -0.29877895\n",
      "time: 4.54759669303894 Epoch: 3132 trainloss: -0.7026405 validloss: -0.2932456\n",
      "time: 4.523612976074219 Epoch: 3133 trainloss: -0.7026287 validloss: -0.29489148\n",
      "time: 4.53620982170105 Epoch: 3134 trainloss: -0.70260227 validloss: -0.2937641\n",
      "time: 4.517501592636108 Epoch: 3135 trainloss: -0.7026002 validloss: -0.29548326\n",
      "time: 4.565905809402466 Epoch: 3136 trainloss: -0.70259273 validloss: -0.2944296\n",
      "time: 4.731378793716431 Epoch: 3137 trainloss: -0.70260084 validloss: -0.29493487\n",
      "time: 4.684678554534912 Epoch: 3138 trainloss: -0.70261145 validloss: -0.29429665\n",
      "time: 4.7689735889434814 Epoch: 3139 trainloss: -0.7025945 validloss: -0.29429856\n",
      "time: 4.7419114112854 Epoch: 3140 trainloss: -0.7025479 validloss: -0.29604134\n",
      "time: 4.716437101364136 Epoch: 3141 trainloss: -0.702537 validloss: -0.29149452\n",
      "time: 4.623681545257568 Epoch: 3142 trainloss: -0.7025415 validloss: -0.2932156\n",
      "time: 4.789313554763794 Epoch: 3143 trainloss: -0.70254356 validloss: -0.29733887\n",
      "time: 4.794396877288818 Epoch: 3144 trainloss: -0.70255226 validloss: -0.29156888\n",
      "time: 4.792960166931152 Epoch: 3145 trainloss: -0.70254445 validloss: -0.2931529\n",
      "time: 4.832852602005005 Epoch: 3146 trainloss: -0.70254815 validloss: -0.29601163\n",
      "time: 4.837742567062378 Epoch: 3147 trainloss: -0.7025213 validloss: -0.29157114\n",
      "time: 4.734179973602295 Epoch: 3148 trainloss: -0.70252407 validloss: -0.29536918\n",
      "time: 4.707443952560425 Epoch: 3149 trainloss: -0.70251405 validloss: -0.29834008\n",
      "time: 4.733658075332642 Epoch: 3150 trainloss: -0.70252264 validloss: -0.29273313\n",
      "time: 4.848241329193115 Epoch: 3151 trainloss: -0.7025038 validloss: -0.29643568\n",
      "time: 4.706334114074707 Epoch: 3152 trainloss: -0.7025341 validloss: -0.2903182\n",
      "time: 4.605906009674072 Epoch: 3153 trainloss: -0.7025716 validloss: -0.2983471\n",
      "time: 4.668376684188843 Epoch: 3154 trainloss: -0.70257485 validloss: -0.296505\n",
      "time: 4.620821475982666 Epoch: 3155 trainloss: -0.70258063 validloss: -0.2944388\n",
      "time: 4.67961311340332 Epoch: 3156 trainloss: -0.7025742 validloss: -0.29575643\n",
      "time: 4.654489755630493 Epoch: 3157 trainloss: -0.7025708 validloss: -0.29497257\n",
      "time: 4.549705505371094 Epoch: 3158 trainloss: -0.70252424 validloss: -0.2920019\n",
      "time: 4.815531492233276 Epoch: 3159 trainloss: -0.7025327 validloss: -0.29514068\n",
      "time: 4.787567138671875 Epoch: 3160 trainloss: -0.7025173 validloss: -0.29768503\n",
      "time: 4.548828125 Epoch: 3161 trainloss: -0.7025358 validloss: -0.29379493\n",
      "time: 4.654112339019775 Epoch: 3162 trainloss: -0.702511 validloss: -0.2966861\n",
      "time: 4.523128271102905 Epoch: 3163 trainloss: -0.70258254 validloss: -0.29452488\n",
      "time: 4.621333599090576 Epoch: 3164 trainloss: -0.7025844 validloss: -0.2937629\n",
      "time: 4.569350481033325 Epoch: 3165 trainloss: -0.70253 validloss: -0.29565743\n",
      "time: 4.938733816146851 Epoch: 3166 trainloss: -0.70258176 validloss: -0.29601592\n",
      "time: 5.072280406951904 Epoch: 3167 trainloss: -0.7025411 validloss: -0.29134426\n",
      "time: 5.0146167278289795 Epoch: 3168 trainloss: -0.70257854 validloss: -0.30088064\n",
      "time: 4.887273788452148 Epoch: 3169 trainloss: -0.7025779 validloss: -0.29163527\n",
      "time: 4.913443088531494 Epoch: 3170 trainloss: -0.70256925 validloss: -0.29429638\n",
      "time: 5.064809083938599 Epoch: 3171 trainloss: -0.70259976 validloss: -0.29848117\n",
      "time: 4.963555812835693 Epoch: 3172 trainloss: -0.7025733 validloss: -0.29507664\n",
      "time: 5.349761247634888 Epoch: 3173 trainloss: -0.7026071 validloss: -0.29418135\n",
      "time: 5.086297035217285 Epoch: 3174 trainloss: -0.7025758 validloss: -0.29421654\n",
      "time: 4.920083045959473 Epoch: 3175 trainloss: -0.7025817 validloss: -0.29511082\n",
      "time: 4.986766815185547 Epoch: 3176 trainloss: -0.702559 validloss: -0.2938039\n",
      "time: 4.732910394668579 Epoch: 3177 trainloss: -0.7026058 validloss: -0.29474893\n",
      "time: 5.08851432800293 Epoch: 3178 trainloss: -0.7025981 validloss: -0.29786783\n",
      "time: 4.938366889953613 Epoch: 3179 trainloss: -0.70262104 validloss: -0.2976312\n",
      "time: 4.600160360336304 Epoch: 3180 trainloss: -0.7026033 validloss: -0.2914218\n",
      "time: 4.726222515106201 Epoch: 3181 trainloss: -0.7026074 validloss: -0.29849243\n",
      "time: 4.776288270950317 Epoch: 3182 trainloss: -0.7026173 validloss: -0.29632956\n",
      "time: 4.749184846878052 Epoch: 3183 trainloss: -0.7026274 validloss: -0.29290012\n",
      "time: 4.615461349487305 Epoch: 3184 trainloss: -0.7026276 validloss: -0.30180478\n",
      "time: 4.838022470474243 Epoch: 3185 trainloss: -0.702633 validloss: -0.2911705\n",
      "time: 4.608325481414795 Epoch: 3186 trainloss: -0.70263284 validloss: -0.29624814\n",
      "time: 4.5775439739227295 Epoch: 3187 trainloss: -0.70262253 validloss: -0.29772168\n",
      "time: 4.597025632858276 Epoch: 3188 trainloss: -0.70264095 validloss: -0.2919165\n",
      "time: 4.543758869171143 Epoch: 3189 trainloss: -0.7026413 validloss: -0.29801223\n",
      "time: 4.694269180297852 Epoch: 3190 trainloss: -0.7026702 validloss: -0.29477736\n",
      "time: 4.561474084854126 Epoch: 3191 trainloss: -0.7026613 validloss: -0.29146484\n",
      "time: 4.557913303375244 Epoch: 3192 trainloss: -0.70267445 validloss: -0.29561016\n",
      "time: 4.550909996032715 Epoch: 3193 trainloss: -0.70266825 validloss: -0.29820627\n",
      "time: 4.55411958694458 Epoch: 3194 trainloss: -0.7026673 validloss: -0.29278734\n",
      "time: 4.564435720443726 Epoch: 3195 trainloss: -0.7026688 validloss: -0.29408643\n",
      "time: 4.567666530609131 Epoch: 3196 trainloss: -0.7026561 validloss: -0.29935986\n",
      "time: 4.5629332065582275 Epoch: 3197 trainloss: -0.702673 validloss: -0.29196376\n",
      "time: 4.562215566635132 Epoch: 3198 trainloss: -0.7026618 validloss: -0.29552194\n",
      "time: 4.544590711593628 Epoch: 3199 trainloss: -0.70265883 validloss: -0.29355738\n",
      "time: 4.604770660400391 Epoch: 3200 trainloss: -0.70266134 validloss: -0.29150936\n",
      "time: 4.558566331863403 Epoch: 3201 trainloss: -0.7026554 validloss: -0.29854557\n",
      "time: 4.55136775970459 Epoch: 3202 trainloss: -0.70264745 validloss: -0.29070553\n",
      "time: 4.557222843170166 Epoch: 3203 trainloss: -0.7026487 validloss: -0.29222384\n",
      "time: 4.581791877746582 Epoch: 3204 trainloss: -0.702654 validloss: -0.2988115\n",
      "time: 4.540481805801392 Epoch: 3205 trainloss: -0.70263726 validloss: -0.2945101\n",
      "time: 4.559913635253906 Epoch: 3206 trainloss: -0.7026491 validloss: -0.29401374\n",
      "time: 4.57110857963562 Epoch: 3207 trainloss: -0.70261514 validloss: -0.2944324\n",
      "time: 4.553591728210449 Epoch: 3208 trainloss: -0.7026237 validloss: -0.29461128\n",
      "time: 4.549077033996582 Epoch: 3209 trainloss: -0.70262897 validloss: -0.29352176\n",
      "time: 4.560509443283081 Epoch: 3210 trainloss: -0.70259345 validloss: -0.28989357\n",
      "time: 4.573886871337891 Epoch: 3211 trainloss: -0.7026091 validloss: -0.29950812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.5560479164123535 Epoch: 3212 trainloss: -0.70258003 validloss: -0.29103827\n",
      "time: 4.538331985473633 Epoch: 3213 trainloss: -0.7026312 validloss: -0.29532006\n",
      "time: 4.558879137039185 Epoch: 3214 trainloss: -0.7026267 validloss: -0.2935794\n",
      "time: 4.56683087348938 Epoch: 3215 trainloss: -0.7026568 validloss: -0.2936834\n",
      "time: 4.571528911590576 Epoch: 3216 trainloss: -0.7026609 validloss: -0.29701638\n",
      "time: 4.537227630615234 Epoch: 3217 trainloss: -0.70265603 validloss: -0.28870165\n",
      "time: 4.528876066207886 Epoch: 3218 trainloss: -0.70265555 validloss: -0.29748142\n",
      "time: 4.589586019515991 Epoch: 3219 trainloss: -0.70267826 validloss: -0.29235226\n",
      "time: 4.609545707702637 Epoch: 3220 trainloss: -0.70269465 validloss: -0.29200634\n",
      "time: 4.698030948638916 Epoch: 3221 trainloss: -0.7026846 validloss: -0.29403436\n",
      "time: 4.601160526275635 Epoch: 3222 trainloss: -0.70269364 validloss: -0.29213342\n",
      "time: 4.779872179031372 Epoch: 3223 trainloss: -0.7026934 validloss: -0.29643464\n",
      "time: 4.863994836807251 Epoch: 3224 trainloss: -0.70267826 validloss: -0.2984852\n",
      "time: 4.6739983558654785 Epoch: 3225 trainloss: -0.70267665 validloss: -0.29262292\n",
      "time: 4.745262384414673 Epoch: 3226 trainloss: -0.7026563 validloss: -0.29606044\n",
      "time: 4.670068264007568 Epoch: 3227 trainloss: -0.7026609 validloss: -0.29509342\n",
      "time: 4.575629711151123 Epoch: 3228 trainloss: -0.70265436 validloss: -0.29265174\n",
      "time: 4.550551891326904 Epoch: 3229 trainloss: -0.70265853 validloss: -0.2948392\n",
      "time: 4.552349805831909 Epoch: 3230 trainloss: -0.7026614 validloss: -0.29435086\n",
      "time: 4.601379156112671 Epoch: 3231 trainloss: -0.702672 validloss: -0.2924131\n",
      "time: 4.550745487213135 Epoch: 3232 trainloss: -0.702687 validloss: -0.2950825\n",
      "time: 4.5734663009643555 Epoch: 3233 trainloss: -0.70268387 validloss: -0.29102764\n",
      "time: 4.623192071914673 Epoch: 3234 trainloss: -0.7026868 validloss: -0.29398146\n",
      "time: 4.755183935165405 Epoch: 3235 trainloss: -0.70269454 validloss: -0.29445451\n",
      "time: 4.8834452629089355 Epoch: 3236 trainloss: -0.70270205 validloss: -0.29392135\n",
      "time: 4.642836093902588 Epoch: 3237 trainloss: -0.70269716 validloss: -0.29493386\n",
      "time: 4.742003917694092 Epoch: 3238 trainloss: -0.70270336 validloss: -0.29346156\n",
      "time: 4.568745136260986 Epoch: 3239 trainloss: -0.7026961 validloss: -0.29431537\n",
      "time: 4.911867618560791 Epoch: 3240 trainloss: -0.70266753 validloss: -0.29450265\n",
      "time: 4.6048736572265625 Epoch: 3241 trainloss: -0.70268124 validloss: -0.29239333\n",
      "time: 4.783780813217163 Epoch: 3242 trainloss: -0.7026714 validloss: -0.2973374\n",
      "time: 4.61042332649231 Epoch: 3243 trainloss: -0.7026603 validloss: -0.2935892\n",
      "time: 4.765884876251221 Epoch: 3244 trainloss: -0.70262897 validloss: -0.29828456\n",
      "time: 4.604022264480591 Epoch: 3245 trainloss: -0.70264107 validloss: -0.29465622\n",
      "time: 4.760188341140747 Epoch: 3246 trainloss: -0.7026138 validloss: -0.29535803\n",
      "time: 4.594151496887207 Epoch: 3247 trainloss: -0.7025703 validloss: -0.2968363\n",
      "time: 4.7078070640563965 Epoch: 3248 trainloss: -0.70256376 validloss: -0.2916007\n",
      "time: 4.741008043289185 Epoch: 3249 trainloss: -0.70253956 validloss: -0.295666\n",
      "time: 4.700592994689941 Epoch: 3250 trainloss: -0.70256287 validloss: -0.29371768\n",
      "time: 4.651824474334717 Epoch: 3251 trainloss: -0.7025554 validloss: -0.2935761\n",
      "time: 4.637603044509888 Epoch: 3252 trainloss: -0.7025996 validloss: -0.29386526\n",
      "time: 4.752041339874268 Epoch: 3253 trainloss: -0.70258856 validloss: -0.29148903\n",
      "time: 4.610995531082153 Epoch: 3254 trainloss: -0.70256495 validloss: -0.30004352\n",
      "time: 4.7610838413238525 Epoch: 3255 trainloss: -0.70259756 validloss: -0.28802052\n",
      "time: 4.520699501037598 Epoch: 3256 trainloss: -0.7026037 validloss: -0.2987491\n",
      "time: 4.5383617877960205 Epoch: 3257 trainloss: -0.7025995 validloss: -0.29408547\n",
      "time: 4.5163280963897705 Epoch: 3258 trainloss: -0.70260423 validloss: -0.29448846\n",
      "time: 4.511648416519165 Epoch: 3259 trainloss: -0.70261085 validloss: -0.29373926\n",
      "time: 4.507150888442993 Epoch: 3260 trainloss: -0.70265317 validloss: -0.29559684\n",
      "time: 4.7594218254089355 Epoch: 3261 trainloss: -0.70264024 validloss: -0.2965918\n",
      "time: 4.5006263256073 Epoch: 3262 trainloss: -0.70263 validloss: -0.2902417\n",
      "time: 4.518293857574463 Epoch: 3263 trainloss: -0.70261484 validloss: -0.29764894\n",
      "time: 4.51233172416687 Epoch: 3264 trainloss: -0.70260227 validloss: -0.29594254\n",
      "time: 4.522195816040039 Epoch: 3265 trainloss: -0.70261806 validloss: -0.29150856\n",
      "time: 4.518320322036743 Epoch: 3266 trainloss: -0.70260394 validloss: -0.3020608\n",
      "time: 4.536057710647583 Epoch: 3267 trainloss: -0.7025894 validloss: -0.29003188\n",
      "time: 4.542008876800537 Epoch: 3268 trainloss: -0.70259273 validloss: -0.29687804\n",
      "time: 4.515339374542236 Epoch: 3269 trainloss: -0.7025929 validloss: -0.29555467\n",
      "time: 4.506127595901489 Epoch: 3270 trainloss: -0.7025437 validloss: -0.29236457\n",
      "time: 4.5150792598724365 Epoch: 3271 trainloss: -0.70252794 validloss: -0.2982688\n",
      "time: 4.504059076309204 Epoch: 3272 trainloss: -0.70249575 validloss: -0.29368582\n",
      "time: 4.699191093444824 Epoch: 3273 trainloss: -0.7024757 validloss: -0.29710403\n",
      "time: 4.5189292430877686 Epoch: 3274 trainloss: -0.70245343 validloss: -0.29797316\n",
      "time: 4.500614643096924 Epoch: 3275 trainloss: -0.7025033 validloss: -0.2884277\n",
      "time: 4.514453649520874 Epoch: 3276 trainloss: -0.70246637 validloss: -0.3006983\n",
      "time: 4.521565675735474 Epoch: 3277 trainloss: -0.702534 validloss: -0.29482242\n",
      "time: 4.617305040359497 Epoch: 3278 trainloss: -0.70251113 validloss: -0.28972268\n",
      "time: 4.85614013671875 Epoch: 3279 trainloss: -0.7025667 validloss: -0.30110157\n",
      "time: 4.521792888641357 Epoch: 3280 trainloss: -0.7025381 validloss: -0.29141167\n",
      "time: 4.515047550201416 Epoch: 3281 trainloss: -0.7025398 validloss: -0.3001211\n",
      "time: 4.61363410949707 Epoch: 3282 trainloss: -0.7025534 validloss: -0.29162487\n",
      "time: 4.554366588592529 Epoch: 3283 trainloss: -0.7025401 validloss: -0.29543456\n",
      "time: 4.55239462852478 Epoch: 3284 trainloss: -0.70251864 validloss: -0.30113906\n",
      "time: 4.535500526428223 Epoch: 3285 trainloss: -0.7025131 validloss: -0.29204875\n",
      "time: 4.551841974258423 Epoch: 3286 trainloss: -0.7024604 validloss: -0.29732668\n",
      "time: 4.521790027618408 Epoch: 3287 trainloss: -0.7025164 validloss: -0.2980125\n",
      "time: 4.520143747329712 Epoch: 3288 trainloss: -0.7024986 validloss: -0.29670915\n",
      "time: 4.532342433929443 Epoch: 3289 trainloss: -0.7025437 validloss: -0.29541275\n",
      "time: 4.5220046043396 Epoch: 3290 trainloss: -0.70257133 validloss: -0.2916526\n",
      "time: 4.602207183837891 Epoch: 3291 trainloss: -0.70257527 validloss: -0.29755002\n",
      "time: 4.633563280105591 Epoch: 3292 trainloss: -0.70257914 validloss: -0.29506063\n",
      "time: 4.719599723815918 Epoch: 3293 trainloss: -0.70257616 validloss: -0.2936508\n",
      "time: 4.6013123989105225 Epoch: 3294 trainloss: -0.70258814 validloss: -0.29661232\n",
      "time: 4.529464244842529 Epoch: 3295 trainloss: -0.70254546 validloss: -0.29694572\n",
      "time: 4.698149681091309 Epoch: 3296 trainloss: -0.70256597 validloss: -0.29475823\n",
      "time: 4.623921871185303 Epoch: 3297 trainloss: -0.70256716 validloss: -0.29430196\n",
      "time: 4.656339168548584 Epoch: 3298 trainloss: -0.7025791 validloss: -0.29926735\n",
      "time: 4.616588592529297 Epoch: 3299 trainloss: -0.70255625 validloss: -0.29331607\n",
      "time: 4.945832252502441 Epoch: 3300 trainloss: -0.702523 validloss: -0.29484367\n",
      "time: 4.546611785888672 Epoch: 3301 trainloss: -0.7025694 validloss: -0.29784966\n",
      "time: 4.6434736251831055 Epoch: 3302 trainloss: -0.7025155 validloss: -0.2902719\n",
      "time: 4.591960430145264 Epoch: 3303 trainloss: -0.7025717 validloss: -0.2994419\n",
      "time: 4.705588102340698 Epoch: 3304 trainloss: -0.7025782 validloss: -0.29601878\n",
      "time: 4.794309139251709 Epoch: 3305 trainloss: -0.7025652 validloss: -0.29287705\n",
      "time: 4.700448036193848 Epoch: 3306 trainloss: -0.7025546 validloss: -0.29925653\n",
      "time: 4.647526741027832 Epoch: 3307 trainloss: -0.70258665 validloss: -0.29375315\n",
      "time: 4.559887409210205 Epoch: 3308 trainloss: -0.7025421 validloss: -0.29100427\n",
      "time: 4.555711507797241 Epoch: 3309 trainloss: -0.7025765 validloss: -0.3016519\n",
      "time: 4.6723411083221436 Epoch: 3310 trainloss: -0.70257777 validloss: -0.29411566\n",
      "time: 4.605361700057983 Epoch: 3311 trainloss: -0.70257926 validloss: -0.29240903\n",
      "time: 4.619586229324341 Epoch: 3312 trainloss: -0.70260084 validloss: -0.30072337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.735257863998413 Epoch: 3313 trainloss: -0.70259124 validloss: -0.29325244\n",
      "time: 4.582425355911255 Epoch: 3314 trainloss: -0.70262766 validloss: -0.29432282\n",
      "time: 4.5427069664001465 Epoch: 3315 trainloss: -0.70258224 validloss: -0.29543608\n",
      "time: 4.554612636566162 Epoch: 3316 trainloss: -0.70255965 validloss: -0.29624945\n",
      "time: 4.534406661987305 Epoch: 3317 trainloss: -0.70256335 validloss: -0.29463804\n",
      "time: 4.586497068405151 Epoch: 3318 trainloss: -0.70248365 validloss: -0.29787192\n",
      "time: 4.587669134140015 Epoch: 3319 trainloss: -0.7025059 validloss: -0.29306495\n",
      "time: 4.561633110046387 Epoch: 3320 trainloss: -0.7024537 validloss: -0.29621053\n",
      "time: 4.535502195358276 Epoch: 3321 trainloss: -0.7025034 validloss: -0.29887688\n",
      "time: 4.5289247035980225 Epoch: 3322 trainloss: -0.70252055 validloss: -0.29319972\n",
      "time: 4.5173020362854 Epoch: 3323 trainloss: -0.7025206 validloss: -0.29819083\n",
      "time: 4.539665699005127 Epoch: 3324 trainloss: -0.70255405 validloss: -0.29540128\n",
      "time: 4.525040864944458 Epoch: 3325 trainloss: -0.7025232 validloss: -0.29741508\n",
      "time: 4.546743869781494 Epoch: 3326 trainloss: -0.70259064 validloss: -0.29369012\n",
      "time: 4.532551527023315 Epoch: 3327 trainloss: -0.7025607 validloss: -0.29318208\n",
      "time: 4.537258625030518 Epoch: 3328 trainloss: -0.7025793 validloss: -0.2960623\n",
      "time: 4.577930688858032 Epoch: 3329 trainloss: -0.7025601 validloss: -0.2973409\n",
      "time: 4.584329605102539 Epoch: 3330 trainloss: -0.70256853 validloss: -0.29626146\n",
      "time: 4.527101039886475 Epoch: 3331 trainloss: -0.7025642 validloss: -0.29393095\n",
      "time: 4.553675413131714 Epoch: 3332 trainloss: -0.70260483 validloss: -0.29583976\n",
      "time: 4.515344619750977 Epoch: 3333 trainloss: -0.7026076 validloss: -0.29635432\n",
      "time: 4.535758972167969 Epoch: 3334 trainloss: -0.702604 validloss: -0.29142442\n",
      "time: 4.534366607666016 Epoch: 3335 trainloss: -0.70260155 validloss: -0.29438347\n",
      "time: 4.894308805465698 Epoch: 3336 trainloss: -0.70261234 validloss: -0.295823\n",
      "time: 5.234391927719116 Epoch: 3337 trainloss: -0.70261794 validloss: -0.2928356\n",
      "time: 5.001492023468018 Epoch: 3338 trainloss: -0.7026391 validloss: -0.2957978\n",
      "time: 4.8561108112335205 Epoch: 3339 trainloss: -0.70264435 validloss: -0.29574347\n",
      "time: 4.81160044670105 Epoch: 3340 trainloss: -0.70263314 validloss: -0.29459244\n",
      "time: 5.414568185806274 Epoch: 3341 trainloss: -0.70262927 validloss: -0.2924778\n",
      "time: 5.176746606826782 Epoch: 3342 trainloss: -0.7026095 validloss: -0.29722908\n",
      "time: 4.818393230438232 Epoch: 3343 trainloss: -0.7026434 validloss: -0.28848293\n",
      "time: 4.742439270019531 Epoch: 3344 trainloss: -0.7026261 validloss: -0.29938242\n",
      "time: 4.676323413848877 Epoch: 3345 trainloss: -0.7026622 validloss: -0.29278782\n",
      "time: 5.106367111206055 Epoch: 3346 trainloss: -0.70265794 validloss: -0.2946629\n",
      "time: 5.03962516784668 Epoch: 3347 trainloss: -0.7026542 validloss: -0.29231715\n",
      "time: 5.161636590957642 Epoch: 3348 trainloss: -0.702646 validloss: -0.293936\n",
      "time: 5.227958917617798 Epoch: 3349 trainloss: -0.70261735 validloss: -0.29408094\n",
      "time: 5.2855870723724365 Epoch: 3350 trainloss: -0.7025962 validloss: -0.291394\n",
      "time: 5.32601261138916 Epoch: 3351 trainloss: -0.70258963 validloss: -0.29988605\n",
      "time: 5.475800514221191 Epoch: 3352 trainloss: -0.70260334 validloss: -0.29421243\n",
      "time: 5.350332498550415 Epoch: 3353 trainloss: -0.70260364 validloss: -0.2934223\n",
      "time: 5.271219253540039 Epoch: 3354 trainloss: -0.7025677 validloss: -0.29621318\n",
      "time: 4.584996700286865 Epoch: 3355 trainloss: -0.7025568 validloss: -0.29389113\n",
      "time: 4.539000034332275 Epoch: 3356 trainloss: -0.7025751 validloss: -0.29415077\n",
      "time: 4.520286798477173 Epoch: 3357 trainloss: -0.70253146 validloss: -0.2971391\n",
      "time: 5.001750707626343 Epoch: 3358 trainloss: -0.70257 validloss: -0.29129928\n",
      "time: 5.204549074172974 Epoch: 3359 trainloss: -0.70252246 validloss: -0.2998624\n",
      "time: 4.494354009628296 Epoch: 3360 trainloss: -0.70253295 validloss: -0.29396325\n",
      "time: 4.52540922164917 Epoch: 3361 trainloss: -0.702506 validloss: -0.29555008\n",
      "time: 4.634052991867065 Epoch: 3362 trainloss: -0.70255744 validloss: -0.29244366\n",
      "time: 4.652279615402222 Epoch: 3363 trainloss: -0.702496 validloss: -0.2973922\n",
      "time: 4.620431423187256 Epoch: 3364 trainloss: -0.7025545 validloss: -0.29441705\n",
      "time: 4.694733619689941 Epoch: 3365 trainloss: -0.70253664 validloss: -0.29332796\n",
      "time: 4.563752889633179 Epoch: 3366 trainloss: -0.7025015 validloss: -0.29888982\n",
      "time: 4.62726902961731 Epoch: 3367 trainloss: -0.70254433 validloss: -0.29219228\n",
      "time: 4.637892007827759 Epoch: 3368 trainloss: -0.702524 validloss: -0.29696542\n",
      "time: 4.872162580490112 Epoch: 3369 trainloss: -0.7025518 validloss: -0.29501674\n",
      "time: 4.5840904712677 Epoch: 3370 trainloss: -0.70249283 validloss: -0.29586807\n",
      "time: 4.721332311630249 Epoch: 3371 trainloss: -0.7025042 validloss: -0.29811388\n",
      "time: 4.8067944049835205 Epoch: 3372 trainloss: -0.7024721 validloss: -0.28911158\n",
      "time: 4.574983835220337 Epoch: 3373 trainloss: -0.70248824 validloss: -0.29996416\n",
      "time: 4.7424397468566895 Epoch: 3374 trainloss: -0.7025002 validloss: -0.29325292\n",
      "time: 4.543690204620361 Epoch: 3375 trainloss: -0.70254695 validloss: -0.2943691\n",
      "time: 4.650813102722168 Epoch: 3376 trainloss: -0.7025525 validloss: -0.29406103\n",
      "time: 4.552069664001465 Epoch: 3377 trainloss: -0.70258844 validloss: -0.29697582\n",
      "time: 4.677459716796875 Epoch: 3378 trainloss: -0.7026159 validloss: -0.29595682\n",
      "time: 4.832502126693726 Epoch: 3379 trainloss: -0.70261556 validloss: -0.29151022\n",
      "time: 4.660733222961426 Epoch: 3380 trainloss: -0.70260566 validloss: -0.3012367\n",
      "time: 4.621749401092529 Epoch: 3381 trainloss: -0.70257264 validloss: -0.29593375\n",
      "time: 4.634677410125732 Epoch: 3382 trainloss: -0.7025923 validloss: -0.2946112\n",
      "time: 4.5107855796813965 Epoch: 3383 trainloss: -0.7025996 validloss: -0.2959984\n",
      "time: 4.600006818771362 Epoch: 3384 trainloss: -0.7026185 validloss: -0.29464605\n",
      "time: 4.797698736190796 Epoch: 3385 trainloss: -0.70265824 validloss: -0.2937866\n",
      "time: 4.690130233764648 Epoch: 3386 trainloss: -0.7026433 validloss: -0.29150975\n",
      "time: 4.790265083312988 Epoch: 3387 trainloss: -0.7026174 validloss: -0.29613447\n",
      "time: 4.901859283447266 Epoch: 3388 trainloss: -0.70259625 validloss: -0.2964432\n",
      "time: 4.998566389083862 Epoch: 3389 trainloss: -0.7025906 validloss: -0.295176\n",
      "time: 4.758639097213745 Epoch: 3390 trainloss: -0.7025976 validloss: -0.2932523\n",
      "time: 4.830258369445801 Epoch: 3391 trainloss: -0.7025802 validloss: -0.3002058\n",
      "time: 4.747955560684204 Epoch: 3392 trainloss: -0.7025973 validloss: -0.2910556\n",
      "time: 4.697654485702515 Epoch: 3393 trainloss: -0.7025843 validloss: -0.30055654\n",
      "time: 4.5542378425598145 Epoch: 3394 trainloss: -0.7026345 validloss: -0.29762897\n",
      "time: 4.545669078826904 Epoch: 3395 trainloss: -0.70265657 validloss: -0.29295754\n",
      "time: 4.523200988769531 Epoch: 3396 trainloss: -0.70265734 validloss: -0.297016\n",
      "time: 4.542141675949097 Epoch: 3397 trainloss: -0.70265925 validloss: -0.292751\n",
      "time: 4.5550665855407715 Epoch: 3398 trainloss: -0.7026305 validloss: -0.2960747\n",
      "time: 4.5236663818359375 Epoch: 3399 trainloss: -0.7026365 validloss: -0.29552844\n",
      "time: 4.54162073135376 Epoch: 3400 trainloss: -0.7026204 validloss: -0.29450166\n",
      "time: 4.535081624984741 Epoch: 3401 trainloss: -0.7026365 validloss: -0.3006686\n",
      "time: 4.52037239074707 Epoch: 3402 trainloss: -0.7026291 validloss: -0.29361466\n",
      "time: 4.566734790802002 Epoch: 3403 trainloss: -0.70263433 validloss: -0.2935439\n",
      "time: 4.5573461055755615 Epoch: 3404 trainloss: -0.70263773 validloss: -0.29588002\n",
      "time: 4.514770269393921 Epoch: 3405 trainloss: -0.70267534 validloss: -0.29480845\n",
      "time: 4.543099880218506 Epoch: 3406 trainloss: -0.7026141 validloss: -0.29524902\n",
      "time: 4.514441728591919 Epoch: 3407 trainloss: -0.70263034 validloss: -0.29348886\n",
      "time: 4.531313419342041 Epoch: 3408 trainloss: -0.70261365 validloss: -0.29824686\n",
      "time: 4.5346455574035645 Epoch: 3409 trainloss: -0.7025932 validloss: -0.298132\n",
      "time: 4.526328802108765 Epoch: 3410 trainloss: -0.7026263 validloss: -0.29398778\n",
      "time: 4.553333044052124 Epoch: 3411 trainloss: -0.70262533 validloss: -0.29507133\n",
      "time: 4.548062086105347 Epoch: 3412 trainloss: -0.7026349 validloss: -0.2940139\n",
      "time: 4.52625036239624 Epoch: 3413 trainloss: -0.70266426 validloss: -0.2999627\n",
      "time: 4.533657550811768 Epoch: 3414 trainloss: -0.70264477 validloss: -0.29618737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.52303671836853 Epoch: 3415 trainloss: -0.7026832 validloss: -0.29914346\n",
      "time: 4.624162673950195 Epoch: 3416 trainloss: -0.70267075 validloss: -0.29710248\n",
      "time: 4.5931220054626465 Epoch: 3417 trainloss: -0.70268685 validloss: -0.29574937\n",
      "time: 4.544528484344482 Epoch: 3418 trainloss: -0.7026676 validloss: -0.29578072\n",
      "time: 4.53287410736084 Epoch: 3419 trainloss: -0.7026623 validloss: -0.29851624\n",
      "time: 4.526082515716553 Epoch: 3420 trainloss: -0.7026803 validloss: -0.29377836\n",
      "time: 4.548769474029541 Epoch: 3421 trainloss: -0.70268154 validloss: -0.29445392\n",
      "time: 4.529458999633789 Epoch: 3422 trainloss: -0.7026961 validloss: -0.2984161\n",
      "time: 4.525548934936523 Epoch: 3423 trainloss: -0.7027116 validloss: -0.29365012\n",
      "time: 4.529819965362549 Epoch: 3424 trainloss: -0.7026991 validloss: -0.29662144\n",
      "time: 4.539801597595215 Epoch: 3425 trainloss: -0.70268553 validloss: -0.2959446\n",
      "time: 4.53818678855896 Epoch: 3426 trainloss: -0.70271015 validloss: -0.29412863\n",
      "time: 4.566544532775879 Epoch: 3427 trainloss: -0.70269716 validloss: -0.2975258\n",
      "time: 4.536883354187012 Epoch: 3428 trainloss: -0.7027049 validloss: -0.2934159\n",
      "time: 4.513879060745239 Epoch: 3429 trainloss: -0.7026675 validloss: -0.29846472\n",
      "time: 4.534210443496704 Epoch: 3430 trainloss: -0.7026887 validloss: -0.29443738\n",
      "time: 4.526597261428833 Epoch: 3431 trainloss: -0.7026748 validloss: -0.29888678\n",
      "time: 4.544095039367676 Epoch: 3432 trainloss: -0.7026812 validloss: -0.29155007\n",
      "time: 4.560012578964233 Epoch: 3433 trainloss: -0.70267266 validloss: -0.29868737\n",
      "time: 4.550912380218506 Epoch: 3434 trainloss: -0.7026746 validloss: -0.29625636\n",
      "time: 4.5249903202056885 Epoch: 3435 trainloss: -0.7026593 validloss: -0.29560652\n",
      "time: 4.534815549850464 Epoch: 3436 trainloss: -0.70265573 validloss: -0.2970723\n",
      "time: 4.531532526016235 Epoch: 3437 trainloss: -0.7026336 validloss: -0.29415467\n",
      "time: 4.53298020362854 Epoch: 3438 trainloss: -0.70261234 validloss: -0.2959975\n",
      "time: 4.533415079116821 Epoch: 3439 trainloss: -0.70261544 validloss: -0.295194\n",
      "time: 4.51616907119751 Epoch: 3440 trainloss: -0.7025925 validloss: -0.29480737\n",
      "time: 4.535097360610962 Epoch: 3441 trainloss: -0.7025907 validloss: -0.3000649\n",
      "time: 4.528845310211182 Epoch: 3442 trainloss: -0.702621 validloss: -0.29088846\n",
      "time: 4.566230297088623 Epoch: 3443 trainloss: -0.7026227 validloss: -0.293727\n",
      "time: 4.538020133972168 Epoch: 3444 trainloss: -0.70266443 validloss: -0.2985655\n",
      "time: 4.559689521789551 Epoch: 3445 trainloss: -0.7026392 validloss: -0.2926134\n",
      "time: 4.532106876373291 Epoch: 3446 trainloss: -0.70268023 validloss: -0.29865053\n",
      "time: 4.54978346824646 Epoch: 3447 trainloss: -0.7026596 validloss: -0.29502204\n",
      "time: 4.5420403480529785 Epoch: 3448 trainloss: -0.7026878 validloss: -0.29673532\n",
      "time: 4.57519268989563 Epoch: 3449 trainloss: -0.7026777 validloss: -0.29698008\n",
      "time: 4.545138597488403 Epoch: 3450 trainloss: -0.70270556 validloss: -0.29509756\n",
      "time: 4.52765417098999 Epoch: 3451 trainloss: -0.70271546 validloss: -0.2940183\n",
      "time: 4.530344724655151 Epoch: 3452 trainloss: -0.70271456 validloss: -0.29385084\n",
      "time: 4.537984848022461 Epoch: 3453 trainloss: -0.70270884 validloss: -0.29672962\n",
      "time: 4.507407903671265 Epoch: 3454 trainloss: -0.7027013 validloss: -0.29301873\n",
      "time: 4.5259881019592285 Epoch: 3455 trainloss: -0.7026693 validloss: -0.29615214\n",
      "time: 4.536107540130615 Epoch: 3456 trainloss: -0.7026658 validloss: -0.2940541\n",
      "time: 4.570265293121338 Epoch: 3457 trainloss: -0.70264983 validloss: -0.2942591\n",
      "time: 4.537841320037842 Epoch: 3458 trainloss: -0.7026749 validloss: -0.29523498\n",
      "time: 4.514466285705566 Epoch: 3459 trainloss: -0.7026677 validloss: -0.29413494\n",
      "time: 4.5513551235198975 Epoch: 3460 trainloss: -0.70263577 validloss: -0.29335013\n",
      "time: 4.566896915435791 Epoch: 3461 trainloss: -0.70261997 validloss: -0.29431832\n",
      "time: 4.560508966445923 Epoch: 3462 trainloss: -0.70254195 validloss: -0.29893985\n",
      "time: 4.523102521896362 Epoch: 3463 trainloss: -0.7025556 validloss: -0.29399955\n",
      "time: 4.5287251472473145 Epoch: 3464 trainloss: -0.70250094 validloss: -0.29029313\n",
      "time: 4.517830848693848 Epoch: 3465 trainloss: -0.70254457 validloss: -0.29889894\n",
      "time: 4.585322618484497 Epoch: 3466 trainloss: -0.70250654 validloss: -0.2952148\n",
      "time: 4.533491611480713 Epoch: 3467 trainloss: -0.7025283 validloss: -0.29532892\n",
      "time: 4.538759469985962 Epoch: 3468 trainloss: -0.7025052 validloss: -0.29829782\n",
      "time: 4.529546022415161 Epoch: 3469 trainloss: -0.70253366 validloss: -0.29655364\n",
      "time: 4.554197072982788 Epoch: 3470 trainloss: -0.7025512 validloss: -0.29391426\n",
      "time: 4.529247760772705 Epoch: 3471 trainloss: -0.7025371 validloss: -0.29704165\n",
      "time: 4.542157173156738 Epoch: 3472 trainloss: -0.70260507 validloss: -0.29425567\n",
      "time: 4.53146767616272 Epoch: 3473 trainloss: -0.70261073 validloss: -0.29535818\n",
      "time: 4.60396146774292 Epoch: 3474 trainloss: -0.7026088 validloss: -0.2953494\n",
      "time: 4.53619909286499 Epoch: 3475 trainloss: -0.7026329 validloss: -0.29687995\n",
      "time: 4.5442986488342285 Epoch: 3476 trainloss: -0.7026407 validloss: -0.2979687\n",
      "time: 4.523301362991333 Epoch: 3477 trainloss: -0.7026645 validloss: -0.2977967\n",
      "time: 4.541488170623779 Epoch: 3478 trainloss: -0.7026648 validloss: -0.2943706\n",
      "time: 4.54106330871582 Epoch: 3479 trainloss: -0.70266485 validloss: -0.29707193\n",
      "time: 4.555804967880249 Epoch: 3480 trainloss: -0.7026521 validloss: -0.29704037\n",
      "time: 4.520571231842041 Epoch: 3481 trainloss: -0.70263654 validloss: -0.29371884\n",
      "time: 4.559195518493652 Epoch: 3482 trainloss: -0.702652 validloss: -0.29603556\n",
      "time: 4.53191876411438 Epoch: 3483 trainloss: -0.702634 validloss: -0.2972024\n",
      "time: 4.5220019817352295 Epoch: 3484 trainloss: -0.70268375 validloss: -0.2967255\n",
      "time: 4.534656047821045 Epoch: 3485 trainloss: -0.7026827 validloss: -0.2930574\n",
      "time: 4.5579674243927 Epoch: 3486 trainloss: -0.7026714 validloss: -0.2996665\n",
      "time: 4.548284530639648 Epoch: 3487 trainloss: -0.70267147 validloss: -0.29275236\n",
      "time: 4.5253517627716064 Epoch: 3488 trainloss: -0.7026689 validloss: -0.29960522\n",
      "time: 4.520658016204834 Epoch: 3489 trainloss: -0.7026826 validloss: -0.29626524\n",
      "time: 4.530733346939087 Epoch: 3490 trainloss: -0.7026504 validloss: -0.29400235\n",
      "time: 4.521442413330078 Epoch: 3491 trainloss: -0.70270395 validloss: -0.2976838\n",
      "time: 4.59197473526001 Epoch: 3492 trainloss: -0.7026817 validloss: -0.29497615\n",
      "time: 4.5210888385772705 Epoch: 3493 trainloss: -0.7026905 validloss: -0.30028513\n",
      "time: 4.527405023574829 Epoch: 3494 trainloss: -0.7027048 validloss: -0.29328734\n",
      "time: 4.520975828170776 Epoch: 3495 trainloss: -0.7027079 validloss: -0.30079696\n",
      "time: 4.514986515045166 Epoch: 3496 trainloss: -0.7027234 validloss: -0.2936304\n",
      "time: 4.531394720077515 Epoch: 3497 trainloss: -0.70272243 validloss: -0.2969061\n",
      "time: 4.534879684448242 Epoch: 3498 trainloss: -0.7026878 validloss: -0.29457974\n",
      "time: 4.515337944030762 Epoch: 3499 trainloss: -0.70269823 validloss: -0.29771915\n",
      "time: 4.570646524429321 Epoch: 3500 trainloss: -0.7027053 validloss: -0.29523152\n",
      "time: 4.523411750793457 Epoch: 3501 trainloss: -0.7026898 validloss: -0.29371575\n",
      "time: 4.526417016983032 Epoch: 3502 trainloss: -0.7026915 validloss: -0.29748985\n",
      "time: 4.524410724639893 Epoch: 3503 trainloss: -0.70268464 validloss: -0.29582638\n",
      "time: 4.525835275650024 Epoch: 3504 trainloss: -0.7026619 validloss: -0.29565674\n",
      "time: 4.526887893676758 Epoch: 3505 trainloss: -0.7026253 validloss: -0.2951685\n",
      "time: 4.519217014312744 Epoch: 3506 trainloss: -0.70267457 validloss: -0.29528043\n",
      "time: 4.627197504043579 Epoch: 3507 trainloss: -0.7026936 validloss: -0.2931167\n",
      "time: 4.570092439651489 Epoch: 3508 trainloss: -0.70269084 validloss: -0.29860562\n",
      "time: 4.531988620758057 Epoch: 3509 trainloss: -0.70270246 validloss: -0.29146975\n",
      "time: 4.520963907241821 Epoch: 3510 trainloss: -0.70269 validloss: -0.2977596\n",
      "time: 4.5602452754974365 Epoch: 3511 trainloss: -0.70270514 validloss: -0.29371244\n",
      "time: 4.647806644439697 Epoch: 3512 trainloss: -0.7026934 validloss: -0.29691845\n",
      "time: 4.553044557571411 Epoch: 3513 trainloss: -0.7026656 validloss: -0.2975631\n",
      "time: 4.708726406097412 Epoch: 3514 trainloss: -0.7026887 validloss: -0.28784007\n",
      "time: 4.80184531211853 Epoch: 3515 trainloss: -0.7026665 validloss: -0.29731086\n",
      "time: 5.034235715866089 Epoch: 3516 trainloss: -0.7026572 validloss: -0.29388425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.7903852462768555 Epoch: 3517 trainloss: -0.7026508 validloss: -0.29627255\n",
      "time: 4.980087518692017 Epoch: 3518 trainloss: -0.7026375 validloss: -0.29575375\n",
      "time: 4.81665301322937 Epoch: 3519 trainloss: -0.7026112 validloss: -0.29339972\n",
      "time: 4.760350942611694 Epoch: 3520 trainloss: -0.7026506 validloss: -0.29660463\n",
      "time: 5.00593376159668 Epoch: 3521 trainloss: -0.70264906 validloss: -0.29546607\n",
      "time: 4.992175340652466 Epoch: 3522 trainloss: -0.70263726 validloss: -0.2942935\n",
      "time: 5.127846002578735 Epoch: 3523 trainloss: -0.7026689 validloss: -0.29555878\n",
      "time: 5.150043725967407 Epoch: 3524 trainloss: -0.70266104 validloss: -0.29773962\n",
      "time: 5.045473575592041 Epoch: 3525 trainloss: -0.7026886 validloss: -0.2910221\n",
      "time: 4.753857612609863 Epoch: 3526 trainloss: -0.70267147 validloss: -0.29405382\n",
      "time: 4.7252514362335205 Epoch: 3527 trainloss: -0.70271194 validloss: -0.29788893\n",
      "time: 4.712359666824341 Epoch: 3528 trainloss: -0.7027322 validloss: -0.2947365\n",
      "time: 4.656891107559204 Epoch: 3529 trainloss: -0.7027456 validloss: -0.29539505\n",
      "time: 4.664709091186523 Epoch: 3530 trainloss: -0.7027437 validloss: -0.29700625\n",
      "time: 4.694956541061401 Epoch: 3531 trainloss: -0.70271623 validloss: -0.29217064\n",
      "time: 4.705504417419434 Epoch: 3532 trainloss: -0.7027161 validloss: -0.29495564\n",
      "time: 4.666680574417114 Epoch: 3533 trainloss: -0.7026959 validloss: -0.297472\n",
      "time: 4.668320417404175 Epoch: 3534 trainloss: -0.7026584 validloss: -0.29613835\n",
      "time: 4.611900806427002 Epoch: 3535 trainloss: -0.7026268 validloss: -0.29449514\n",
      "time: 4.681995630264282 Epoch: 3536 trainloss: -0.70265585 validloss: -0.29701263\n",
      "time: 4.703811407089233 Epoch: 3537 trainloss: -0.70262986 validloss: -0.29145777\n",
      "time: 4.6348981857299805 Epoch: 3538 trainloss: -0.70262057 validloss: -0.29817182\n",
      "time: 4.665292501449585 Epoch: 3539 trainloss: -0.7026092 validloss: -0.29607317\n",
      "time: 4.663697719573975 Epoch: 3540 trainloss: -0.7025882 validloss: -0.29117227\n",
      "time: 4.769159317016602 Epoch: 3541 trainloss: -0.7025348 validloss: -0.29596746\n",
      "time: 4.741791248321533 Epoch: 3542 trainloss: -0.70255476 validloss: -0.299678\n",
      "time: 4.780574321746826 Epoch: 3543 trainloss: -0.70260483 validloss: -0.29245666\n",
      "time: 4.996720552444458 Epoch: 3544 trainloss: -0.7025777 validloss: -0.29559115\n",
      "time: 4.997473239898682 Epoch: 3545 trainloss: -0.7025737 validloss: -0.29457965\n",
      "time: 5.019259452819824 Epoch: 3546 trainloss: -0.7025485 validloss: -0.30079073\n",
      "time: 5.012865781784058 Epoch: 3547 trainloss: -0.70258194 validloss: -0.29368237\n",
      "time: 5.021685600280762 Epoch: 3548 trainloss: -0.70256317 validloss: -0.2944729\n",
      "time: 4.980677366256714 Epoch: 3549 trainloss: -0.7025803 validloss: -0.29815412\n",
      "time: 5.013281345367432 Epoch: 3550 trainloss: -0.70252806 validloss: -0.29500508\n",
      "time: 5.106205701828003 Epoch: 3551 trainloss: -0.70254356 validloss: -0.3010434\n",
      "time: 5.02155876159668 Epoch: 3552 trainloss: -0.7024986 validloss: -0.29275352\n",
      "time: 4.986188888549805 Epoch: 3553 trainloss: -0.70255995 validloss: -0.3002388\n",
      "time: 4.999366044998169 Epoch: 3554 trainloss: -0.70255893 validloss: -0.29613927\n",
      "time: 5.005661487579346 Epoch: 3555 trainloss: -0.7025909 validloss: -0.29373154\n",
      "time: 4.990153074264526 Epoch: 3556 trainloss: -0.7025824 validloss: -0.30043283\n",
      "time: 5.034597396850586 Epoch: 3557 trainloss: -0.702594 validloss: -0.29421708\n",
      "time: 5.002900123596191 Epoch: 3558 trainloss: -0.7025991 validloss: -0.30064243\n",
      "time: 5.030640602111816 Epoch: 3559 trainloss: -0.7026343 validloss: -0.2944318\n",
      "time: 5.014845609664917 Epoch: 3560 trainloss: -0.70264864 validloss: -0.2954456\n",
      "time: 5.028496503829956 Epoch: 3561 trainloss: -0.7026725 validloss: -0.2968577\n",
      "time: 5.020314693450928 Epoch: 3562 trainloss: -0.70267546 validloss: -0.29403174\n",
      "time: 5.021745443344116 Epoch: 3563 trainloss: -0.7026643 validloss: -0.29386967\n",
      "time: 5.035120725631714 Epoch: 3564 trainloss: -0.7026952 validloss: -0.29585448\n",
      "time: 5.01757550239563 Epoch: 3565 trainloss: -0.7026925 validloss: -0.29660133\n",
      "time: 5.005621433258057 Epoch: 3566 trainloss: -0.70270556 validloss: -0.2961025\n",
      "time: 4.998824119567871 Epoch: 3567 trainloss: -0.702709 validloss: -0.29250193\n",
      "time: 5.024506568908691 Epoch: 3568 trainloss: -0.7027038 validloss: -0.29851165\n",
      "time: 5.012374639511108 Epoch: 3569 trainloss: -0.7027078 validloss: -0.29532158\n",
      "time: 5.054661989212036 Epoch: 3570 trainloss: -0.70271486 validloss: -0.29603463\n",
      "time: 5.009615182876587 Epoch: 3571 trainloss: -0.70267314 validloss: -0.29347616\n",
      "time: 4.989869832992554 Epoch: 3572 trainloss: -0.702647 validloss: -0.2984446\n",
      "time: 4.989429950714111 Epoch: 3573 trainloss: -0.7026387 validloss: -0.2960788\n",
      "time: 5.01284646987915 Epoch: 3574 trainloss: -0.70262665 validloss: -0.29992726\n",
      "time: 5.019899845123291 Epoch: 3575 trainloss: -0.7026648 validloss: -0.29567185\n",
      "time: 5.018641710281372 Epoch: 3576 trainloss: -0.70261973 validloss: -0.2985087\n",
      "time: 5.034050703048706 Epoch: 3577 trainloss: -0.702665 validloss: -0.29338202\n",
      "time: 5.001910209655762 Epoch: 3578 trainloss: -0.70264363 validloss: -0.29531872\n",
      "time: 5.0177507400512695 Epoch: 3579 trainloss: -0.70266634 validloss: -0.29711208\n",
      "time: 5.011861324310303 Epoch: 3580 trainloss: -0.70267665 validloss: -0.29652444\n",
      "time: 5.007034540176392 Epoch: 3581 trainloss: -0.7026835 validloss: -0.29341105\n",
      "time: 5.030453205108643 Epoch: 3582 trainloss: -0.7027207 validloss: -0.2981664\n",
      "time: 4.993632793426514 Epoch: 3583 trainloss: -0.7027012 validloss: -0.2947732\n",
      "time: 5.000093460083008 Epoch: 3584 trainloss: -0.70271254 validloss: -0.29750872\n",
      "time: 4.999388694763184 Epoch: 3585 trainloss: -0.70270395 validloss: -0.29219764\n",
      "time: 5.015218734741211 Epoch: 3586 trainloss: -0.7026953 validloss: -0.30004463\n",
      "time: 4.994851112365723 Epoch: 3587 trainloss: -0.7026975 validloss: -0.29505908\n",
      "time: 4.991593599319458 Epoch: 3588 trainloss: -0.70267475 validloss: -0.29664138\n",
      "time: 5.009824991226196 Epoch: 3589 trainloss: -0.7026743 validloss: -0.29594702\n",
      "time: 4.998701095581055 Epoch: 3590 trainloss: -0.70266825 validloss: -0.29712433\n",
      "time: 5.018914699554443 Epoch: 3591 trainloss: -0.7027067 validloss: -0.2956682\n",
      "time: 5.019952058792114 Epoch: 3592 trainloss: -0.70269483 validloss: -0.2933411\n",
      "time: 5.012667894363403 Epoch: 3593 trainloss: -0.7027206 validloss: -0.29860252\n",
      "time: 5.049042701721191 Epoch: 3594 trainloss: -0.7027188 validloss: -0.2969507\n",
      "time: 4.9962029457092285 Epoch: 3595 trainloss: -0.7027051 validloss: -0.2942965\n",
      "time: 5.0142247676849365 Epoch: 3596 trainloss: -0.7026953 validloss: -0.29753992\n",
      "time: 4.9925291538238525 Epoch: 3597 trainloss: -0.70270574 validloss: -0.29759875\n",
      "time: 5.028124094009399 Epoch: 3598 trainloss: -0.70270264 validloss: -0.29595476\n",
      "time: 5.040391206741333 Epoch: 3599 trainloss: -0.7027298 validloss: -0.29492152\n",
      "time: 5.028785228729248 Epoch: 3600 trainloss: -0.70273477 validloss: -0.29682633\n",
      "time: 5.0160071849823 Epoch: 3601 trainloss: -0.7027297 validloss: -0.29533488\n",
      "time: 5.005439043045044 Epoch: 3602 trainloss: -0.7027293 validloss: -0.29462156\n",
      "time: 5.037075996398926 Epoch: 3603 trainloss: -0.7027389 validloss: -0.2965284\n",
      "time: 4.999534845352173 Epoch: 3604 trainloss: -0.7027457 validloss: -0.29488307\n",
      "time: 4.983144283294678 Epoch: 3605 trainloss: -0.7027355 validloss: -0.29542693\n",
      "time: 5.036262035369873 Epoch: 3606 trainloss: -0.70274 validloss: -0.29509273\n",
      "time: 5.019076108932495 Epoch: 3607 trainloss: -0.70274276 validloss: -0.29308277\n",
      "time: 5.005533933639526 Epoch: 3608 trainloss: -0.7027364 validloss: -0.2953714\n",
      "time: 5.009625196456909 Epoch: 3609 trainloss: -0.7027161 validloss: -0.29242527\n",
      "time: 5.012442111968994 Epoch: 3610 trainloss: -0.70270586 validloss: -0.29742226\n",
      "time: 5.030887126922607 Epoch: 3611 trainloss: -0.7026408 validloss: -0.29340476\n",
      "time: 5.037459373474121 Epoch: 3612 trainloss: -0.7026266 validloss: -0.29313603\n",
      "time: 5.0260210037231445 Epoch: 3613 trainloss: -0.7025933 validloss: -0.30047965\n",
      "time: 5.000568866729736 Epoch: 3614 trainloss: -0.70265204 validloss: -0.29333284\n",
      "time: 5.045486927032471 Epoch: 3615 trainloss: -0.70261925 validloss: -0.29569343\n",
      "time: 5.002436876296997 Epoch: 3616 trainloss: -0.7026637 validloss: -0.29678616\n",
      "time: 4.995923757553101 Epoch: 3617 trainloss: -0.7026668 validloss: -0.29590377\n",
      "time: 4.830103874206543 Epoch: 3618 trainloss: -0.70269185 validloss: -0.29920226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.606937885284424 Epoch: 3619 trainloss: -0.70270056 validloss: -0.2951866\n",
      "time: 4.625684499740601 Epoch: 3620 trainloss: -0.7027181 validloss: -0.29824275\n",
      "time: 4.585115909576416 Epoch: 3621 trainloss: -0.7027159 validloss: -0.29329273\n",
      "time: 4.698441028594971 Epoch: 3622 trainloss: -0.702701 validloss: -0.29573464\n",
      "time: 4.77178692817688 Epoch: 3623 trainloss: -0.70269924 validloss: -0.29497892\n",
      "time: 4.778862953186035 Epoch: 3624 trainloss: -0.7026518 validloss: -0.29849795\n",
      "time: 4.524231433868408 Epoch: 3625 trainloss: -0.702682 validloss: -0.2954843\n",
      "time: 4.91377854347229 Epoch: 3626 trainloss: -0.70261884 validloss: -0.29558703\n",
      "time: 4.713132619857788 Epoch: 3627 trainloss: -0.7026703 validloss: -0.29641876\n",
      "time: 4.696515798568726 Epoch: 3628 trainloss: -0.7026198 validloss: -0.2948207\n",
      "time: 4.513986825942993 Epoch: 3629 trainloss: -0.7026515 validloss: -0.297275\n",
      "time: 4.550952434539795 Epoch: 3630 trainloss: -0.70260644 validloss: -0.2960817\n",
      "time: 4.518675327301025 Epoch: 3631 trainloss: -0.70264804 validloss: -0.29449514\n",
      "time: 4.52813720703125 Epoch: 3632 trainloss: -0.70266175 validloss: -0.29924178\n",
      "time: 4.536377191543579 Epoch: 3633 trainloss: -0.70261806 validloss: -0.29357773\n",
      "time: 4.5306689739227295 Epoch: 3634 trainloss: -0.70263827 validloss: -0.29578263\n",
      "time: 4.513916730880737 Epoch: 3635 trainloss: -0.7026055 validloss: -0.2951132\n",
      "time: 4.56166410446167 Epoch: 3636 trainloss: -0.70264316 validloss: -0.29658228\n",
      "time: 4.523885488510132 Epoch: 3637 trainloss: -0.7026338 validloss: -0.29216823\n",
      "time: 4.516785383224487 Epoch: 3638 trainloss: -0.70263946 validloss: -0.3000145\n",
      "time: 4.52593207359314 Epoch: 3639 trainloss: -0.7026379 validloss: -0.2949384\n",
      "time: 4.530317306518555 Epoch: 3640 trainloss: -0.70266783 validloss: -0.29344037\n",
      "time: 4.524147033691406 Epoch: 3641 trainloss: -0.7027147 validloss: -0.2979505\n",
      "time: 4.530888557434082 Epoch: 3642 trainloss: -0.7027151 validloss: -0.29676312\n",
      "time: 4.520564079284668 Epoch: 3643 trainloss: -0.7027499 validloss: -0.2946201\n",
      "time: 4.52825665473938 Epoch: 3644 trainloss: -0.7027714 validloss: -0.29367432\n",
      "time: 4.525484561920166 Epoch: 3645 trainloss: -0.7027858 validloss: -0.2983809\n",
      "time: 4.536396741867065 Epoch: 3646 trainloss: -0.702798 validloss: -0.29642385\n",
      "time: 4.533425331115723 Epoch: 3647 trainloss: -0.7027968 validloss: -0.29387918\n",
      "time: 4.516015529632568 Epoch: 3648 trainloss: -0.7027975 validloss: -0.29848593\n",
      "time: 4.5335447788238525 Epoch: 3649 trainloss: -0.702799 validloss: -0.2920538\n",
      "time: 4.506925821304321 Epoch: 3650 trainloss: -0.70279163 validloss: -0.2989525\n",
      "time: 4.5323145389556885 Epoch: 3651 trainloss: -0.7027936 validloss: -0.29206485\n",
      "time: 4.498697280883789 Epoch: 3652 trainloss: -0.7027862 validloss: -0.2985096\n",
      "time: 4.522387742996216 Epoch: 3653 trainloss: -0.70279217 validloss: -0.29451984\n",
      "time: 4.515439033508301 Epoch: 3654 trainloss: -0.7027865 validloss: -0.29777518\n",
      "time: 4.526890516281128 Epoch: 3655 trainloss: -0.70278037 validloss: -0.29491732\n",
      "time: 4.515861749649048 Epoch: 3656 trainloss: -0.7027718 validloss: -0.29338604\n",
      "time: 4.518758058547974 Epoch: 3657 trainloss: -0.7027816 validloss: -0.29686505\n",
      "time: 4.545397520065308 Epoch: 3658 trainloss: -0.7027705 validloss: -0.2980115\n",
      "time: 4.521807670593262 Epoch: 3659 trainloss: -0.70277387 validloss: -0.29493135\n",
      "time: 4.5061445236206055 Epoch: 3660 trainloss: -0.70277303 validloss: -0.2954738\n",
      "time: 4.533573865890503 Epoch: 3661 trainloss: -0.70279986 validloss: -0.2931347\n",
      "time: 4.525280475616455 Epoch: 3662 trainloss: -0.70278394 validloss: -0.29470164\n",
      "time: 4.53689169883728 Epoch: 3663 trainloss: -0.70274127 validloss: -0.29646707\n",
      "time: 4.532906532287598 Epoch: 3664 trainloss: -0.7027257 validloss: -0.29289445\n",
      "time: 4.5136425495147705 Epoch: 3665 trainloss: -0.70272267 validloss: -0.29943362\n",
      "time: 4.5206310749053955 Epoch: 3666 trainloss: -0.7027202 validloss: -0.29190862\n",
      "time: 4.5344767570495605 Epoch: 3667 trainloss: -0.7027258 validloss: -0.29545546\n",
      "time: 4.515948057174683 Epoch: 3668 trainloss: -0.7027445 validloss: -0.29389384\n",
      "time: 4.535425901412964 Epoch: 3669 trainloss: -0.7027362 validloss: -0.2945836\n",
      "time: 4.528550863265991 Epoch: 3670 trainloss: -0.7027632 validloss: -0.29403278\n",
      "time: 4.531344413757324 Epoch: 3671 trainloss: -0.7027627 validloss: -0.29828966\n",
      "time: 4.550097227096558 Epoch: 3672 trainloss: -0.70276093 validloss: -0.29109526\n",
      "time: 4.5110485553741455 Epoch: 3673 trainloss: -0.70277315 validloss: -0.29888853\n",
      "time: 4.522599697113037 Epoch: 3674 trainloss: -0.702779 validloss: -0.2949709\n",
      "time: 4.516879081726074 Epoch: 3675 trainloss: -0.7027916 validloss: -0.2925746\n",
      "time: 4.555394411087036 Epoch: 3676 trainloss: -0.7027824 validloss: -0.29845193\n",
      "time: 4.511549949645996 Epoch: 3677 trainloss: -0.7027849 validloss: -0.28693253\n",
      "time: 4.521464109420776 Epoch: 3678 trainloss: -0.70277673 validloss: -0.29917738\n",
      "time: 4.501948356628418 Epoch: 3679 trainloss: -0.702766 validloss: -0.29532722\n",
      "time: 4.519758462905884 Epoch: 3680 trainloss: -0.70277184 validloss: -0.2910824\n",
      "time: 4.508687496185303 Epoch: 3681 trainloss: -0.7027337 validloss: -0.29576182\n",
      "time: 4.589711666107178 Epoch: 3682 trainloss: -0.702746 validloss: -0.29038945\n",
      "time: 5.0050575733184814 Epoch: 3683 trainloss: -0.70274043 validloss: -0.29607782\n",
      "time: 4.706483840942383 Epoch: 3684 trainloss: -0.70274377 validloss: -0.29197806\n",
      "time: 4.812022924423218 Epoch: 3685 trainloss: -0.70274353 validloss: -0.29753864\n",
      "time: 4.67071533203125 Epoch: 3686 trainloss: -0.70277834 validloss: -0.29414564\n",
      "time: 4.536314487457275 Epoch: 3687 trainloss: -0.7027778 validloss: -0.29350033\n",
      "time: 4.5516767501831055 Epoch: 3688 trainloss: -0.70278203 validloss: -0.29338706\n",
      "time: 4.519981145858765 Epoch: 3689 trainloss: -0.7027917 validloss: -0.29463172\n",
      "time: 4.540281772613525 Epoch: 3690 trainloss: -0.7027733 validloss: -0.29393828\n",
      "time: 4.51271915435791 Epoch: 3691 trainloss: -0.7027788 validloss: -0.29465455\n",
      "time: 4.522216796875 Epoch: 3692 trainloss: -0.7027506 validloss: -0.29580408\n",
      "time: 4.545074462890625 Epoch: 3693 trainloss: -0.7027732 validloss: -0.29721612\n",
      "time: 4.53316593170166 Epoch: 3694 trainloss: -0.7027812 validloss: -0.2931328\n",
      "time: 4.565673589706421 Epoch: 3695 trainloss: -0.7027793 validloss: -0.29570153\n",
      "time: 4.524263143539429 Epoch: 3696 trainloss: -0.7027689 validloss: -0.29377088\n",
      "time: 4.5185546875 Epoch: 3697 trainloss: -0.702796 validloss: -0.2957328\n",
      "time: 4.535186767578125 Epoch: 3698 trainloss: -0.7027674 validloss: -0.2937992\n",
      "time: 4.52520227432251 Epoch: 3699 trainloss: -0.70276475 validloss: -0.29412085\n",
      "time: 4.512260913848877 Epoch: 3700 trainloss: -0.7027288 validloss: -0.29698494\n",
      "time: 4.562282085418701 Epoch: 3701 trainloss: -0.7027181 validloss: -0.2937965\n",
      "time: 4.549061059951782 Epoch: 3702 trainloss: -0.7026873 validloss: -0.29717028\n",
      "time: 4.517380475997925 Epoch: 3703 trainloss: -0.7027124 validloss: -0.29306713\n",
      "time: 4.517894268035889 Epoch: 3704 trainloss: -0.7027279 validloss: -0.29501033\n",
      "time: 4.518478631973267 Epoch: 3705 trainloss: -0.7027348 validloss: -0.29568318\n",
      "time: 4.529318809509277 Epoch: 3706 trainloss: -0.7027684 validloss: -0.29050344\n",
      "time: 4.5309576988220215 Epoch: 3707 trainloss: -0.70275164 validloss: -0.29799402\n",
      "time: 4.5137779712677 Epoch: 3708 trainloss: -0.7027494 validloss: -0.2943461\n",
      "time: 4.517489433288574 Epoch: 3709 trainloss: -0.70272344 validloss: -0.2944121\n",
      "time: 4.5170578956604 Epoch: 3710 trainloss: -0.7027452 validloss: -0.29510608\n",
      "time: 4.542047500610352 Epoch: 3711 trainloss: -0.70273477 validloss: -0.29719228\n",
      "time: 4.531620025634766 Epoch: 3712 trainloss: -0.70276767 validloss: -0.2948009\n",
      "time: 4.537041902542114 Epoch: 3713 trainloss: -0.70274794 validloss: -0.29251215\n",
      "time: 4.5406882762908936 Epoch: 3714 trainloss: -0.7027363 validloss: -0.29826528\n",
      "time: 4.536147594451904 Epoch: 3715 trainloss: -0.7027199 validloss: -0.29192713\n",
      "time: 4.525335311889648 Epoch: 3716 trainloss: -0.7027274 validloss: -0.29679868\n",
      "time: 4.559532880783081 Epoch: 3717 trainloss: -0.7027318 validloss: -0.29328346\n",
      "time: 4.528773307800293 Epoch: 3718 trainloss: -0.7027225 validloss: -0.2952088\n",
      "time: 4.504246711730957 Epoch: 3719 trainloss: -0.7027013 validloss: -0.29802513\n",
      "time: 4.539798259735107 Epoch: 3720 trainloss: -0.70270276 validloss: -0.29426792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.533836126327515 Epoch: 3721 trainloss: -0.7026673 validloss: -0.29152006\n",
      "time: 4.5345072746276855 Epoch: 3722 trainloss: -0.70267063 validloss: -0.296558\n",
      "time: 4.526526927947998 Epoch: 3723 trainloss: -0.70269835 validloss: -0.2945639\n",
      "time: 4.530956745147705 Epoch: 3724 trainloss: -0.7026756 validloss: -0.29067755\n",
      "time: 4.536919593811035 Epoch: 3725 trainloss: -0.7026477 validloss: -0.296858\n",
      "time: 4.504453659057617 Epoch: 3726 trainloss: -0.7026172 validloss: -0.29702514\n",
      "time: 4.560798645019531 Epoch: 3727 trainloss: -0.70268685 validloss: -0.29161507\n",
      "time: 4.538017272949219 Epoch: 3728 trainloss: -0.70274246 validloss: -0.29594684\n",
      "time: 4.529473066329956 Epoch: 3729 trainloss: -0.7027456 validloss: -0.29229337\n",
      "time: 4.50872802734375 Epoch: 3730 trainloss: -0.70277315 validloss: -0.2990878\n",
      "time: 4.532874345779419 Epoch: 3731 trainloss: -0.7027468 validloss: -0.29041204\n",
      "time: 4.523302316665649 Epoch: 3732 trainloss: -0.7027446 validloss: -0.29751247\n",
      "time: 4.562237739562988 Epoch: 3733 trainloss: -0.70273304 validloss: -0.29632574\n",
      "time: 4.531081914901733 Epoch: 3734 trainloss: -0.7027179 validloss: -0.29474428\n",
      "time: 4.50614857673645 Epoch: 3735 trainloss: -0.7027286 validloss: -0.29111186\n",
      "time: 4.526511907577515 Epoch: 3736 trainloss: -0.7027346 validloss: -0.29659098\n",
      "time: 4.5615317821502686 Epoch: 3737 trainloss: -0.70273745 validloss: -0.29428664\n",
      "time: 4.503579616546631 Epoch: 3738 trainloss: -0.7027419 validloss: -0.29596585\n",
      "time: 4.522259712219238 Epoch: 3739 trainloss: -0.70273185 validloss: -0.29410347\n",
      "time: 4.524573087692261 Epoch: 3740 trainloss: -0.70275414 validloss: -0.29641253\n",
      "time: 4.526316165924072 Epoch: 3741 trainloss: -0.702745 validloss: -0.29667646\n",
      "time: 4.520224571228027 Epoch: 3742 trainloss: -0.70276976 validloss: -0.2970345\n",
      "time: 4.560186386108398 Epoch: 3743 trainloss: -0.7027202 validloss: -0.2928341\n",
      "time: 4.5125439167022705 Epoch: 3744 trainloss: -0.7027463 validloss: -0.29979488\n",
      "time: 4.519023180007935 Epoch: 3745 trainloss: -0.702763 validloss: -0.2921682\n",
      "time: 4.518123388290405 Epoch: 3746 trainloss: -0.7027497 validloss: -0.29691646\n",
      "time: 4.53670859336853 Epoch: 3747 trainloss: -0.70278406 validloss: -0.2931521\n",
      "time: 4.509937524795532 Epoch: 3748 trainloss: -0.70275646 validloss: -0.2937611\n",
      "time: 4.519909143447876 Epoch: 3749 trainloss: -0.7027689 validloss: -0.29616326\n",
      "time: 4.526998281478882 Epoch: 3750 trainloss: -0.70272493 validloss: -0.2904701\n",
      "time: 4.536359786987305 Epoch: 3751 trainloss: -0.7027054 validloss: -0.29971898\n",
      "time: 4.519377708435059 Epoch: 3752 trainloss: -0.70264614 validloss: -0.29465663\n",
      "time: 4.540417194366455 Epoch: 3753 trainloss: -0.7026226 validloss: -0.29436433\n",
      "time: 4.536240100860596 Epoch: 3754 trainloss: -0.7026163 validloss: -0.29557118\n",
      "time: 4.557360887527466 Epoch: 3755 trainloss: -0.7026205 validloss: -0.29508522\n",
      "time: 4.530261039733887 Epoch: 3756 trainloss: -0.70262635 validloss: -0.2940973\n",
      "time: 4.531040191650391 Epoch: 3757 trainloss: -0.7026002 validloss: -0.29594737\n",
      "time: 4.538335561752319 Epoch: 3758 trainloss: -0.7026345 validloss: -0.29658583\n",
      "time: 4.538862228393555 Epoch: 3759 trainloss: -0.7026307 validloss: -0.29447907\n",
      "time: 4.536762952804565 Epoch: 3760 trainloss: -0.70261794 validloss: -0.29852515\n",
      "time: 4.5272536277771 Epoch: 3761 trainloss: -0.7026416 validloss: -0.29593647\n",
      "time: 4.515493631362915 Epoch: 3762 trainloss: -0.70257604 validloss: -0.2979125\n",
      "time: 4.544079065322876 Epoch: 3763 trainloss: -0.7026553 validloss: -0.2949824\n",
      "time: 4.534589052200317 Epoch: 3764 trainloss: -0.7025987 validloss: -0.29263717\n",
      "time: 4.542930603027344 Epoch: 3765 trainloss: -0.70261365 validloss: -0.3018746\n",
      "time: 4.526048898696899 Epoch: 3766 trainloss: -0.7025872 validloss: -0.29319662\n",
      "time: 4.533804178237915 Epoch: 3767 trainloss: -0.70260805 validloss: -0.29723966\n",
      "time: 4.526068449020386 Epoch: 3768 trainloss: -0.70265067 validloss: -0.29872555\n",
      "time: 4.527621030807495 Epoch: 3769 trainloss: -0.7026343 validloss: -0.29320598\n",
      "time: 4.5177507400512695 Epoch: 3770 trainloss: -0.7026752 validloss: -0.29450598\n",
      "time: 4.55142617225647 Epoch: 3771 trainloss: -0.7026958 validloss: -0.29683778\n",
      "time: 4.534241676330566 Epoch: 3772 trainloss: -0.70268846 validloss: -0.29985252\n",
      "time: 4.539480686187744 Epoch: 3773 trainloss: -0.7026929 validloss: -0.2944362\n",
      "time: 4.569333076477051 Epoch: 3774 trainloss: -0.7027187 validloss: -0.29628164\n",
      "time: 4.703454494476318 Epoch: 3775 trainloss: -0.70272225 validloss: -0.29879215\n",
      "time: 4.797871351242065 Epoch: 3776 trainloss: -0.70271665 validloss: -0.29665762\n",
      "time: 4.672295331954956 Epoch: 3777 trainloss: -0.7027141 validloss: -0.2938171\n",
      "time: 4.577349901199341 Epoch: 3778 trainloss: -0.702659 validloss: -0.29802132\n",
      "time: 4.5923449993133545 Epoch: 3779 trainloss: -0.70266634 validloss: -0.29751688\n",
      "time: 4.6935248374938965 Epoch: 3780 trainloss: -0.7026646 validloss: -0.29491654\n",
      "time: 4.620586633682251 Epoch: 3781 trainloss: -0.7026874 validloss: -0.29358527\n",
      "time: 4.689985036849976 Epoch: 3782 trainloss: -0.7026646 validloss: -0.30042288\n",
      "time: 4.997857332229614 Epoch: 3783 trainloss: -0.7026776 validloss: -0.29734385\n",
      "time: 5.090856552124023 Epoch: 3784 trainloss: -0.70266825 validloss: -0.29271036\n",
      "time: 4.824514627456665 Epoch: 3785 trainloss: -0.70269173 validloss: -0.30000255\n",
      "time: 4.550717830657959 Epoch: 3786 trainloss: -0.7026994 validloss: -0.2966747\n",
      "time: 4.630828619003296 Epoch: 3787 trainloss: -0.7026986 validloss: -0.2937464\n",
      "time: 4.69713282585144 Epoch: 3788 trainloss: -0.70269537 validloss: -0.29612413\n",
      "time: 4.678405523300171 Epoch: 3789 trainloss: -0.7026382 validloss: -0.2972979\n",
      "time: 4.615342378616333 Epoch: 3790 trainloss: -0.7026729 validloss: -0.30014014\n",
      "time: 4.625462293624878 Epoch: 3791 trainloss: -0.7026656 validloss: -0.2939959\n",
      "time: 4.611791372299194 Epoch: 3792 trainloss: -0.7026902 validloss: -0.29921234\n",
      "time: 4.619099855422974 Epoch: 3793 trainloss: -0.70268214 validloss: -0.29408157\n",
      "time: 4.5754759311676025 Epoch: 3794 trainloss: -0.70269394 validloss: -0.29527345\n",
      "time: 4.6050941944122314 Epoch: 3795 trainloss: -0.70270014 validloss: -0.29774016\n",
      "time: 4.537980794906616 Epoch: 3796 trainloss: -0.70272964 validloss: -0.29498535\n",
      "time: 4.697880268096924 Epoch: 3797 trainloss: -0.7027128 validloss: -0.2995963\n",
      "time: 4.610737562179565 Epoch: 3798 trainloss: -0.70271736 validloss: -0.29176337\n",
      "time: 4.727673530578613 Epoch: 3799 trainloss: -0.70270544 validloss: -0.2979151\n",
      "time: 4.613067626953125 Epoch: 3800 trainloss: -0.7026752 validloss: -0.29831684\n",
      "time: 4.579809904098511 Epoch: 3801 trainloss: -0.7026714 validloss: -0.29625374\n",
      "time: 4.578204870223999 Epoch: 3802 trainloss: -0.7026963 validloss: -0.29478922\n",
      "time: 4.578691482543945 Epoch: 3803 trainloss: -0.7027123 validloss: -0.30210036\n",
      "time: 4.558467149734497 Epoch: 3804 trainloss: -0.7027476 validloss: -0.2943916\n",
      "time: 4.5913519859313965 Epoch: 3805 trainloss: -0.70274365 validloss: -0.2988096\n",
      "time: 4.613048791885376 Epoch: 3806 trainloss: -0.7027667 validloss: -0.3000848\n",
      "time: 4.605240106582642 Epoch: 3807 trainloss: -0.7027358 validloss: -0.29344857\n",
      "time: 4.571992635726929 Epoch: 3808 trainloss: -0.7027241 validloss: -0.29623324\n",
      "time: 4.551775932312012 Epoch: 3809 trainloss: -0.70273244 validloss: -0.30140632\n",
      "time: 4.565025091171265 Epoch: 3810 trainloss: -0.70272624 validloss: -0.29296482\n",
      "time: 4.70020866394043 Epoch: 3811 trainloss: -0.70273787 validloss: -0.29477993\n",
      "time: 4.625238656997681 Epoch: 3812 trainloss: -0.7027267 validloss: -0.29603893\n",
      "time: 4.572799205780029 Epoch: 3813 trainloss: -0.70269996 validloss: -0.29765487\n",
      "time: 4.673010587692261 Epoch: 3814 trainloss: -0.7027054 validloss: -0.2945667\n",
      "time: 4.611800193786621 Epoch: 3815 trainloss: -0.7026996 validloss: -0.29809406\n",
      "time: 4.592243432998657 Epoch: 3816 trainloss: -0.7026848 validloss: -0.2993175\n",
      "time: 4.557987451553345 Epoch: 3817 trainloss: -0.7026617 validloss: -0.2937306\n",
      "time: 4.557468414306641 Epoch: 3818 trainloss: -0.7026459 validloss: -0.29355675\n",
      "time: 4.563421726226807 Epoch: 3819 trainloss: -0.7026757 validloss: -0.2965644\n",
      "time: 4.559052228927612 Epoch: 3820 trainloss: -0.7026309 validloss: -0.2948111\n",
      "time: 4.550224304199219 Epoch: 3821 trainloss: -0.7026558 validloss: -0.29601756\n",
      "time: 4.542557716369629 Epoch: 3822 trainloss: -0.70267355 validloss: -0.29554942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.617231607437134 Epoch: 3823 trainloss: -0.7026697 validloss: -0.2975053\n",
      "time: 4.649402141571045 Epoch: 3824 trainloss: -0.7026816 validloss: -0.3021783\n",
      "time: 4.72815728187561 Epoch: 3825 trainloss: -0.7026483 validloss: -0.28752258\n",
      "time: 4.952639102935791 Epoch: 3826 trainloss: -0.7026869 validloss: -0.30113852\n",
      "time: 4.821912050247192 Epoch: 3827 trainloss: -0.7026735 validloss: -0.2907047\n",
      "time: 4.630927801132202 Epoch: 3828 trainloss: -0.7027457 validloss: -0.29800454\n",
      "time: 4.540405511856079 Epoch: 3829 trainloss: -0.70275533 validloss: -0.29561862\n",
      "time: 4.7197265625 Epoch: 3830 trainloss: -0.702762 validloss: -0.29389298\n",
      "time: 4.87078595161438 Epoch: 3831 trainloss: -0.7027514 validloss: -0.29951945\n",
      "time: 4.74623703956604 Epoch: 3832 trainloss: -0.70277065 validloss: -0.29416037\n",
      "time: 4.574862003326416 Epoch: 3833 trainloss: -0.7027379 validloss: -0.29422227\n",
      "time: 4.572309255599976 Epoch: 3834 trainloss: -0.7027245 validloss: -0.297607\n",
      "time: 4.630860328674316 Epoch: 3835 trainloss: -0.70276296 validloss: -0.29627556\n",
      "time: 4.593243598937988 Epoch: 3836 trainloss: -0.7027441 validloss: -0.2943143\n",
      "time: 4.586483716964722 Epoch: 3837 trainloss: -0.7027786 validloss: -0.29750603\n",
      "time: 4.628363132476807 Epoch: 3838 trainloss: -0.7027944 validloss: -0.2940861\n",
      "time: 4.681394338607788 Epoch: 3839 trainloss: -0.7027917 validloss: -0.29667515\n",
      "time: 4.700140953063965 Epoch: 3840 trainloss: -0.702797 validloss: -0.29287726\n",
      "time: 4.776869535446167 Epoch: 3841 trainloss: -0.7027765 validloss: -0.29947194\n",
      "time: 4.683030128479004 Epoch: 3842 trainloss: -0.7027795 validloss: -0.29536736\n",
      "time: 4.859543085098267 Epoch: 3843 trainloss: -0.7027492 validloss: -0.29763025\n",
      "time: 4.684877872467041 Epoch: 3844 trainloss: -0.70275825 validloss: -0.29413244\n",
      "time: 5.007856130599976 Epoch: 3845 trainloss: -0.702727 validloss: -0.29749182\n",
      "time: 5.176640033721924 Epoch: 3846 trainloss: -0.7027304 validloss: -0.29884368\n",
      "time: 4.911689519882202 Epoch: 3847 trainloss: -0.7026752 validloss: -0.29338557\n",
      "time: 5.03083062171936 Epoch: 3848 trainloss: -0.70265967 validloss: -0.29626182\n",
      "time: 5.109015941619873 Epoch: 3849 trainloss: -0.7026563 validloss: -0.30195272\n",
      "time: 4.740786552429199 Epoch: 3850 trainloss: -0.70262057 validloss: -0.2903395\n",
      "time: 4.900277853012085 Epoch: 3851 trainloss: -0.702662 validloss: -0.29898953\n",
      "time: 4.733659029006958 Epoch: 3852 trainloss: -0.7026249 validloss: -0.2948202\n",
      "time: 4.941608905792236 Epoch: 3853 trainloss: -0.70265394 validloss: -0.29569498\n",
      "time: 5.122366905212402 Epoch: 3854 trainloss: -0.7026403 validloss: -0.29468724\n",
      "time: 4.856135606765747 Epoch: 3855 trainloss: -0.7026785 validloss: -0.2961878\n",
      "time: 4.686136484146118 Epoch: 3856 trainloss: -0.70265025 validloss: -0.29819864\n",
      "time: 4.775141477584839 Epoch: 3857 trainloss: -0.70263857 validloss: -0.2920134\n",
      "time: 4.60033392906189 Epoch: 3858 trainloss: -0.70266825 validloss: -0.29366884\n",
      "time: 4.534507989883423 Epoch: 3859 trainloss: -0.7026175 validloss: -0.29686135\n",
      "time: 4.533236265182495 Epoch: 3860 trainloss: -0.70272666 validloss: -0.29607344\n",
      "time: 4.650434494018555 Epoch: 3861 trainloss: -0.7026871 validloss: -0.2981551\n",
      "time: 4.605828762054443 Epoch: 3862 trainloss: -0.70271856 validloss: -0.29618782\n",
      "time: 4.55867075920105 Epoch: 3863 trainloss: -0.70271975 validloss: -0.29906026\n",
      "time: 4.730917453765869 Epoch: 3864 trainloss: -0.70271975 validloss: -0.29655457\n",
      "time: 4.620494604110718 Epoch: 3865 trainloss: -0.70271784 validloss: -0.2939686\n",
      "time: 4.929404258728027 Epoch: 3866 trainloss: -0.70269793 validloss: -0.30089006\n",
      "time: 5.0200982093811035 Epoch: 3867 trainloss: -0.70272547 validloss: -0.29655153\n",
      "time: 5.025155305862427 Epoch: 3868 trainloss: -0.7027544 validloss: -0.29670486\n",
      "time: 4.943375587463379 Epoch: 3869 trainloss: -0.7027928 validloss: -0.29754633\n",
      "time: 4.933520317077637 Epoch: 3870 trainloss: -0.70282227 validloss: -0.2962529\n",
      "time: 4.746422052383423 Epoch: 3871 trainloss: -0.7028282 validloss: -0.2988155\n",
      "time: 4.598691463470459 Epoch: 3872 trainloss: -0.7028516 validloss: -0.2944799\n",
      "time: 4.713162660598755 Epoch: 3873 trainloss: -0.7028324 validloss: -0.29714817\n",
      "time: 4.637620210647583 Epoch: 3874 trainloss: -0.70283484 validloss: -0.29855806\n",
      "time: 4.560478925704956 Epoch: 3875 trainloss: -0.702812 validloss: -0.2938098\n",
      "time: 4.577998876571655 Epoch: 3876 trainloss: -0.7028002 validloss: -0.3020621\n",
      "time: 4.567657232284546 Epoch: 3877 trainloss: -0.70277846 validloss: -0.29434603\n",
      "time: 4.553772926330566 Epoch: 3878 trainloss: -0.7027474 validloss: -0.29370093\n",
      "time: 4.690494060516357 Epoch: 3879 trainloss: -0.70276374 validloss: -0.2991187\n",
      "time: 4.598756551742554 Epoch: 3880 trainloss: -0.7027552 validloss: -0.29466054\n",
      "time: 4.555266380310059 Epoch: 3881 trainloss: -0.70278955 validloss: -0.2975005\n",
      "time: 4.568563938140869 Epoch: 3882 trainloss: -0.70276767 validloss: -0.29412273\n",
      "time: 4.587602138519287 Epoch: 3883 trainloss: -0.7027759 validloss: -0.29674298\n",
      "time: 4.572819471359253 Epoch: 3884 trainloss: -0.7027739 validloss: -0.2967427\n",
      "time: 4.58450722694397 Epoch: 3885 trainloss: -0.70277554 validloss: -0.2964561\n",
      "time: 4.667906284332275 Epoch: 3886 trainloss: -0.7027883 validloss: -0.29442665\n",
      "time: 4.726771354675293 Epoch: 3887 trainloss: -0.70275897 validloss: -0.30222893\n",
      "time: 4.690565824508667 Epoch: 3888 trainloss: -0.7027513 validloss: -0.29593885\n",
      "time: 4.645395755767822 Epoch: 3889 trainloss: -0.70272183 validloss: -0.29496753\n",
      "time: 4.619287967681885 Epoch: 3890 trainloss: -0.7027314 validloss: -0.29747024\n",
      "time: 4.610438108444214 Epoch: 3891 trainloss: -0.7026866 validloss: -0.29570764\n",
      "time: 4.574002981185913 Epoch: 3892 trainloss: -0.70272964 validloss: -0.2980383\n",
      "time: 4.553858757019043 Epoch: 3893 trainloss: -0.7027089 validloss: -0.2940793\n",
      "time: 4.569471597671509 Epoch: 3894 trainloss: -0.70274043 validloss: -0.29881436\n",
      "time: 4.780279636383057 Epoch: 3895 trainloss: -0.702758 validloss: -0.29507425\n",
      "time: 5.097178220748901 Epoch: 3896 trainloss: -0.70275927 validloss: -0.29260537\n",
      "time: 4.988492727279663 Epoch: 3897 trainloss: -0.7027918 validloss: -0.29764566\n",
      "time: 4.9263365268707275 Epoch: 3898 trainloss: -0.702792 validloss: -0.2941673\n",
      "time: 4.551761150360107 Epoch: 3899 trainloss: -0.7028015 validloss: -0.2972202\n",
      "time: 4.569639682769775 Epoch: 3900 trainloss: -0.7028075 validloss: -0.29581964\n",
      "time: 4.541720628738403 Epoch: 3901 trainloss: -0.7028169 validloss: -0.29592675\n",
      "time: 4.581854820251465 Epoch: 3902 trainloss: -0.7028075 validloss: -0.29772648\n",
      "time: 4.561234951019287 Epoch: 3903 trainloss: -0.7028123 validloss: -0.2956986\n",
      "time: 4.575207471847534 Epoch: 3904 trainloss: -0.7028152 validloss: -0.2950312\n",
      "time: 4.5621819496154785 Epoch: 3905 trainloss: -0.70281416 validloss: -0.29728034\n",
      "time: 4.599778652191162 Epoch: 3906 trainloss: -0.70280224 validloss: -0.2976149\n",
      "time: 4.5468902587890625 Epoch: 3907 trainloss: -0.70280063 validloss: -0.2941042\n",
      "time: 4.718984842300415 Epoch: 3908 trainloss: -0.7028033 validloss: -0.29934677\n",
      "time: 4.77238917350769 Epoch: 3909 trainloss: -0.7027934 validloss: -0.29722646\n",
      "time: 4.595501899719238 Epoch: 3910 trainloss: -0.70278937 validloss: -0.2968341\n",
      "time: 4.584395885467529 Epoch: 3911 trainloss: -0.7027628 validloss: -0.29605377\n",
      "time: 4.953474998474121 Epoch: 3912 trainloss: -0.7027679 validloss: -0.29840323\n",
      "time: 4.82838249206543 Epoch: 3913 trainloss: -0.7027817 validloss: -0.2963478\n",
      "time: 5.043392896652222 Epoch: 3914 trainloss: -0.7027439 validloss: -0.29660103\n",
      "time: 5.137921333312988 Epoch: 3915 trainloss: -0.70275587 validloss: -0.29604036\n",
      "time: 5.1390221118927 Epoch: 3916 trainloss: -0.70273346 validloss: -0.29549563\n",
      "time: 5.065707206726074 Epoch: 3917 trainloss: -0.7027637 validloss: -0.2973326\n",
      "time: 4.779957294464111 Epoch: 3918 trainloss: -0.7027471 validloss: -0.2962931\n",
      "time: 4.692246675491333 Epoch: 3919 trainloss: -0.70274395 validloss: -0.2987976\n",
      "time: 4.64032769203186 Epoch: 3920 trainloss: -0.7027752 validloss: -0.29683375\n",
      "time: 4.596233606338501 Epoch: 3921 trainloss: -0.70276904 validloss: -0.2941028\n",
      "time: 4.606990814208984 Epoch: 3922 trainloss: -0.70277196 validloss: -0.29850557\n",
      "time: 4.541170358657837 Epoch: 3923 trainloss: -0.70275384 validloss: -0.29727164\n",
      "time: 4.548451900482178 Epoch: 3924 trainloss: -0.7027679 validloss: -0.29465392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.598202466964722 Epoch: 3925 trainloss: -0.70277387 validloss: -0.29733646\n",
      "time: 4.636790752410889 Epoch: 3926 trainloss: -0.7027641 validloss: -0.30017966\n",
      "time: 4.897523880004883 Epoch: 3927 trainloss: -0.70278674 validloss: -0.29504937\n",
      "time: 4.599035263061523 Epoch: 3928 trainloss: -0.7027972 validloss: -0.29619414\n",
      "time: 4.729816436767578 Epoch: 3929 trainloss: -0.7027926 validloss: -0.29849753\n",
      "time: 4.677493333816528 Epoch: 3930 trainloss: -0.70282155 validloss: -0.2989566\n",
      "time: 4.61872410774231 Epoch: 3931 trainloss: -0.702794 validloss: -0.29506034\n",
      "time: 4.588293075561523 Epoch: 3932 trainloss: -0.70280856 validloss: -0.2935132\n",
      "time: 4.5924599170684814 Epoch: 3933 trainloss: -0.7027915 validloss: -0.29754788\n",
      "time: 4.74665904045105 Epoch: 3934 trainloss: -0.70278984 validloss: -0.29597884\n",
      "time: 4.573111295700073 Epoch: 3935 trainloss: -0.7027823 validloss: -0.29341054\n",
      "time: 4.7135655879974365 Epoch: 3936 trainloss: -0.70277923 validloss: -0.29840955\n",
      "time: 4.660010814666748 Epoch: 3937 trainloss: -0.7027856 validloss: -0.2946156\n",
      "time: 4.562854051589966 Epoch: 3938 trainloss: -0.7027274 validloss: -0.29280382\n",
      "time: 4.574437618255615 Epoch: 3939 trainloss: -0.70275956 validloss: -0.30065772\n",
      "time: 4.558588743209839 Epoch: 3940 trainloss: -0.7027552 validloss: -0.29457238\n",
      "time: 4.565422534942627 Epoch: 3941 trainloss: -0.7027512 validloss: -0.2966994\n",
      "time: 4.566607713699341 Epoch: 3942 trainloss: -0.70275754 validloss: -0.29280183\n",
      "time: 4.561380863189697 Epoch: 3943 trainloss: -0.70275086 validloss: -0.2976808\n",
      "time: 4.551969766616821 Epoch: 3944 trainloss: -0.70276654 validloss: -0.29637492\n",
      "time: 4.824463129043579 Epoch: 3945 trainloss: -0.70275027 validloss: -0.29588345\n",
      "time: 4.964437961578369 Epoch: 3946 trainloss: -0.7027763 validloss: -0.29424745\n",
      "time: 4.982230186462402 Epoch: 3947 trainloss: -0.7027515 validloss: -0.29883254\n",
      "time: 4.938234567642212 Epoch: 3948 trainloss: -0.70280766 validloss: -0.2931225\n",
      "time: 4.960573434829712 Epoch: 3949 trainloss: -0.70277995 validloss: -0.2947897\n",
      "time: 4.952692747116089 Epoch: 3950 trainloss: -0.70278955 validloss: -0.2996025\n",
      "time: 4.948386907577515 Epoch: 3951 trainloss: -0.70277923 validloss: -0.29336712\n",
      "time: 4.960303544998169 Epoch: 3952 trainloss: -0.7028051 validloss: -0.29598197\n",
      "time: 4.95863676071167 Epoch: 3953 trainloss: -0.70280147 validloss: -0.2939274\n",
      "time: 4.939192771911621 Epoch: 3954 trainloss: -0.70281345 validloss: -0.29853445\n",
      "time: 4.949982643127441 Epoch: 3955 trainloss: -0.70281607 validloss: -0.29504943\n",
      "time: 4.9967570304870605 Epoch: 3956 trainloss: -0.7028237 validloss: -0.29732493\n",
      "time: 5.256780624389648 Epoch: 3957 trainloss: -0.70281774 validloss: -0.29260457\n",
      "time: 5.3488450050354 Epoch: 3958 trainloss: -0.70281976 validloss: -0.2994176\n",
      "time: 5.31139063835144 Epoch: 3959 trainloss: -0.7028436 validloss: -0.29280096\n",
      "time: 5.2723610401153564 Epoch: 3960 trainloss: -0.7028282 validloss: -0.29622144\n",
      "time: 5.176015853881836 Epoch: 3961 trainloss: -0.7028438 validloss: -0.29368505\n",
      "time: 5.017117261886597 Epoch: 3962 trainloss: -0.70281893 validloss: -0.29644504\n",
      "time: 5.072300434112549 Epoch: 3963 trainloss: -0.7028307 validloss: -0.2962766\n",
      "time: 4.934483289718628 Epoch: 3964 trainloss: -0.7028157 validloss: -0.29513857\n",
      "time: 4.929227828979492 Epoch: 3965 trainloss: -0.7028289 validloss: -0.2940217\n",
      "time: 4.945594787597656 Epoch: 3966 trainloss: -0.70281196 validloss: -0.29404637\n",
      "time: 4.943363189697266 Epoch: 3967 trainloss: -0.7028226 validloss: -0.29422987\n",
      "time: 4.934226036071777 Epoch: 3968 trainloss: -0.702811 validloss: -0.2936443\n",
      "time: 4.971190690994263 Epoch: 3969 trainloss: -0.70282006 validloss: -0.29417056\n",
      "time: 4.952789545059204 Epoch: 3970 trainloss: -0.7028177 validloss: -0.2960586\n",
      "time: 4.930543422698975 Epoch: 3971 trainloss: -0.70281166 validloss: -0.29119864\n",
      "time: 4.933947324752808 Epoch: 3972 trainloss: -0.7028158 validloss: -0.2972039\n",
      "time: 4.934142351150513 Epoch: 3973 trainloss: -0.70282626 validloss: -0.2935938\n",
      "time: 4.912768840789795 Epoch: 3974 trainloss: -0.7028234 validloss: -0.2978247\n",
      "time: 4.9287543296813965 Epoch: 3975 trainloss: -0.702824 validloss: -0.29266864\n",
      "time: 4.9282519817352295 Epoch: 3976 trainloss: -0.70282227 validloss: -0.29443204\n",
      "time: 4.915920972824097 Epoch: 3977 trainloss: -0.70282036 validloss: -0.2948602\n",
      "time: 4.949196100234985 Epoch: 3978 trainloss: -0.7028493 validloss: -0.29822055\n",
      "time: 4.945400953292847 Epoch: 3979 trainloss: -0.70283645 validloss: -0.29094768\n",
      "time: 4.965468406677246 Epoch: 3980 trainloss: -0.7028633 validloss: -0.29686418\n",
      "time: 4.997459173202515 Epoch: 3981 trainloss: -0.702854 validloss: -0.29367933\n",
      "time: 4.9754064083099365 Epoch: 3982 trainloss: -0.7028473 validloss: -0.29694074\n",
      "time: 4.94520115852356 Epoch: 3983 trainloss: -0.7028568 validloss: -0.29274315\n",
      "time: 4.999504804611206 Epoch: 3984 trainloss: -0.7028499 validloss: -0.2946516\n",
      "time: 4.952239751815796 Epoch: 3985 trainloss: -0.70286036 validloss: -0.29388446\n",
      "time: 4.937198638916016 Epoch: 3986 trainloss: -0.70284057 validloss: -0.29517782\n",
      "time: 4.924753427505493 Epoch: 3987 trainloss: -0.7028388 validloss: -0.2924207\n",
      "time: 4.961890935897827 Epoch: 3988 trainloss: -0.70284754 validloss: -0.29852492\n",
      "time: 4.9244065284729 Epoch: 3989 trainloss: -0.7028338 validloss: -0.29111695\n",
      "time: 4.935920000076294 Epoch: 3990 trainloss: -0.7028146 validloss: -0.30011547\n",
      "time: 5.043829679489136 Epoch: 3991 trainloss: -0.7028106 validloss: -0.29222307\n",
      "time: 5.062370300292969 Epoch: 3992 trainloss: -0.70281 validloss: -0.2951901\n",
      "time: 4.982939004898071 Epoch: 3993 trainloss: -0.70281935 validloss: -0.297706\n",
      "time: 4.943775415420532 Epoch: 3994 trainloss: -0.70283616 validloss: -0.29125544\n",
      "time: 4.974703788757324 Epoch: 3995 trainloss: -0.7027954 validloss: -0.29674044\n",
      "time: 5.063344240188599 Epoch: 3996 trainloss: -0.7027491 validloss: -0.29602784\n",
      "time: 5.086780548095703 Epoch: 3997 trainloss: -0.70274514 validloss: -0.29644793\n",
      "time: 4.96560263633728 Epoch: 3998 trainloss: -0.70275134 validloss: -0.2986066\n",
      "time: 4.991780757904053 Epoch: 3999 trainloss: -0.7027903 validloss: -0.2923806\n",
      "time: 4.926504850387573 Epoch: 4000 trainloss: -0.7027886 validloss: -0.29612976\n",
      "time: 4.937953472137451 Epoch: 4001 trainloss: -0.70278126 validloss: -0.29685447\n",
      "time: 5.1874098777771 Epoch: 4002 trainloss: -0.7027679 validloss: -0.29674137\n",
      "time: 4.9792046546936035 Epoch: 4003 trainloss: -0.7027732 validloss: -0.2920966\n",
      "time: 4.903144121170044 Epoch: 4004 trainloss: -0.7027471 validloss: -0.2987914\n",
      "time: 4.9293413162231445 Epoch: 4005 trainloss: -0.7027461 validloss: -0.29465538\n",
      "time: 4.921633005142212 Epoch: 4006 trainloss: -0.7027048 validloss: -0.29249763\n",
      "time: 4.9286792278289795 Epoch: 4007 trainloss: -0.702759 validloss: -0.29693505\n",
      "time: 4.923125982284546 Epoch: 4008 trainloss: -0.7027001 validloss: -0.2989105\n",
      "time: 4.937869310379028 Epoch: 4009 trainloss: -0.70274234 validloss: -0.29542464\n",
      "time: 4.929550409317017 Epoch: 4010 trainloss: -0.70271784 validloss: -0.29444954\n",
      "time: 4.919739484786987 Epoch: 4011 trainloss: -0.70271724 validloss: -0.2997972\n",
      "time: 4.930020570755005 Epoch: 4012 trainloss: -0.7026702 validloss: -0.2973889\n",
      "time: 4.920231103897095 Epoch: 4013 trainloss: -0.7027239 validloss: -0.29553407\n",
      "time: 4.918221712112427 Epoch: 4014 trainloss: -0.7027411 validloss: -0.29633474\n",
      "time: 4.91643762588501 Epoch: 4015 trainloss: -0.7027514 validloss: -0.3005427\n",
      "time: 4.957685708999634 Epoch: 4016 trainloss: -0.7027396 validloss: -0.29406062\n",
      "time: 4.917950868606567 Epoch: 4017 trainloss: -0.702755 validloss: -0.293323\n",
      "time: 4.919450998306274 Epoch: 4018 trainloss: -0.7027315 validloss: -0.30020285\n",
      "time: 4.898168325424194 Epoch: 4019 trainloss: -0.7027294 validloss: -0.2957766\n",
      "time: 4.925820827484131 Epoch: 4020 trainloss: -0.7027882 validloss: -0.29485264\n",
      "time: 4.90852427482605 Epoch: 4021 trainloss: -0.70279783 validloss: -0.294409\n",
      "time: 4.9351091384887695 Epoch: 4022 trainloss: -0.7028059 validloss: -0.29715413\n",
      "time: 4.892466306686401 Epoch: 4023 trainloss: -0.7028113 validloss: -0.29841664\n",
      "time: 5.037633419036865 Epoch: 4024 trainloss: -0.70281076 validloss: -0.29253456\n",
      "time: 4.801955938339233 Epoch: 4025 trainloss: -0.7028327 validloss: -0.30043542\n",
      "time: 4.897568464279175 Epoch: 4026 trainloss: -0.7028483 validloss: -0.29144654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.567401170730591 Epoch: 4027 trainloss: -0.7028547 validloss: -0.29805288\n",
      "time: 4.5470380783081055 Epoch: 4028 trainloss: -0.7028618 validloss: -0.29634216\n",
      "time: 4.58613920211792 Epoch: 4029 trainloss: -0.7028791 validloss: -0.2941959\n",
      "time: 4.791996240615845 Epoch: 4030 trainloss: -0.70286214 validloss: -0.29650503\n",
      "time: 4.639502048492432 Epoch: 4031 trainloss: -0.7028695 validloss: -0.2961927\n",
      "time: 4.594185829162598 Epoch: 4032 trainloss: -0.7028646 validloss: -0.2929298\n",
      "time: 4.810317277908325 Epoch: 4033 trainloss: -0.7028555 validloss: -0.29639614\n",
      "time: 4.677631139755249 Epoch: 4034 trainloss: -0.702866 validloss: -0.2938488\n",
      "time: 4.701178073883057 Epoch: 4035 trainloss: -0.7028553 validloss: -0.29540223\n",
      "time: 4.723346948623657 Epoch: 4036 trainloss: -0.70285106 validloss: -0.29350883\n",
      "time: 4.732962608337402 Epoch: 4037 trainloss: -0.7028671 validloss: -0.29833093\n",
      "time: 4.582256555557251 Epoch: 4038 trainloss: -0.7028483 validloss: -0.2935392\n",
      "time: 4.78753137588501 Epoch: 4039 trainloss: -0.70285076 validloss: -0.29535845\n",
      "time: 4.629803895950317 Epoch: 4040 trainloss: -0.702866 validloss: -0.29455906\n",
      "time: 4.846259117126465 Epoch: 4041 trainloss: -0.70283055 validloss: -0.2975906\n",
      "time: 4.544607639312744 Epoch: 4042 trainloss: -0.7028432 validloss: -0.295848\n",
      "time: 4.921533584594727 Epoch: 4043 trainloss: -0.7028391 validloss: -0.29164803\n",
      "time: 4.767414808273315 Epoch: 4044 trainloss: -0.7028645 validloss: -0.29804108\n",
      "time: 4.553816795349121 Epoch: 4045 trainloss: -0.70284456 validloss: -0.29595008\n",
      "time: 4.667069673538208 Epoch: 4046 trainloss: -0.7028673 validloss: -0.2949958\n",
      "time: 4.774374723434448 Epoch: 4047 trainloss: -0.7028361 validloss: -0.29513833\n",
      "time: 4.788590908050537 Epoch: 4048 trainloss: -0.7028396 validloss: -0.29623663\n",
      "time: 4.563074827194214 Epoch: 4049 trainloss: -0.7028348 validloss: -0.29429674\n",
      "time: 4.5787436962127686 Epoch: 4050 trainloss: -0.70283335 validloss: -0.29778233\n",
      "time: 4.558959484100342 Epoch: 4051 trainloss: -0.7028447 validloss: -0.29129595\n",
      "time: 4.569791316986084 Epoch: 4052 trainloss: -0.7028442 validloss: -0.29846004\n",
      "time: 4.6334922313690186 Epoch: 4053 trainloss: -0.70284545 validloss: -0.2934459\n",
      "time: 4.970911502838135 Epoch: 4054 trainloss: -0.702834 validloss: -0.29368463\n",
      "time: 4.566376209259033 Epoch: 4055 trainloss: -0.70284724 validloss: -0.29757163\n",
      "time: 4.562690734863281 Epoch: 4056 trainloss: -0.70283145 validloss: -0.29086897\n",
      "time: 4.565812826156616 Epoch: 4057 trainloss: -0.70282835 validloss: -0.29956055\n",
      "time: 4.707848072052002 Epoch: 4058 trainloss: -0.7028133 validloss: -0.2937435\n",
      "time: 4.6830291748046875 Epoch: 4059 trainloss: -0.70283175 validloss: -0.29495126\n",
      "time: 4.853433132171631 Epoch: 4060 trainloss: -0.702819 validloss: -0.29424646\n",
      "time: 4.773592948913574 Epoch: 4061 trainloss: -0.7028143 validloss: -0.2960332\n",
      "time: 4.960340261459351 Epoch: 4062 trainloss: -0.70279586 validloss: -0.29660136\n",
      "time: 4.918600082397461 Epoch: 4063 trainloss: -0.70280635 validloss: -0.295121\n",
      "time: 4.794761419296265 Epoch: 4064 trainloss: -0.702803 validloss: -0.29765278\n",
      "time: 4.774246454238892 Epoch: 4065 trainloss: -0.70283 validloss: -0.2906185\n",
      "time: 4.647416114807129 Epoch: 4066 trainloss: -0.7028098 validloss: -0.29852295\n",
      "time: 4.618328332901001 Epoch: 4067 trainloss: -0.70283014 validloss: -0.2935899\n",
      "time: 4.710772752761841 Epoch: 4068 trainloss: -0.70281386 validloss: -0.2926318\n",
      "time: 4.549098014831543 Epoch: 4069 trainloss: -0.70284945 validloss: -0.2978558\n",
      "time: 4.5150909423828125 Epoch: 4070 trainloss: -0.7028554 validloss: -0.2905266\n",
      "time: 4.532530069351196 Epoch: 4071 trainloss: -0.702827 validloss: -0.30046204\n",
      "time: 4.730092287063599 Epoch: 4072 trainloss: -0.7028357 validloss: -0.29278833\n",
      "time: 4.915183067321777 Epoch: 4073 trainloss: -0.7028298 validloss: -0.2959605\n",
      "time: 5.054948806762695 Epoch: 4074 trainloss: -0.70285213 validloss: -0.2952898\n",
      "time: 4.948652505874634 Epoch: 4075 trainloss: -0.7028471 validloss: -0.29403847\n",
      "time: 4.93764853477478 Epoch: 4076 trainloss: -0.70282614 validloss: -0.2981853\n",
      "time: 4.9564080238342285 Epoch: 4077 trainloss: -0.7028114 validloss: -0.29530618\n",
      "time: 4.985990285873413 Epoch: 4078 trainloss: -0.7028008 validloss: -0.29505977\n",
      "time: 4.990406274795532 Epoch: 4079 trainloss: -0.70279133 validloss: -0.2957399\n",
      "time: 4.95997166633606 Epoch: 4080 trainloss: -0.70281655 validloss: -0.29464576\n",
      "time: 4.947767496109009 Epoch: 4081 trainloss: -0.7028201 validloss: -0.29614514\n",
      "time: 4.604671239852905 Epoch: 4082 trainloss: -0.7028441 validloss: -0.29531804\n",
      "time: 4.594738483428955 Epoch: 4083 trainloss: -0.7028712 validloss: -0.29646128\n",
      "time: 4.557394504547119 Epoch: 4084 trainloss: -0.7028981 validloss: -0.29506838\n",
      "time: 4.532148838043213 Epoch: 4085 trainloss: -0.7028901 validloss: -0.2971803\n",
      "time: 4.606380224227905 Epoch: 4086 trainloss: -0.70289034 validloss: -0.2940638\n",
      "time: 4.645675420761108 Epoch: 4087 trainloss: -0.7028731 validloss: -0.29342976\n",
      "time: 4.761624813079834 Epoch: 4088 trainloss: -0.7028684 validloss: -0.29916194\n",
      "time: 4.896785497665405 Epoch: 4089 trainloss: -0.70284855 validloss: -0.29113176\n",
      "time: 5.115052700042725 Epoch: 4090 trainloss: -0.7028626 validloss: -0.29740083\n",
      "time: 4.7848429679870605 Epoch: 4091 trainloss: -0.70285577 validloss: -0.29356408\n",
      "time: 4.725980520248413 Epoch: 4092 trainloss: -0.70287937 validloss: -0.29397655\n",
      "time: 4.64825439453125 Epoch: 4093 trainloss: -0.7028765 validloss: -0.2958969\n",
      "time: 4.592910051345825 Epoch: 4094 trainloss: -0.70287305 validloss: -0.29526904\n",
      "time: 4.6629250049591064 Epoch: 4095 trainloss: -0.7028634 validloss: -0.29231262\n",
      "time: 4.874789476394653 Epoch: 4096 trainloss: -0.70286304 validloss: -0.29383793\n",
      "time: 4.806835651397705 Epoch: 4097 trainloss: -0.70284706 validloss: -0.2940716\n",
      "time: 4.772263765335083 Epoch: 4098 trainloss: -0.7028352 validloss: -0.2946187\n",
      "time: 4.649619102478027 Epoch: 4099 trainloss: -0.702827 validloss: -0.2926385\n",
      "time: 4.784700155258179 Epoch: 4100 trainloss: -0.7028225 validloss: -0.2956127\n",
      "time: 4.933653831481934 Epoch: 4101 trainloss: -0.7028102 validloss: -0.2968743\n",
      "time: 5.031397819519043 Epoch: 4102 trainloss: -0.7028378 validloss: -0.29694024\n",
      "time: 4.9707558155059814 Epoch: 4103 trainloss: -0.7028547 validloss: -0.29446104\n",
      "time: 4.8797736167907715 Epoch: 4104 trainloss: -0.7028663 validloss: -0.29703087\n",
      "time: 4.989912748336792 Epoch: 4105 trainloss: -0.7028536 validloss: -0.29384783\n",
      "time: 4.98234748840332 Epoch: 4106 trainloss: -0.7028351 validloss: -0.29620498\n",
      "time: 4.998739957809448 Epoch: 4107 trainloss: -0.70286334 validloss: -0.29613802\n",
      "time: 4.990275144577026 Epoch: 4108 trainloss: -0.7028564 validloss: -0.29952997\n",
      "time: 4.982003927230835 Epoch: 4109 trainloss: -0.7028598 validloss: -0.29253122\n",
      "time: 5.261089563369751 Epoch: 4110 trainloss: -0.7028581 validloss: -0.29656103\n",
      "time: 5.287271022796631 Epoch: 4111 trainloss: -0.7028542 validloss: -0.29880497\n",
      "time: 5.159982919692993 Epoch: 4112 trainloss: -0.7028679 validloss: -0.29599726\n",
      "time: 5.041050910949707 Epoch: 4113 trainloss: -0.70287335 validloss: -0.2940238\n",
      "time: 5.078809022903442 Epoch: 4114 trainloss: -0.70289177 validloss: -0.29509103\n",
      "time: 4.97402811050415 Epoch: 4115 trainloss: -0.7028842 validloss: -0.29823536\n",
      "time: 4.984050512313843 Epoch: 4116 trainloss: -0.7028579 validloss: -0.29289192\n",
      "time: 5.000871896743774 Epoch: 4117 trainloss: -0.70285046 validloss: -0.29910806\n",
      "time: 4.993683338165283 Epoch: 4118 trainloss: -0.70285124 validloss: -0.29582748\n",
      "time: 5.0031232833862305 Epoch: 4119 trainloss: -0.702873 validloss: -0.29256138\n",
      "time: 5.0336103439331055 Epoch: 4120 trainloss: -0.7028704 validloss: -0.2962674\n",
      "time: 5.024593114852905 Epoch: 4121 trainloss: -0.7028538 validloss: -0.2929408\n",
      "time: 5.028606176376343 Epoch: 4122 trainloss: -0.70286834 validloss: -0.29568943\n",
      "time: 5.0085368156433105 Epoch: 4123 trainloss: -0.70286536 validloss: -0.29443312\n",
      "time: 5.003878593444824 Epoch: 4124 trainloss: -0.70285577 validloss: -0.2968779\n",
      "time: 5.006227970123291 Epoch: 4125 trainloss: -0.70284575 validloss: -0.29566297\n",
      "time: 4.996160268783569 Epoch: 4126 trainloss: -0.70285434 validloss: -0.2966736\n",
      "time: 4.994030475616455 Epoch: 4127 trainloss: -0.7028476 validloss: -0.29716098\n",
      "time: 5.0081634521484375 Epoch: 4128 trainloss: -0.7028433 validloss: -0.29803336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.024303197860718 Epoch: 4129 trainloss: -0.70282805 validloss: -0.29403266\n",
      "time: 5.018199682235718 Epoch: 4130 trainloss: -0.702799 validloss: -0.29563227\n",
      "time: 5.045658588409424 Epoch: 4131 trainloss: -0.70282644 validloss: -0.29638267\n",
      "time: 5.038750648498535 Epoch: 4132 trainloss: -0.70281416 validloss: -0.29685867\n",
      "time: 5.054669141769409 Epoch: 4133 trainloss: -0.70279866 validloss: -0.29479071\n",
      "time: 4.803349733352661 Epoch: 4134 trainloss: -0.7028192 validloss: -0.29582167\n",
      "time: 4.54889702796936 Epoch: 4135 trainloss: -0.70276934 validloss: -0.29563075\n",
      "time: 4.610854148864746 Epoch: 4136 trainloss: -0.70280206 validloss: -0.2966818\n",
      "time: 4.556324481964111 Epoch: 4137 trainloss: -0.7027936 validloss: -0.29872033\n",
      "time: 4.579292058944702 Epoch: 4138 trainloss: -0.7027978 validloss: -0.29258302\n",
      "time: 4.826550006866455 Epoch: 4139 trainloss: -0.7028157 validloss: -0.2996202\n",
      "time: 4.542878150939941 Epoch: 4140 trainloss: -0.70279104 validloss: -0.2947215\n",
      "time: 4.5387725830078125 Epoch: 4141 trainloss: -0.70282507 validloss: -0.29760388\n",
      "time: 4.595022916793823 Epoch: 4142 trainloss: -0.7028199 validloss: -0.29693237\n",
      "time: 4.683761835098267 Epoch: 4143 trainloss: -0.7028082 validloss: -0.29432803\n",
      "time: 5.274920463562012 Epoch: 4144 trainloss: -0.7028384 validloss: -0.29678676\n",
      "time: 5.043065309524536 Epoch: 4145 trainloss: -0.7028229 validloss: -0.29768696\n",
      "time: 5.017689228057861 Epoch: 4146 trainloss: -0.70286715 validloss: -0.29256797\n",
      "time: 4.83944296836853 Epoch: 4147 trainloss: -0.7028576 validloss: -0.2977792\n",
      "time: 4.754361629486084 Epoch: 4148 trainloss: -0.70287836 validloss: -0.2992827\n",
      "time: 4.967539548873901 Epoch: 4149 trainloss: -0.7028889 validloss: -0.2945457\n",
      "time: 4.5954015254974365 Epoch: 4150 trainloss: -0.70288044 validloss: -0.2951632\n",
      "time: 4.901494026184082 Epoch: 4151 trainloss: -0.7028641 validloss: -0.2951674\n",
      "time: 4.90304708480835 Epoch: 4152 trainloss: -0.7028651 validloss: -0.29800075\n",
      "time: 4.838212490081787 Epoch: 4153 trainloss: -0.70285565 validloss: -0.29827178\n",
      "time: 4.664061069488525 Epoch: 4154 trainloss: -0.70287645 validloss: -0.29483306\n",
      "time: 4.541653394699097 Epoch: 4155 trainloss: -0.70287234 validloss: -0.29916492\n",
      "time: 4.614203214645386 Epoch: 4156 trainloss: -0.70285875 validloss: -0.29628512\n",
      "time: 4.817997694015503 Epoch: 4157 trainloss: -0.70288414 validloss: -0.2963037\n",
      "time: 4.70815634727478 Epoch: 4158 trainloss: -0.702869 validloss: -0.29569384\n",
      "time: 4.807551383972168 Epoch: 4159 trainloss: -0.70287496 validloss: -0.29374555\n",
      "time: 5.077948093414307 Epoch: 4160 trainloss: -0.70287454 validloss: -0.29642892\n",
      "time: 4.646632432937622 Epoch: 4161 trainloss: -0.70286214 validloss: -0.29514375\n",
      "time: 4.53265380859375 Epoch: 4162 trainloss: -0.7028553 validloss: -0.29826608\n",
      "time: 4.52276349067688 Epoch: 4163 trainloss: -0.7028455 validloss: -0.29308957\n",
      "time: 4.5364158153533936 Epoch: 4164 trainloss: -0.7028342 validloss: -0.2968795\n",
      "time: 4.606988906860352 Epoch: 4165 trainloss: -0.7028326 validloss: -0.29794428\n",
      "time: 4.5661070346832275 Epoch: 4166 trainloss: -0.70283353 validloss: -0.29376313\n",
      "time: 4.543419361114502 Epoch: 4167 trainloss: -0.7028084 validloss: -0.29685506\n",
      "time: 4.523953676223755 Epoch: 4168 trainloss: -0.7028126 validloss: -0.2959586\n",
      "time: 4.539773941040039 Epoch: 4169 trainloss: -0.70276374 validloss: -0.29474652\n",
      "time: 4.528017997741699 Epoch: 4170 trainloss: -0.7027853 validloss: -0.2943413\n",
      "time: 4.54425048828125 Epoch: 4171 trainloss: -0.70279026 validloss: -0.29536465\n",
      "time: 4.549938201904297 Epoch: 4172 trainloss: -0.70279896 validloss: -0.29961932\n",
      "time: 4.555562496185303 Epoch: 4173 trainloss: -0.7028187 validloss: -0.2941473\n",
      "time: 4.5443432331085205 Epoch: 4174 trainloss: -0.70280087 validloss: -0.29842877\n",
      "time: 4.567221641540527 Epoch: 4175 trainloss: -0.70282 validloss: -0.2965979\n",
      "time: 4.522207260131836 Epoch: 4176 trainloss: -0.70278966 validloss: -0.29659057\n",
      "time: 4.5309412479400635 Epoch: 4177 trainloss: -0.70281273 validloss: -0.2958619\n",
      "time: 4.5469701290130615 Epoch: 4178 trainloss: -0.70282155 validloss: -0.2971555\n",
      "time: 4.60906982421875 Epoch: 4179 trainloss: -0.7028323 validloss: -0.29340628\n",
      "time: 4.551541566848755 Epoch: 4180 trainloss: -0.7028366 validloss: -0.29665002\n",
      "time: 4.5393126010894775 Epoch: 4181 trainloss: -0.7028489 validloss: -0.29672775\n",
      "time: 4.559475660324097 Epoch: 4182 trainloss: -0.7028758 validloss: -0.29780388\n",
      "time: 4.705252408981323 Epoch: 4183 trainloss: -0.7028488 validloss: -0.2954934\n",
      "time: 4.791664361953735 Epoch: 4184 trainloss: -0.7028614 validloss: -0.29815668\n",
      "time: 4.6299896240234375 Epoch: 4185 trainloss: -0.7028492 validloss: -0.2917355\n",
      "time: 4.6873931884765625 Epoch: 4186 trainloss: -0.7028528 validloss: -0.2963869\n",
      "time: 4.525789499282837 Epoch: 4187 trainloss: -0.7028641 validloss: -0.29620278\n",
      "time: 4.544728755950928 Epoch: 4188 trainloss: -0.70284986 validloss: -0.29660463\n",
      "time: 4.8408801555633545 Epoch: 4189 trainloss: -0.7028685 validloss: -0.29817575\n",
      "time: 4.638684034347534 Epoch: 4190 trainloss: -0.702844 validloss: -0.29793513\n",
      "time: 4.7258830070495605 Epoch: 4191 trainloss: -0.70286775 validloss: -0.29710534\n",
      "time: 4.629267692565918 Epoch: 4192 trainloss: -0.7028373 validloss: -0.29569325\n",
      "time: 4.57526969909668 Epoch: 4193 trainloss: -0.7028351 validloss: -0.29879233\n",
      "time: 4.742296934127808 Epoch: 4194 trainloss: -0.70284754 validloss: -0.29397714\n",
      "time: 4.795435428619385 Epoch: 4195 trainloss: -0.7028533 validloss: -0.29630363\n",
      "time: 4.933111190795898 Epoch: 4196 trainloss: -0.7028616 validloss: -0.29863322\n",
      "time: 4.841468334197998 Epoch: 4197 trainloss: -0.7028358 validloss: -0.2972856\n",
      "time: 4.624226093292236 Epoch: 4198 trainloss: -0.70283234 validloss: -0.29668406\n",
      "time: 4.550376653671265 Epoch: 4199 trainloss: -0.702813 validloss: -0.297748\n",
      "time: 4.569096326828003 Epoch: 4200 trainloss: -0.7027541 validloss: -0.2959342\n",
      "time: 4.637778997421265 Epoch: 4201 trainloss: -0.70274186 validloss: -0.2996055\n",
      "time: 4.645406723022461 Epoch: 4202 trainloss: -0.7027017 validloss: -0.29078412\n",
      "time: 4.559305906295776 Epoch: 4203 trainloss: -0.7027509 validloss: -0.3025328\n",
      "time: 5.011693954467773 Epoch: 4204 trainloss: -0.7027052 validloss: -0.29844818\n",
      "time: 5.080962419509888 Epoch: 4205 trainloss: -0.7027308 validloss: -0.29661217\n",
      "time: 4.534235954284668 Epoch: 4206 trainloss: -0.7027447 validloss: -0.29578006\n",
      "time: 4.543461799621582 Epoch: 4207 trainloss: -0.7027551 validloss: -0.29874194\n",
      "time: 4.554648399353027 Epoch: 4208 trainloss: -0.7027691 validloss: -0.29819098\n",
      "time: 4.641066074371338 Epoch: 4209 trainloss: -0.70277584 validloss: -0.29166183\n",
      "time: 4.596430778503418 Epoch: 4210 trainloss: -0.7028138 validloss: -0.2972986\n",
      "time: 4.600327014923096 Epoch: 4211 trainloss: -0.7027802 validloss: -0.29801148\n",
      "time: 4.682720184326172 Epoch: 4212 trainloss: -0.70280105 validloss: -0.29424787\n",
      "time: 4.642103433609009 Epoch: 4213 trainloss: -0.7027931 validloss: -0.29656303\n",
      "time: 4.618353843688965 Epoch: 4214 trainloss: -0.7027876 validloss: -0.29429483\n",
      "time: 4.77670955657959 Epoch: 4215 trainloss: -0.7027566 validloss: -0.29866225\n",
      "time: 4.841101408004761 Epoch: 4216 trainloss: -0.7027881 validloss: -0.29541978\n",
      "time: 5.052802085876465 Epoch: 4217 trainloss: -0.70275617 validloss: -0.2906114\n",
      "time: 4.808535099029541 Epoch: 4218 trainloss: -0.7027745 validloss: -0.3035112\n",
      "time: 4.835747480392456 Epoch: 4219 trainloss: -0.70274734 validloss: -0.29175112\n",
      "time: 5.061627388000488 Epoch: 4220 trainloss: -0.7027471 validloss: -0.29975566\n",
      "time: 5.0213963985443115 Epoch: 4221 trainloss: -0.7027537 validloss: -0.29133728\n",
      "time: 5.044433832168579 Epoch: 4222 trainloss: -0.70279485 validloss: -0.3006712\n",
      "time: 5.1333091259002686 Epoch: 4223 trainloss: -0.7028037 validloss: -0.29551172\n",
      "time: 5.1241114139556885 Epoch: 4224 trainloss: -0.70282453 validloss: -0.29496777\n",
      "time: 5.2889416217803955 Epoch: 4225 trainloss: -0.702829 validloss: -0.2955011\n",
      "time: 5.0360941886901855 Epoch: 4226 trainloss: -0.70284164 validloss: -0.29817438\n",
      "time: 4.987435340881348 Epoch: 4227 trainloss: -0.70285726 validloss: -0.29801005\n",
      "time: 4.992746353149414 Epoch: 4228 trainloss: -0.70285803 validloss: -0.29533127\n",
      "time: 5.046688079833984 Epoch: 4229 trainloss: -0.70287955 validloss: -0.29657736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.973759889602661 Epoch: 4230 trainloss: -0.7028602 validloss: -0.2951471\n",
      "time: 5.063905477523804 Epoch: 4231 trainloss: -0.70287067 validloss: -0.2999481\n",
      "time: 5.3801515102386475 Epoch: 4232 trainloss: -0.7028231 validloss: -0.29573396\n",
      "time: 5.190079212188721 Epoch: 4233 trainloss: -0.7028346 validloss: -0.29677188\n",
      "time: 5.174991846084595 Epoch: 4234 trainloss: -0.7027848 validloss: -0.29634625\n",
      "time: 5.1413984298706055 Epoch: 4235 trainloss: -0.7028253 validloss: -0.296741\n",
      "time: 5.247278690338135 Epoch: 4236 trainloss: -0.70279723 validloss: -0.2923187\n",
      "time: 5.294816255569458 Epoch: 4237 trainloss: -0.7028235 validloss: -0.29774567\n",
      "time: 5.17287015914917 Epoch: 4238 trainloss: -0.7028178 validloss: -0.29472896\n",
      "time: 5.105311870574951 Epoch: 4239 trainloss: -0.7028341 validloss: -0.297018\n",
      "time: 5.04924750328064 Epoch: 4240 trainloss: -0.7028373 validloss: -0.29615876\n",
      "time: 5.104450941085815 Epoch: 4241 trainloss: -0.70282197 validloss: -0.29339916\n",
      "time: 4.992647647857666 Epoch: 4242 trainloss: -0.7028631 validloss: -0.30002195\n",
      "time: 4.998510837554932 Epoch: 4243 trainloss: -0.70286316 validloss: -0.2934736\n",
      "time: 4.965573310852051 Epoch: 4244 trainloss: -0.702879 validloss: -0.2977407\n",
      "time: 4.9836907386779785 Epoch: 4245 trainloss: -0.7028702 validloss: -0.29541677\n",
      "time: 5.008862257003784 Epoch: 4246 trainloss: -0.7028882 validloss: -0.29408434\n",
      "time: 5.027429819107056 Epoch: 4247 trainloss: -0.70290464 validloss: -0.29719657\n",
      "time: 5.039194822311401 Epoch: 4248 trainloss: -0.70290864 validloss: -0.29184446\n",
      "time: 4.997157335281372 Epoch: 4249 trainloss: -0.7029202 validloss: -0.2974919\n",
      "time: 4.986462116241455 Epoch: 4250 trainloss: -0.70290065 validloss: -0.29652378\n",
      "time: 5.031834840774536 Epoch: 4251 trainloss: -0.70289016 validloss: -0.29419795\n",
      "time: 4.988857984542847 Epoch: 4252 trainloss: -0.7028934 validloss: -0.29580346\n",
      "time: 5.029887676239014 Epoch: 4253 trainloss: -0.70286953 validloss: -0.2957836\n",
      "time: 4.997473478317261 Epoch: 4254 trainloss: -0.7028892 validloss: -0.294957\n",
      "time: 5.008219957351685 Epoch: 4255 trainloss: -0.7028827 validloss: -0.2965836\n",
      "time: 5.006685018539429 Epoch: 4256 trainloss: -0.70286965 validloss: -0.2973746\n",
      "time: 5.111857175827026 Epoch: 4257 trainloss: -0.7028625 validloss: -0.29478455\n",
      "time: 5.061113357543945 Epoch: 4258 trainloss: -0.7028603 validloss: -0.2947091\n",
      "time: 4.96626091003418 Epoch: 4259 trainloss: -0.702893 validloss: -0.293166\n",
      "time: 4.990616083145142 Epoch: 4260 trainloss: -0.70287734 validloss: -0.29926276\n",
      "time: 4.983003377914429 Epoch: 4261 trainloss: -0.702909 validloss: -0.29345787\n",
      "time: 5.005161285400391 Epoch: 4262 trainloss: -0.7028936 validloss: -0.29541755\n",
      "time: 5.138357162475586 Epoch: 4263 trainloss: -0.70291245 validloss: -0.3008896\n",
      "time: 5.154806852340698 Epoch: 4264 trainloss: -0.70290595 validloss: -0.29427415\n",
      "time: 5.0041749477386475 Epoch: 4265 trainloss: -0.702915 validloss: -0.29565078\n",
      "time: 5.067564249038696 Epoch: 4266 trainloss: -0.7029111 validloss: -0.29629976\n",
      "time: 4.988538503646851 Epoch: 4267 trainloss: -0.70291317 validloss: -0.29326686\n",
      "time: 4.979741811752319 Epoch: 4268 trainloss: -0.7029175 validloss: -0.29956925\n",
      "time: 5.068082809448242 Epoch: 4269 trainloss: -0.7029198 validloss: -0.29413804\n",
      "time: 5.123568058013916 Epoch: 4270 trainloss: -0.70293355 validloss: -0.29657924\n",
      "time: 5.017932415008545 Epoch: 4271 trainloss: -0.702932 validloss: -0.29501528\n",
      "time: 4.994518041610718 Epoch: 4272 trainloss: -0.70293206 validloss: -0.29615274\n",
      "time: 5.028110980987549 Epoch: 4273 trainloss: -0.7029376 validloss: -0.29448736\n",
      "time: 5.0040671825408936 Epoch: 4274 trainloss: -0.7029363 validloss: -0.2950098\n",
      "time: 5.006232738494873 Epoch: 4275 trainloss: -0.70294034 validloss: -0.29485604\n",
      "time: 5.0379109382629395 Epoch: 4276 trainloss: -0.7029252 validloss: -0.2964699\n",
      "time: 5.00915789604187 Epoch: 4277 trainloss: -0.7029238 validloss: -0.29655603\n",
      "time: 5.0056867599487305 Epoch: 4278 trainloss: -0.70291245 validloss: -0.29591373\n",
      "time: 4.964013338088989 Epoch: 4279 trainloss: -0.7029254 validloss: -0.29821658\n",
      "time: 5.018532991409302 Epoch: 4280 trainloss: -0.70290893 validloss: -0.29411453\n",
      "time: 4.995868921279907 Epoch: 4281 trainloss: -0.702927 validloss: -0.29665273\n",
      "time: 5.018927812576294 Epoch: 4282 trainloss: -0.7029213 validloss: -0.29503572\n",
      "time: 4.994468450546265 Epoch: 4283 trainloss: -0.7029262 validloss: -0.29774934\n",
      "time: 5.00830340385437 Epoch: 4284 trainloss: -0.70292765 validloss: -0.2959419\n",
      "time: 5.025774002075195 Epoch: 4285 trainloss: -0.70292145 validloss: -0.29641214\n",
      "time: 5.048783302307129 Epoch: 4286 trainloss: -0.70291483 validloss: -0.2958641\n",
      "time: 4.961367130279541 Epoch: 4287 trainloss: -0.70292884 validloss: -0.29534763\n",
      "time: 4.94431734085083 Epoch: 4288 trainloss: -0.7029025 validloss: -0.29562238\n",
      "time: 4.9414918422698975 Epoch: 4289 trainloss: -0.7028879 validloss: -0.294248\n",
      "time: 4.965980529785156 Epoch: 4290 trainloss: -0.7028364 validloss: -0.29586485\n",
      "time: 4.959068775177002 Epoch: 4291 trainloss: -0.70284295 validloss: -0.29587686\n",
      "time: 4.931232452392578 Epoch: 4292 trainloss: -0.7028059 validloss: -0.2956808\n",
      "time: 4.95708966255188 Epoch: 4293 trainloss: -0.7028384 validloss: -0.2978736\n",
      "time: 4.9474852085113525 Epoch: 4294 trainloss: -0.7027977 validloss: -0.29787534\n",
      "time: 4.947125434875488 Epoch: 4295 trainloss: -0.7028234 validloss: -0.29679322\n",
      "time: 4.97472071647644 Epoch: 4296 trainloss: -0.7027807 validloss: -0.2935061\n",
      "time: 4.93998384475708 Epoch: 4297 trainloss: -0.70280755 validloss: -0.2989577\n",
      "time: 4.933626174926758 Epoch: 4298 trainloss: -0.70278627 validloss: -0.29578933\n",
      "time: 4.933673143386841 Epoch: 4299 trainloss: -0.7028012 validloss: -0.2934433\n",
      "time: 4.947198867797852 Epoch: 4300 trainloss: -0.70278245 validloss: -0.2959409\n",
      "time: 4.94894003868103 Epoch: 4301 trainloss: -0.70274466 validloss: -0.29808682\n",
      "time: 4.986660480499268 Epoch: 4302 trainloss: -0.70276093 validloss: -0.2982222\n",
      "time: 4.946477890014648 Epoch: 4303 trainloss: -0.7027151 validloss: -0.29427683\n",
      "time: 4.957134485244751 Epoch: 4304 trainloss: -0.70273983 validloss: -0.2947634\n",
      "time: 4.946910381317139 Epoch: 4305 trainloss: -0.7026532 validloss: -0.30042192\n",
      "time: 4.992836236953735 Epoch: 4306 trainloss: -0.7027005 validloss: -0.29823303\n",
      "time: 4.938555002212524 Epoch: 4307 trainloss: -0.70267653 validloss: -0.2977659\n",
      "time: 4.949702501296997 Epoch: 4308 trainloss: -0.70269704 validloss: -0.29655564\n",
      "time: 4.943693161010742 Epoch: 4309 trainloss: -0.7026889 validloss: -0.29484224\n",
      "time: 4.939712047576904 Epoch: 4310 trainloss: -0.7027351 validloss: -0.29534298\n",
      "time: 4.956104516983032 Epoch: 4311 trainloss: -0.70274806 validloss: -0.29369962\n",
      "time: 4.93607497215271 Epoch: 4312 trainloss: -0.70275104 validloss: -0.3029929\n",
      "time: 4.97031044960022 Epoch: 4313 trainloss: -0.70277876 validloss: -0.29481527\n",
      "time: 4.956148386001587 Epoch: 4314 trainloss: -0.7027471 validloss: -0.29794705\n",
      "time: 4.961575269699097 Epoch: 4315 trainloss: -0.7027845 validloss: -0.2937984\n",
      "time: 4.955822944641113 Epoch: 4316 trainloss: -0.70274717 validloss: -0.3031455\n",
      "time: 4.969462156295776 Epoch: 4317 trainloss: -0.7027509 validloss: -0.29500297\n",
      "time: 4.947216987609863 Epoch: 4318 trainloss: -0.70274615 validloss: -0.29877183\n",
      "time: 4.96189284324646 Epoch: 4319 trainloss: -0.702766 validloss: -0.294451\n",
      "time: 4.981879949569702 Epoch: 4320 trainloss: -0.7027356 validloss: -0.29920942\n",
      "time: 4.957594394683838 Epoch: 4321 trainloss: -0.70276755 validloss: -0.2973165\n",
      "time: 4.921071529388428 Epoch: 4322 trainloss: -0.70279366 validloss: -0.29639643\n",
      "time: 4.954188346862793 Epoch: 4323 trainloss: -0.70282406 validloss: -0.2983006\n",
      "time: 4.960420846939087 Epoch: 4324 trainloss: -0.7028324 validloss: -0.2990429\n",
      "time: 4.950097322463989 Epoch: 4325 trainloss: -0.7028023 validloss: -0.2927288\n",
      "time: 4.954875946044922 Epoch: 4326 trainloss: -0.7028228 validloss: -0.29818866\n",
      "time: 4.9163923263549805 Epoch: 4327 trainloss: -0.7028288 validloss: -0.29997957\n",
      "time: 4.911136627197266 Epoch: 4328 trainloss: -0.7028266 validloss: -0.29380634\n",
      "time: 4.946607351303101 Epoch: 4329 trainloss: -0.70285696 validloss: -0.29543868\n",
      "time: 4.9471800327301025 Epoch: 4330 trainloss: -0.7028462 validloss: -0.30105343\n",
      "time: 4.963948965072632 Epoch: 4331 trainloss: -0.7028487 validloss: -0.29683656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.967143774032593 Epoch: 4332 trainloss: -0.7028338 validloss: -0.29837966\n",
      "time: 4.959902048110962 Epoch: 4333 trainloss: -0.70285696 validloss: -0.29463506\n",
      "time: 4.954374551773071 Epoch: 4334 trainloss: -0.70282 validloss: -0.3024155\n",
      "time: 4.963475704193115 Epoch: 4335 trainloss: -0.7028231 validloss: -0.29504374\n",
      "time: 4.949814081192017 Epoch: 4336 trainloss: -0.70281047 validloss: -0.2949319\n",
      "time: 4.975512742996216 Epoch: 4337 trainloss: -0.70276856 validloss: -0.29962984\n",
      "time: 4.9783711433410645 Epoch: 4338 trainloss: -0.70278394 validloss: -0.29716292\n",
      "time: 4.985558271408081 Epoch: 4339 trainloss: -0.7027716 validloss: -0.2948166\n",
      "time: 4.999337196350098 Epoch: 4340 trainloss: -0.70279735 validloss: -0.3022391\n",
      "time: 4.986672639846802 Epoch: 4341 trainloss: -0.70277566 validloss: -0.2920725\n",
      "time: 5.008796215057373 Epoch: 4342 trainloss: -0.7027647 validloss: -0.30045927\n",
      "time: 4.986859321594238 Epoch: 4343 trainloss: -0.7027447 validloss: -0.29562923\n",
      "time: 5.0089640617370605 Epoch: 4344 trainloss: -0.70269567 validloss: -0.2974899\n",
      "time: 4.996477127075195 Epoch: 4345 trainloss: -0.7027452 validloss: -0.3006655\n",
      "time: 4.994097709655762 Epoch: 4346 trainloss: -0.7027006 validloss: -0.29281524\n",
      "time: 4.994730472564697 Epoch: 4347 trainloss: -0.7027451 validloss: -0.2943726\n",
      "time: 4.986255645751953 Epoch: 4348 trainloss: -0.7027182 validloss: -0.30172622\n",
      "time: 4.9874444007873535 Epoch: 4349 trainloss: -0.702716 validloss: -0.29344738\n",
      "time: 4.981788158416748 Epoch: 4350 trainloss: -0.7027665 validloss: -0.2984659\n",
      "time: 4.9939916133880615 Epoch: 4351 trainloss: -0.7027261 validloss: -0.29915595\n",
      "time: 4.98810887336731 Epoch: 4352 trainloss: -0.7027657 validloss: -0.2964868\n",
      "time: 5.009319305419922 Epoch: 4353 trainloss: -0.7027701 validloss: -0.29912463\n",
      "time: 4.9885029792785645 Epoch: 4354 trainloss: -0.70279896 validloss: -0.29558197\n",
      "time: 5.013723611831665 Epoch: 4355 trainloss: -0.7027945 validloss: -0.30038846\n",
      "time: 4.999853134155273 Epoch: 4356 trainloss: -0.70282954 validloss: -0.2959161\n",
      "time: 4.995935916900635 Epoch: 4357 trainloss: -0.70285785 validloss: -0.2963271\n",
      "time: 4.975865602493286 Epoch: 4358 trainloss: -0.70286554 validloss: -0.29615512\n",
      "time: 4.992221832275391 Epoch: 4359 trainloss: -0.7028963 validloss: -0.29815865\n",
      "time: 5.0028698444366455 Epoch: 4360 trainloss: -0.70289767 validloss: -0.2938991\n",
      "time: 4.995206594467163 Epoch: 4361 trainloss: -0.7029135 validloss: -0.2965827\n",
      "time: 4.98997163772583 Epoch: 4362 trainloss: -0.70290375 validloss: -0.30158997\n",
      "time: 4.996960878372192 Epoch: 4363 trainloss: -0.7029195 validloss: -0.29373127\n",
      "time: 4.985333204269409 Epoch: 4364 trainloss: -0.70290005 validloss: -0.30064794\n",
      "time: 4.999921798706055 Epoch: 4365 trainloss: -0.7029156 validloss: -0.29329443\n",
      "time: 4.981177568435669 Epoch: 4366 trainloss: -0.70290977 validloss: -0.29711112\n",
      "time: 5.000158071517944 Epoch: 4367 trainloss: -0.7029164 validloss: -0.29903978\n",
      "time: 4.9907386302948 Epoch: 4368 trainloss: -0.70291066 validloss: -0.29591948\n",
      "time: 4.989076375961304 Epoch: 4369 trainloss: -0.7029384 validloss: -0.29788733\n",
      "time: 5.002686262130737 Epoch: 4370 trainloss: -0.7029269 validloss: -0.29640287\n",
      "time: 4.989176273345947 Epoch: 4371 trainloss: -0.7029094 validloss: -0.29492462\n",
      "time: 5.002861022949219 Epoch: 4372 trainloss: -0.7029012 validloss: -0.29739657\n",
      "time: 4.984375715255737 Epoch: 4373 trainloss: -0.7028845 validloss: -0.29655594\n",
      "time: 4.996976137161255 Epoch: 4374 trainloss: -0.70284826 validloss: -0.29741606\n",
      "time: 4.992247104644775 Epoch: 4375 trainloss: -0.7028171 validloss: -0.29834178\n",
      "time: 4.999208211898804 Epoch: 4376 trainloss: -0.7028048 validloss: -0.29527292\n",
      "time: 5.002716302871704 Epoch: 4377 trainloss: -0.70279634 validloss: -0.2995135\n",
      "time: 4.986243724822998 Epoch: 4378 trainloss: -0.702788 validloss: -0.29370877\n",
      "time: 4.991468906402588 Epoch: 4379 trainloss: -0.70278984 validloss: -0.29935515\n",
      "time: 4.970584154129028 Epoch: 4380 trainloss: -0.70279664 validloss: -0.29919353\n",
      "time: 4.983833074569702 Epoch: 4381 trainloss: -0.7027894 validloss: -0.2947315\n",
      "time: 5.013320446014404 Epoch: 4382 trainloss: -0.7028361 validloss: -0.29706764\n",
      "time: 4.9773969650268555 Epoch: 4383 trainloss: -0.7028409 validloss: -0.30269602\n",
      "time: 4.997402906417847 Epoch: 4384 trainloss: -0.7028347 validloss: -0.29471976\n",
      "time: 4.994379997253418 Epoch: 4385 trainloss: -0.70284617 validloss: -0.2988187\n",
      "time: 4.998783349990845 Epoch: 4386 trainloss: -0.7028481 validloss: -0.29343626\n",
      "time: 4.984952211380005 Epoch: 4387 trainloss: -0.7028758 validloss: -0.2996666\n",
      "time: 4.989810943603516 Epoch: 4388 trainloss: -0.7028755 validloss: -0.2956532\n",
      "time: 4.990997552871704 Epoch: 4389 trainloss: -0.7029019 validloss: -0.298421\n",
      "time: 4.989267110824585 Epoch: 4390 trainloss: -0.70290786 validloss: -0.29552525\n",
      "time: 4.991751432418823 Epoch: 4391 trainloss: -0.7028896 validloss: -0.29637778\n",
      "time: 5.002180576324463 Epoch: 4392 trainloss: -0.7028775 validloss: -0.29958606\n",
      "time: 4.9988625049591064 Epoch: 4393 trainloss: -0.70286685 validloss: -0.2964337\n",
      "time: 5.00759220123291 Epoch: 4394 trainloss: -0.70287657 validloss: -0.29824656\n",
      "time: 4.9970457553863525 Epoch: 4395 trainloss: -0.7028929 validloss: -0.29712552\n",
      "time: 4.989253997802734 Epoch: 4396 trainloss: -0.7028782 validloss: -0.2979006\n",
      "time: 5.011695146560669 Epoch: 4397 trainloss: -0.7028711 validloss: -0.29625368\n",
      "time: 4.997166395187378 Epoch: 4398 trainloss: -0.7029114 validloss: -0.29424912\n",
      "time: 4.989666700363159 Epoch: 4399 trainloss: -0.7028931 validloss: -0.2996938\n",
      "time: 4.997825384140015 Epoch: 4400 trainloss: -0.70290715 validloss: -0.29440314\n",
      "time: 4.996305227279663 Epoch: 4401 trainloss: -0.7029159 validloss: -0.29975027\n",
      "time: 4.998046398162842 Epoch: 4402 trainloss: -0.702936 validloss: -0.298934\n",
      "time: 5.004065036773682 Epoch: 4403 trainloss: -0.702932 validloss: -0.2980056\n",
      "time: 5.012202501296997 Epoch: 4404 trainloss: -0.7029245 validloss: -0.29435527\n",
      "time: 4.9936842918396 Epoch: 4405 trainloss: -0.7029204 validloss: -0.29701293\n",
      "time: 5.004793405532837 Epoch: 4406 trainloss: -0.7028998 validloss: -0.29716903\n",
      "time: 5.003015041351318 Epoch: 4407 trainloss: -0.70291007 validloss: -0.29421717\n",
      "time: 4.982606649398804 Epoch: 4408 trainloss: -0.70288086 validloss: -0.2968515\n",
      "time: 5.000046730041504 Epoch: 4409 trainloss: -0.7029136 validloss: -0.2980549\n",
      "time: 4.998922109603882 Epoch: 4410 trainloss: -0.7028981 validloss: -0.29374385\n",
      "time: 4.984666347503662 Epoch: 4411 trainloss: -0.7029127 validloss: -0.2976216\n",
      "time: 4.97359299659729 Epoch: 4412 trainloss: -0.7029264 validloss: -0.29512796\n",
      "time: 4.987738370895386 Epoch: 4413 trainloss: -0.70291865 validloss: -0.29661414\n",
      "time: 4.99778151512146 Epoch: 4414 trainloss: -0.7029239 validloss: -0.2977439\n",
      "time: 4.999552488327026 Epoch: 4415 trainloss: -0.70290583 validloss: -0.2948023\n",
      "time: 4.9956746101379395 Epoch: 4416 trainloss: -0.70292985 validloss: -0.29750928\n",
      "time: 5.0096611976623535 Epoch: 4417 trainloss: -0.702923 validloss: -0.29653087\n",
      "time: 5.0023744106292725 Epoch: 4418 trainloss: -0.70292425 validloss: -0.29769665\n",
      "time: 4.988206624984741 Epoch: 4419 trainloss: -0.7029187 validloss: -0.2939503\n",
      "time: 4.981908082962036 Epoch: 4420 trainloss: -0.70292604 validloss: -0.2983439\n",
      "time: 5.002604961395264 Epoch: 4421 trainloss: -0.70292073 validloss: -0.29334512\n",
      "time: 4.991165399551392 Epoch: 4422 trainloss: -0.70291823 validloss: -0.2970714\n",
      "time: 4.99930477142334 Epoch: 4423 trainloss: -0.7028958 validloss: -0.29448652\n",
      "time: 4.976493835449219 Epoch: 4424 trainloss: -0.70291615 validloss: -0.2967137\n",
      "time: 5.01513409614563 Epoch: 4425 trainloss: -0.70288855 validloss: -0.2947696\n",
      "time: 5.009951591491699 Epoch: 4426 trainloss: -0.7028868 validloss: -0.2967632\n",
      "time: 4.990346193313599 Epoch: 4427 trainloss: -0.70287114 validloss: -0.29673472\n",
      "time: 4.991870403289795 Epoch: 4428 trainloss: -0.7029004 validloss: -0.29424816\n",
      "time: 4.990724802017212 Epoch: 4429 trainloss: -0.7029089 validloss: -0.29709253\n",
      "time: 5.012998580932617 Epoch: 4430 trainloss: -0.70290077 validloss: -0.2972964\n",
      "time: 5.006970167160034 Epoch: 4431 trainloss: -0.70291525 validloss: -0.29335403\n",
      "time: 4.986121654510498 Epoch: 4432 trainloss: -0.7028824 validloss: -0.29559377\n",
      "time: 4.9989988803863525 Epoch: 4433 trainloss: -0.70291024 validloss: -0.29679874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.00406551361084 Epoch: 4434 trainloss: -0.7029143 validloss: -0.29446656\n",
      "time: 4.991547346115112 Epoch: 4435 trainloss: -0.70292354 validloss: -0.29305387\n",
      "time: 4.993892669677734 Epoch: 4436 trainloss: -0.70290464 validloss: -0.2985677\n",
      "time: 4.990204572677612 Epoch: 4437 trainloss: -0.7029112 validloss: -0.29459298\n",
      "time: 4.982166290283203 Epoch: 4438 trainloss: -0.70289737 validloss: -0.2972664\n",
      "time: 4.9942991733551025 Epoch: 4439 trainloss: -0.7029004 validloss: -0.29222384\n",
      "time: 4.992313623428345 Epoch: 4440 trainloss: -0.7028733 validloss: -0.29951495\n",
      "time: 4.990992069244385 Epoch: 4441 trainloss: -0.7028727 validloss: -0.29424348\n",
      "time: 4.972369909286499 Epoch: 4442 trainloss: -0.7028768 validloss: -0.29342204\n",
      "time: 4.999559640884399 Epoch: 4443 trainloss: -0.702854 validloss: -0.30001718\n",
      "time: 4.980261564254761 Epoch: 4444 trainloss: -0.70285535 validloss: -0.29749754\n",
      "time: 4.997496843338013 Epoch: 4445 trainloss: -0.7028316 validloss: -0.29420784\n",
      "time: 4.978430509567261 Epoch: 4446 trainloss: -0.70285773 validloss: -0.29847467\n",
      "time: 5.011487245559692 Epoch: 4447 trainloss: -0.7028291 validloss: -0.29510996\n",
      "time: 4.988873481750488 Epoch: 4448 trainloss: -0.702857 validloss: -0.29547578\n",
      "time: 4.994983434677124 Epoch: 4449 trainloss: -0.70285094 validloss: -0.29505673\n",
      "time: 4.9976818561553955 Epoch: 4450 trainloss: -0.70284635 validloss: -0.29777744\n",
      "time: 4.994514465332031 Epoch: 4451 trainloss: -0.70287853 validloss: -0.29590365\n",
      "time: 5.004300832748413 Epoch: 4452 trainloss: -0.70288193 validloss: -0.2963575\n",
      "time: 5.000952959060669 Epoch: 4453 trainloss: -0.7029083 validloss: -0.29642057\n",
      "time: 5.020977735519409 Epoch: 4454 trainloss: -0.7028868 validloss: -0.29898775\n",
      "time: 4.986050128936768 Epoch: 4455 trainloss: -0.7029079 validloss: -0.29752946\n",
      "time: 4.990761756896973 Epoch: 4456 trainloss: -0.7029155 validloss: -0.2953491\n",
      "time: 4.986012697219849 Epoch: 4457 trainloss: -0.7029218 validloss: -0.2946792\n",
      "time: 5.007483720779419 Epoch: 4458 trainloss: -0.70292276 validloss: -0.29953527\n",
      "time: 4.996243238449097 Epoch: 4459 trainloss: -0.70291734 validloss: -0.29804912\n",
      "time: 4.991982936859131 Epoch: 4460 trainloss: -0.7028864 validloss: -0.2952625\n",
      "time: 5.003759145736694 Epoch: 4461 trainloss: -0.7029012 validloss: -0.29858404\n",
      "time: 5.008617401123047 Epoch: 4462 trainloss: -0.7028555 validloss: -0.2962025\n",
      "time: 4.998361825942993 Epoch: 4463 trainloss: -0.70288694 validloss: -0.29467657\n",
      "time: 5.001304864883423 Epoch: 4464 trainloss: -0.7028801 validloss: -0.2967614\n",
      "time: 5.0014026165008545 Epoch: 4465 trainloss: -0.70289886 validloss: -0.29734826\n",
      "time: 4.9836366176605225 Epoch: 4466 trainloss: -0.70291114 validloss: -0.297532\n",
      "time: 5.0003862380981445 Epoch: 4467 trainloss: -0.7029024 validloss: -0.2928828\n",
      "time: 4.991525411605835 Epoch: 4468 trainloss: -0.70291525 validloss: -0.29781413\n",
      "time: 4.989041805267334 Epoch: 4469 trainloss: -0.7029125 validloss: -0.29715857\n",
      "time: 4.997023344039917 Epoch: 4470 trainloss: -0.7029118 validloss: -0.29559165\n",
      "time: 4.999439477920532 Epoch: 4471 trainloss: -0.7029041 validloss: -0.29472888\n",
      "time: 4.986794710159302 Epoch: 4472 trainloss: -0.7029151 validloss: -0.29499084\n",
      "time: 5.010481834411621 Epoch: 4473 trainloss: -0.7029314 validloss: -0.29792196\n",
      "time: 5.004255771636963 Epoch: 4474 trainloss: -0.7029329 validloss: -0.29265708\n",
      "time: 4.991971731185913 Epoch: 4475 trainloss: -0.7029401 validloss: -0.29677814\n",
      "time: 4.996203184127808 Epoch: 4476 trainloss: -0.70294696 validloss: -0.29522917\n",
      "time: 4.989470958709717 Epoch: 4477 trainloss: -0.7029516 validloss: -0.29722843\n",
      "time: 4.9931676387786865 Epoch: 4478 trainloss: -0.7029509 validloss: -0.29545313\n",
      "time: 5.012454271316528 Epoch: 4479 trainloss: -0.7029532 validloss: -0.2945554\n",
      "time: 5.016079425811768 Epoch: 4480 trainloss: -0.7029554 validloss: -0.29557446\n",
      "time: 4.985932111740112 Epoch: 4481 trainloss: -0.702947 validloss: -0.29446083\n",
      "time: 4.998309135437012 Epoch: 4482 trainloss: -0.70293933 validloss: -0.29855826\n",
      "time: 4.980528116226196 Epoch: 4483 trainloss: -0.7029287 validloss: -0.29394886\n",
      "time: 5.012421369552612 Epoch: 4484 trainloss: -0.70292497 validloss: -0.29843342\n",
      "time: 4.996898889541626 Epoch: 4485 trainloss: -0.7029319 validloss: -0.2945941\n",
      "time: 4.9885382652282715 Epoch: 4486 trainloss: -0.7029203 validloss: -0.29509747\n",
      "time: 4.990925312042236 Epoch: 4487 trainloss: -0.7029191 validloss: -0.29489356\n",
      "time: 4.986407995223999 Epoch: 4488 trainloss: -0.7029043 validloss: -0.2930738\n",
      "time: 5.005364179611206 Epoch: 4489 trainloss: -0.7029169 validloss: -0.295611\n",
      "time: 5.009660720825195 Epoch: 4490 trainloss: -0.7029227 validloss: -0.29708648\n",
      "time: 4.990284442901611 Epoch: 4491 trainloss: -0.7029258 validloss: -0.29435042\n",
      "time: 4.996670722961426 Epoch: 4492 trainloss: -0.70293736 validloss: -0.29602617\n",
      "time: 4.986159324645996 Epoch: 4493 trainloss: -0.70292705 validloss: -0.29517633\n",
      "time: 5.002843141555786 Epoch: 4494 trainloss: -0.70293707 validloss: -0.2934719\n",
      "time: 4.9811789989471436 Epoch: 4495 trainloss: -0.70292115 validloss: -0.29672384\n",
      "time: 4.990234613418579 Epoch: 4496 trainloss: -0.70291317 validloss: -0.29811832\n",
      "time: 5.00470232963562 Epoch: 4497 trainloss: -0.70291644 validloss: -0.29525164\n",
      "time: 4.996002912521362 Epoch: 4498 trainloss: -0.70290476 validloss: -0.29204094\n",
      "time: 4.995303392410278 Epoch: 4499 trainloss: -0.7029093 validloss: -0.29541102\n",
      "time: 5.005957126617432 Epoch: 4500 trainloss: -0.70288813 validloss: -0.29725406\n",
      "time: 5.010105133056641 Epoch: 4501 trainloss: -0.7029216 validloss: -0.2944817\n",
      "time: 4.997890949249268 Epoch: 4502 trainloss: -0.7029016 validloss: -0.2955196\n",
      "time: 4.996645212173462 Epoch: 4503 trainloss: -0.70289874 validloss: -0.29608113\n",
      "time: 4.995492935180664 Epoch: 4504 trainloss: -0.70289695 validloss: -0.29905498\n",
      "time: 5.01639461517334 Epoch: 4505 trainloss: -0.7028486 validloss: -0.2931912\n",
      "time: 4.9975745677948 Epoch: 4506 trainloss: -0.70288205 validloss: -0.29920548\n",
      "time: 4.994457721710205 Epoch: 4507 trainloss: -0.7028943 validloss: -0.2982311\n",
      "time: 5.00574803352356 Epoch: 4508 trainloss: -0.7028978 validloss: -0.2943872\n",
      "time: 4.997039794921875 Epoch: 4509 trainloss: -0.7029029 validloss: -0.2920569\n",
      "time: 4.995989799499512 Epoch: 4510 trainloss: -0.70291376 validloss: -0.3003885\n",
      "time: 4.99439001083374 Epoch: 4511 trainloss: -0.7029183 validloss: -0.29419842\n",
      "time: 4.991816282272339 Epoch: 4512 trainloss: -0.7028927 validloss: -0.2943016\n",
      "time: 5.000063896179199 Epoch: 4513 trainloss: -0.70291424 validloss: -0.297454\n",
      "time: 5.000046491622925 Epoch: 4514 trainloss: -0.7028843 validloss: -0.29345137\n",
      "time: 5.003901481628418 Epoch: 4515 trainloss: -0.7028991 validloss: -0.2931529\n",
      "time: 4.978423357009888 Epoch: 4516 trainloss: -0.7028855 validloss: -0.29620245\n",
      "time: 4.997105121612549 Epoch: 4517 trainloss: -0.7028789 validloss: -0.2974781\n",
      "time: 4.987395524978638 Epoch: 4518 trainloss: -0.70288867 validloss: -0.29350722\n",
      "time: 5.002295017242432 Epoch: 4519 trainloss: -0.70288104 validloss: -0.29559407\n",
      "time: 4.998640537261963 Epoch: 4520 trainloss: -0.7029116 validloss: -0.2954614\n",
      "time: 5.016003608703613 Epoch: 4521 trainloss: -0.7028817 validloss: -0.29847732\n",
      "time: 5.001190185546875 Epoch: 4522 trainloss: -0.70287603 validloss: -0.29500303\n",
      "time: 5.001237392425537 Epoch: 4523 trainloss: -0.70285064 validloss: -0.29372242\n",
      "time: 4.99517297744751 Epoch: 4524 trainloss: -0.70284283 validloss: -0.29853588\n",
      "time: 4.999279737472534 Epoch: 4525 trainloss: -0.70284516 validloss: -0.29575646\n",
      "time: 4.998190402984619 Epoch: 4526 trainloss: -0.7027954 validloss: -0.29733962\n",
      "time: 4.996275901794434 Epoch: 4527 trainloss: -0.70282096 validloss: -0.29892612\n",
      "time: 5.000304460525513 Epoch: 4528 trainloss: -0.7027791 validloss: -0.29506442\n",
      "time: 4.991948127746582 Epoch: 4529 trainloss: -0.7028636 validloss: -0.29573503\n",
      "time: 4.989051103591919 Epoch: 4530 trainloss: -0.7028744 validloss: -0.29622105\n",
      "time: 4.994670867919922 Epoch: 4531 trainloss: -0.7028703 validloss: -0.30103627\n",
      "time: 5.005021810531616 Epoch: 4532 trainloss: -0.7028803 validloss: -0.29493418\n",
      "time: 5.003964185714722 Epoch: 4533 trainloss: -0.70284295 validloss: -0.29258028\n",
      "time: 5.1549153327941895 Epoch: 4534 trainloss: -0.7028686 validloss: -0.30282667\n",
      "time: 5.0326316356658936 Epoch: 4535 trainloss: -0.70282525 validloss: -0.29417124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.075603246688843 Epoch: 4536 trainloss: -0.70286816 validloss: -0.2955622\n",
      "time: 5.16721248626709 Epoch: 4537 trainloss: -0.70288 validloss: -0.2975978\n",
      "time: 5.033404111862183 Epoch: 4538 trainloss: -0.70289713 validloss: -0.2961632\n",
      "time: 5.137308835983276 Epoch: 4539 trainloss: -0.7028823 validloss: -0.2971732\n",
      "time: 5.099153757095337 Epoch: 4540 trainloss: -0.7028746 validloss: -0.29709753\n",
      "time: 5.13422417640686 Epoch: 4541 trainloss: -0.7028699 validloss: -0.2956536\n",
      "time: 5.14286994934082 Epoch: 4542 trainloss: -0.70287865 validloss: -0.29482165\n",
      "time: 5.112794876098633 Epoch: 4543 trainloss: -0.702887 validloss: -0.30025783\n",
      "time: 5.074097394943237 Epoch: 4544 trainloss: -0.7028994 validloss: -0.29487792\n",
      "time: 5.172449588775635 Epoch: 4545 trainloss: -0.7029077 validloss: -0.30095652\n",
      "time: 5.098798513412476 Epoch: 4546 trainloss: -0.70291626 validloss: -0.29653025\n",
      "time: 5.017823219299316 Epoch: 4547 trainloss: -0.702906 validloss: -0.29388684\n",
      "time: 5.090282678604126 Epoch: 4548 trainloss: -0.70293033 validloss: -0.30019408\n",
      "time: 5.039469957351685 Epoch: 4549 trainloss: -0.7029174 validloss: -0.29400447\n",
      "time: 5.024094820022583 Epoch: 4550 trainloss: -0.70292276 validloss: -0.30027595\n",
      "time: 5.022526264190674 Epoch: 4551 trainloss: -0.70291305 validloss: -0.29591256\n",
      "time: 4.901915550231934 Epoch: 4552 trainloss: -0.7029116 validloss: -0.29433358\n",
      "time: 4.701260805130005 Epoch: 4553 trainloss: -0.7029217 validloss: -0.29471284\n",
      "time: 4.688342332839966 Epoch: 4554 trainloss: -0.70290387 validloss: -0.29774705\n",
      "time: 4.6402881145477295 Epoch: 4555 trainloss: -0.70294195 validloss: -0.29779637\n",
      "time: 4.979297161102295 Epoch: 4556 trainloss: -0.7029125 validloss: -0.2944386\n",
      "time: 5.108293294906616 Epoch: 4557 trainloss: -0.7029268 validloss: -0.2987114\n",
      "time: 5.04941987991333 Epoch: 4558 trainloss: -0.70290834 validloss: -0.29640153\n",
      "time: 5.068087339401245 Epoch: 4559 trainloss: -0.7029169 validloss: -0.2944055\n",
      "time: 5.1291327476501465 Epoch: 4560 trainloss: -0.70288867 validloss: -0.2989422\n",
      "time: 5.0234150886535645 Epoch: 4561 trainloss: -0.7028875 validloss: -0.2958748\n",
      "time: 5.006108522415161 Epoch: 4562 trainloss: -0.7028558 validloss: -0.29960126\n",
      "time: 4.9455320835113525 Epoch: 4563 trainloss: -0.7029015 validloss: -0.29495934\n",
      "time: 4.769550323486328 Epoch: 4564 trainloss: -0.70290095 validloss: -0.29435948\n",
      "time: 4.790250778198242 Epoch: 4565 trainloss: -0.70289326 validloss: -0.29901797\n",
      "time: 4.649552822113037 Epoch: 4566 trainloss: -0.70290303 validloss: -0.29746437\n",
      "time: 4.943040132522583 Epoch: 4567 trainloss: -0.7028672 validloss: -0.29263508\n",
      "time: 5.057960033416748 Epoch: 4568 trainloss: -0.7028643 validloss: -0.29996443\n",
      "time: 4.942817687988281 Epoch: 4569 trainloss: -0.70285875 validloss: -0.29395118\n",
      "time: 4.989026308059692 Epoch: 4570 trainloss: -0.7028728 validloss: -0.29662016\n",
      "time: 4.906317234039307 Epoch: 4571 trainloss: -0.702905 validloss: -0.2980122\n",
      "time: 5.2467429637908936 Epoch: 4572 trainloss: -0.70294726 validloss: -0.29631904\n",
      "time: 5.069260597229004 Epoch: 4573 trainloss: -0.70295876 validloss: -0.2956326\n",
      "time: 5.1533215045928955 Epoch: 4574 trainloss: -0.70296127 validloss: -0.29699504\n",
      "time: 5.304462432861328 Epoch: 4575 trainloss: -0.7029663 validloss: -0.29878885\n",
      "time: 4.713263988494873 Epoch: 4576 trainloss: -0.7029573 validloss: -0.29482165\n",
      "time: 4.7366042137146 Epoch: 4577 trainloss: -0.7029475 validloss: -0.29775164\n",
      "time: 5.046194553375244 Epoch: 4578 trainloss: -0.7029626 validloss: -0.29701376\n",
      "time: 4.974437236785889 Epoch: 4579 trainloss: -0.70296574 validloss: -0.29671377\n",
      "time: 4.960067510604858 Epoch: 4580 trainloss: -0.7029658 validloss: -0.2940507\n",
      "time: 4.7221291065216064 Epoch: 4581 trainloss: -0.7029724 validloss: -0.29709563\n",
      "time: 4.700165271759033 Epoch: 4582 trainloss: -0.70297134 validloss: -0.2940051\n",
      "time: 4.976630926132202 Epoch: 4583 trainloss: -0.7029852 validloss: -0.29834574\n",
      "time: 4.974729061126709 Epoch: 4584 trainloss: -0.70298225 validloss: -0.29616797\n",
      "time: 5.016567707061768 Epoch: 4585 trainloss: -0.7029746 validloss: -0.29387996\n",
      "time: 4.842581510543823 Epoch: 4586 trainloss: -0.70295924 validloss: -0.29806408\n",
      "time: 4.697080373764038 Epoch: 4587 trainloss: -0.7029642 validloss: -0.29616246\n",
      "time: 4.718385219573975 Epoch: 4588 trainloss: -0.7029673 validloss: -0.29641768\n",
      "time: 4.678740501403809 Epoch: 4589 trainloss: -0.70295703 validloss: -0.29688084\n",
      "time: 4.545046329498291 Epoch: 4590 trainloss: -0.70293325 validloss: -0.29347482\n",
      "time: 4.61016845703125 Epoch: 4591 trainloss: -0.70293 validloss: -0.29588348\n",
      "time: 4.796779155731201 Epoch: 4592 trainloss: -0.7029238 validloss: -0.29727343\n",
      "time: 4.905078649520874 Epoch: 4593 trainloss: -0.70292425 validloss: -0.29222453\n",
      "time: 4.747514963150024 Epoch: 4594 trainloss: -0.70294964 validloss: -0.29741967\n",
      "time: 4.7056052684783936 Epoch: 4595 trainloss: -0.702924 validloss: -0.29797423\n",
      "time: 4.685736894607544 Epoch: 4596 trainloss: -0.7029391 validloss: -0.2909622\n",
      "time: 4.734452962875366 Epoch: 4597 trainloss: -0.702938 validloss: -0.2962012\n",
      "time: 4.996896505355835 Epoch: 4598 trainloss: -0.7029149 validloss: -0.2958958\n",
      "time: 4.625699996948242 Epoch: 4599 trainloss: -0.7029256 validloss: -0.29626983\n",
      "time: 4.6480090618133545 Epoch: 4600 trainloss: -0.70288426 validloss: -0.2996337\n",
      "time: 4.512771129608154 Epoch: 4601 trainloss: -0.7028858 validloss: -0.2913798\n",
      "time: 4.638716697692871 Epoch: 4602 trainloss: -0.70286673 validloss: -0.2996682\n",
      "time: 4.539419412612915 Epoch: 4603 trainloss: -0.7028978 validloss: -0.29671705\n",
      "time: 4.559395790100098 Epoch: 4604 trainloss: -0.70291215 validloss: -0.30176684\n",
      "time: 4.566302537918091 Epoch: 4605 trainloss: -0.70291 validloss: -0.29183966\n",
      "time: 5.026936769485474 Epoch: 4606 trainloss: -0.70292413 validloss: -0.29772273\n",
      "time: 4.818796396255493 Epoch: 4607 trainloss: -0.7029091 validloss: -0.2973452\n",
      "time: 4.5498573780059814 Epoch: 4608 trainloss: -0.7029297 validloss: -0.29547817\n",
      "time: 4.588076114654541 Epoch: 4609 trainloss: -0.70292634 validloss: -0.2966183\n",
      "time: 4.5317418575286865 Epoch: 4610 trainloss: -0.7029307 validloss: -0.2950026\n",
      "time: 4.541361093521118 Epoch: 4611 trainloss: -0.7029351 validloss: -0.29584646\n",
      "time: 4.547597885131836 Epoch: 4612 trainloss: -0.7029587 validloss: -0.29780853\n",
      "time: 4.5274083614349365 Epoch: 4613 trainloss: -0.7029483 validloss: -0.2944863\n",
      "time: 4.531001091003418 Epoch: 4614 trainloss: -0.7029557 validloss: -0.29596853\n",
      "time: 4.578073263168335 Epoch: 4615 trainloss: -0.7029522 validloss: -0.29639003\n",
      "time: 4.568140983581543 Epoch: 4616 trainloss: -0.7029423 validloss: -0.29537755\n",
      "time: 4.546410322189331 Epoch: 4617 trainloss: -0.7029402 validloss: -0.29470283\n",
      "time: 4.536693572998047 Epoch: 4618 trainloss: -0.7029435 validloss: -0.3002455\n",
      "time: 4.540300130844116 Epoch: 4619 trainloss: -0.70295435 validloss: -0.29483345\n",
      "time: 4.6771769523620605 Epoch: 4620 trainloss: -0.70295364 validloss: -0.29426616\n",
      "time: 4.544853448867798 Epoch: 4621 trainloss: -0.70296806 validloss: -0.29890755\n",
      "time: 4.568761587142944 Epoch: 4622 trainloss: -0.70297027 validloss: -0.29523957\n",
      "time: 4.595835208892822 Epoch: 4623 trainloss: -0.70298356 validloss: -0.29479602\n",
      "time: 4.700202226638794 Epoch: 4624 trainloss: -0.7029902 validloss: -0.30026326\n",
      "time: 4.669063091278076 Epoch: 4625 trainloss: -0.7029713 validloss: -0.29203263\n",
      "time: 4.560675859451294 Epoch: 4626 trainloss: -0.7029802 validloss: -0.30100086\n",
      "time: 4.552780866622925 Epoch: 4627 trainloss: -0.7029718 validloss: -0.2919207\n",
      "time: 4.830527305603027 Epoch: 4628 trainloss: -0.7029745 validloss: -0.29594654\n",
      "time: 4.527623653411865 Epoch: 4629 trainloss: -0.7029599 validloss: -0.29855955\n",
      "time: 4.696680784225464 Epoch: 4630 trainloss: -0.70297 validloss: -0.29076478\n",
      "time: 4.611958980560303 Epoch: 4631 trainloss: -0.7029679 validloss: -0.29767734\n",
      "time: 4.743449926376343 Epoch: 4632 trainloss: -0.7029663 validloss: -0.29374805\n",
      "time: 4.557859420776367 Epoch: 4633 trainloss: -0.70296097 validloss: -0.29660562\n",
      "time: 4.584510087966919 Epoch: 4634 trainloss: -0.7029529 validloss: -0.29781538\n",
      "time: 4.603708982467651 Epoch: 4635 trainloss: -0.70296 validloss: -0.29382303\n",
      "time: 4.7069995403289795 Epoch: 4636 trainloss: -0.7029628 validloss: -0.2962831\n",
      "time: 4.545733451843262 Epoch: 4637 trainloss: -0.70297486 validloss: -0.29456353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.668355941772461 Epoch: 4638 trainloss: -0.70298564 validloss: -0.29822335\n",
      "time: 4.579716444015503 Epoch: 4639 trainloss: -0.7029803 validloss: -0.29675877\n",
      "time: 4.578847169876099 Epoch: 4640 trainloss: -0.70298207 validloss: -0.29480729\n",
      "time: 4.530765056610107 Epoch: 4641 trainloss: -0.7029678 validloss: -0.29757568\n",
      "time: 4.526508808135986 Epoch: 4642 trainloss: -0.7029675 validloss: -0.29488942\n",
      "time: 4.555726766586304 Epoch: 4643 trainloss: -0.70295435 validloss: -0.2927538\n",
      "time: 4.527323007583618 Epoch: 4644 trainloss: -0.70295775 validloss: -0.2985036\n",
      "time: 4.536006450653076 Epoch: 4645 trainloss: -0.7029474 validloss: -0.29647622\n",
      "time: 4.526905536651611 Epoch: 4646 trainloss: -0.7029429 validloss: -0.2960846\n",
      "time: 4.611002445220947 Epoch: 4647 trainloss: -0.70292467 validloss: -0.29645777\n",
      "time: 4.542001247406006 Epoch: 4648 trainloss: -0.7029071 validloss: -0.29443985\n",
      "time: 4.555864095687866 Epoch: 4649 trainloss: -0.7028912 validloss: -0.30218711\n",
      "time: 4.677921533584595 Epoch: 4650 trainloss: -0.70286065 validloss: -0.2911479\n",
      "time: 4.987019777297974 Epoch: 4651 trainloss: -0.7028682 validloss: -0.2973081\n",
      "time: 4.933281660079956 Epoch: 4652 trainloss: -0.7028671 validloss: -0.29504296\n",
      "time: 4.895867586135864 Epoch: 4653 trainloss: -0.70289314 validloss: -0.29448584\n",
      "time: 4.674092531204224 Epoch: 4654 trainloss: -0.7029032 validloss: -0.2978196\n",
      "time: 4.531945466995239 Epoch: 4655 trainloss: -0.7029071 validloss: -0.29184702\n",
      "time: 4.553546905517578 Epoch: 4656 trainloss: -0.702879 validloss: -0.29819873\n",
      "time: 4.568540811538696 Epoch: 4657 trainloss: -0.70291245 validloss: -0.29713365\n",
      "time: 4.557149171829224 Epoch: 4658 trainloss: -0.70291746 validloss: -0.2947805\n",
      "time: 4.544305324554443 Epoch: 4659 trainloss: -0.7029055 validloss: -0.29372892\n",
      "time: 4.663520574569702 Epoch: 4660 trainloss: -0.70291907 validloss: -0.30183548\n",
      "time: 4.538288116455078 Epoch: 4661 trainloss: -0.70292336 validloss: -0.29327956\n",
      "time: 4.542168855667114 Epoch: 4662 trainloss: -0.70292425 validloss: -0.2957158\n",
      "time: 4.546178579330444 Epoch: 4663 trainloss: -0.7029124 validloss: -0.30012265\n",
      "time: 4.64215087890625 Epoch: 4664 trainloss: -0.7028591 validloss: -0.29608497\n",
      "time: 4.555762052536011 Epoch: 4665 trainloss: -0.7028645 validloss: -0.2998604\n",
      "time: 4.553966045379639 Epoch: 4666 trainloss: -0.70279586 validloss: -0.29348347\n",
      "time: 4.65123176574707 Epoch: 4667 trainloss: -0.70275015 validloss: -0.3008033\n",
      "time: 4.555337429046631 Epoch: 4668 trainloss: -0.7027514 validloss: -0.29586908\n",
      "time: 4.654654026031494 Epoch: 4669 trainloss: -0.7027435 validloss: -0.29595602\n",
      "time: 4.598189353942871 Epoch: 4670 trainloss: -0.70280874 validloss: -0.30249295\n",
      "time: 4.581318616867065 Epoch: 4671 trainloss: -0.7027942 validloss: -0.29523522\n",
      "time: 4.600526332855225 Epoch: 4672 trainloss: -0.7028322 validloss: -0.29447666\n",
      "time: 4.634027719497681 Epoch: 4673 trainloss: -0.7028822 validloss: -0.30122104\n",
      "time: 4.6774985790252686 Epoch: 4674 trainloss: -0.70285755 validloss: -0.29828098\n",
      "time: 4.548966884613037 Epoch: 4675 trainloss: -0.70286924 validloss: -0.29688185\n",
      "time: 4.5090954303741455 Epoch: 4676 trainloss: -0.7028547 validloss: -0.29604384\n",
      "time: 4.649792671203613 Epoch: 4677 trainloss: -0.7028711 validloss: -0.3004197\n",
      "time: 4.529315710067749 Epoch: 4678 trainloss: -0.70285904 validloss: -0.29331142\n",
      "time: 4.530324220657349 Epoch: 4679 trainloss: -0.70286685 validloss: -0.2964731\n",
      "time: 4.539795398712158 Epoch: 4680 trainloss: -0.70285356 validloss: -0.2997176\n",
      "time: 4.524289608001709 Epoch: 4681 trainloss: -0.7028419 validloss: -0.29589838\n",
      "time: 4.517611265182495 Epoch: 4682 trainloss: -0.7028502 validloss: -0.2963351\n",
      "time: 4.51522159576416 Epoch: 4683 trainloss: -0.70284116 validloss: -0.29790983\n",
      "time: 4.572921276092529 Epoch: 4684 trainloss: -0.702852 validloss: -0.29881594\n",
      "time: 4.528241157531738 Epoch: 4685 trainloss: -0.70285267 validloss: -0.29854164\n",
      "time: 4.544665575027466 Epoch: 4686 trainloss: -0.70282435 validloss: -0.29871476\n",
      "time: 4.633237361907959 Epoch: 4687 trainloss: -0.7028589 validloss: -0.30065754\n",
      "time: 4.52912449836731 Epoch: 4688 trainloss: -0.7028356 validloss: -0.29988164\n",
      "time: 4.526528358459473 Epoch: 4689 trainloss: -0.7028505 validloss: -0.29636636\n",
      "time: 4.5745837688446045 Epoch: 4690 trainloss: -0.70288765 validloss: -0.29859418\n",
      "time: 4.781380653381348 Epoch: 4691 trainloss: -0.7028601 validloss: -0.2999176\n",
      "time: 4.566476583480835 Epoch: 4692 trainloss: -0.702852 validloss: -0.29758963\n",
      "time: 4.555124998092651 Epoch: 4693 trainloss: -0.7028559 validloss: -0.2984784\n",
      "time: 4.534381151199341 Epoch: 4694 trainloss: -0.7028528 validloss: -0.3000596\n",
      "time: 4.67465615272522 Epoch: 4695 trainloss: -0.70289534 validloss: -0.29904383\n",
      "time: 4.595287084579468 Epoch: 4696 trainloss: -0.70285773 validloss: -0.29875124\n",
      "time: 4.683109998703003 Epoch: 4697 trainloss: -0.7028625 validloss: -0.2956961\n",
      "time: 4.56846809387207 Epoch: 4698 trainloss: -0.7028696 validloss: -0.29636502\n",
      "time: 4.6488542556762695 Epoch: 4699 trainloss: -0.70287734 validloss: -0.30224964\n",
      "time: 4.942106246948242 Epoch: 4700 trainloss: -0.70286596 validloss: -0.29594272\n",
      "time: 4.99392294883728 Epoch: 4701 trainloss: -0.7028723 validloss: -0.30203253\n",
      "time: 4.8146820068359375 Epoch: 4702 trainloss: -0.70284796 validloss: -0.29878554\n",
      "time: 4.564342737197876 Epoch: 4703 trainloss: -0.7028812 validloss: -0.29872715\n",
      "time: 4.631681203842163 Epoch: 4704 trainloss: -0.70285064 validloss: -0.30018887\n",
      "time: 5.226958751678467 Epoch: 4705 trainloss: -0.7028836 validloss: -0.29576775\n",
      "time: 5.040289402008057 Epoch: 4706 trainloss: -0.7028522 validloss: -0.3010104\n",
      "time: 4.824298858642578 Epoch: 4707 trainloss: -0.7029026 validloss: -0.29739848\n",
      "time: 4.738936424255371 Epoch: 4708 trainloss: -0.70288974 validloss: -0.30039907\n",
      "time: 4.613340377807617 Epoch: 4709 trainloss: -0.7029188 validloss: -0.29886633\n",
      "time: 4.8313353061676025 Epoch: 4710 trainloss: -0.70291543 validloss: -0.2988346\n",
      "time: 4.898165225982666 Epoch: 4711 trainloss: -0.70292395 validloss: -0.30065897\n",
      "time: 4.641856908798218 Epoch: 4712 trainloss: -0.70293033 validloss: -0.29603097\n",
      "time: 4.795374155044556 Epoch: 4713 trainloss: -0.70292073 validloss: -0.29983816\n",
      "time: 5.016833782196045 Epoch: 4714 trainloss: -0.7029281 validloss: -0.29685193\n",
      "time: 4.87002158164978 Epoch: 4715 trainloss: -0.7029195 validloss: -0.30023637\n",
      "time: 5.124996185302734 Epoch: 4716 trainloss: -0.7029035 validloss: -0.29291227\n",
      "time: 5.14675760269165 Epoch: 4717 trainloss: -0.70289254 validloss: -0.30257696\n",
      "time: 5.082931995391846 Epoch: 4718 trainloss: -0.7029119 validloss: -0.2985508\n",
      "time: 5.142973184585571 Epoch: 4719 trainloss: -0.7029 validloss: -0.29472867\n",
      "time: 4.994053840637207 Epoch: 4720 trainloss: -0.7029316 validloss: -0.2985446\n",
      "time: 4.9714086055755615 Epoch: 4721 trainloss: -0.70291424 validloss: -0.29838645\n",
      "time: 4.928463697433472 Epoch: 4722 trainloss: -0.70291114 validloss: -0.29702055\n",
      "time: 4.653818607330322 Epoch: 4723 trainloss: -0.7029306 validloss: -0.29734585\n",
      "time: 5.334593296051025 Epoch: 4724 trainloss: -0.70292354 validloss: -0.29797298\n",
      "time: 4.790571451187134 Epoch: 4725 trainloss: -0.70293945 validloss: -0.29914987\n",
      "time: 4.76294207572937 Epoch: 4726 trainloss: -0.7029328 validloss: -0.2980443\n",
      "time: 4.596046447753906 Epoch: 4727 trainloss: -0.70295596 validloss: -0.29612267\n",
      "time: 4.663207530975342 Epoch: 4728 trainloss: -0.70293605 validloss: -0.29543674\n",
      "time: 4.521173477172852 Epoch: 4729 trainloss: -0.70294404 validloss: -0.30173233\n",
      "time: 4.613433122634888 Epoch: 4730 trainloss: -0.7029413 validloss: -0.29647127\n",
      "time: 4.8411359786987305 Epoch: 4731 trainloss: -0.7029459 validloss: -0.29629076\n",
      "time: 5.176609754562378 Epoch: 4732 trainloss: -0.7029282 validloss: -0.2991592\n",
      "time: 4.725940942764282 Epoch: 4733 trainloss: -0.7029726 validloss: -0.29528382\n",
      "time: 4.7383904457092285 Epoch: 4734 trainloss: -0.7029795 validloss: -0.29578066\n",
      "time: 4.652785301208496 Epoch: 4735 trainloss: -0.70297253 validloss: -0.29820937\n",
      "time: 4.6994948387146 Epoch: 4736 trainloss: -0.70299524 validloss: -0.30012745\n",
      "time: 4.954031944274902 Epoch: 4737 trainloss: -0.703008 validloss: -0.29430068\n",
      "time: 5.015004873275757 Epoch: 4738 trainloss: -0.70300096 validloss: -0.29670462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.066881418228149 Epoch: 4739 trainloss: -0.7029961 validloss: -0.29887566\n",
      "time: 4.836915969848633 Epoch: 4740 trainloss: -0.70298845 validloss: -0.29176065\n",
      "time: 4.631437301635742 Epoch: 4741 trainloss: -0.7029846 validloss: -0.299136\n",
      "time: 4.557146310806274 Epoch: 4742 trainloss: -0.70299584 validloss: -0.29680875\n",
      "time: 4.546156883239746 Epoch: 4743 trainloss: -0.70299554 validloss: -0.2961916\n",
      "time: 4.548584699630737 Epoch: 4744 trainloss: -0.7030073 validloss: -0.29369453\n",
      "time: 4.886430263519287 Epoch: 4745 trainloss: -0.7030066 validloss: -0.2980503\n",
      "time: 4.792699575424194 Epoch: 4746 trainloss: -0.70300555 validloss: -0.29723647\n",
      "time: 4.601346254348755 Epoch: 4747 trainloss: -0.7030087 validloss: -0.29593137\n",
      "time: 4.7753801345825195 Epoch: 4748 trainloss: -0.70301366 validloss: -0.2960287\n",
      "time: 5.004583835601807 Epoch: 4749 trainloss: -0.7030039 validloss: -0.29482362\n",
      "time: 5.018845319747925 Epoch: 4750 trainloss: -0.703017 validloss: -0.296263\n",
      "time: 4.975715160369873 Epoch: 4751 trainloss: -0.7030018 validloss: -0.29851785\n",
      "time: 4.641227960586548 Epoch: 4752 trainloss: -0.7030098 validloss: -0.2937198\n",
      "time: 4.571055889129639 Epoch: 4753 trainloss: -0.7030103 validloss: -0.29909453\n",
      "time: 4.559692621231079 Epoch: 4754 trainloss: -0.70299006 validloss: -0.29689866\n",
      "time: 4.566822528839111 Epoch: 4755 trainloss: -0.7029784 validloss: -0.29549167\n",
      "time: 4.570412635803223 Epoch: 4756 trainloss: -0.70297533 validloss: -0.2974696\n",
      "time: 4.937891006469727 Epoch: 4757 trainloss: -0.7029734 validloss: -0.29834825\n",
      "time: 4.913017988204956 Epoch: 4758 trainloss: -0.7029615 validloss: -0.29743782\n",
      "time: 4.83748197555542 Epoch: 4759 trainloss: -0.70296556 validloss: -0.29209068\n",
      "time: 4.640169143676758 Epoch: 4760 trainloss: -0.70297664 validloss: -0.29966533\n",
      "time: 4.73980975151062 Epoch: 4761 trainloss: -0.7029734 validloss: -0.2955034\n",
      "time: 4.818685054779053 Epoch: 4762 trainloss: -0.7029904 validloss: -0.29855117\n",
      "time: 4.559262752532959 Epoch: 4763 trainloss: -0.7029864 validloss: -0.29906553\n",
      "time: 4.642136096954346 Epoch: 4764 trainloss: -0.7029665 validloss: -0.29348132\n",
      "time: 5.0038909912109375 Epoch: 4765 trainloss: -0.7029668 validloss: -0.29876378\n",
      "time: 4.656352996826172 Epoch: 4766 trainloss: -0.70295674 validloss: -0.29662654\n",
      "time: 5.149707794189453 Epoch: 4767 trainloss: -0.7029702 validloss: -0.2965782\n",
      "time: 5.042573690414429 Epoch: 4768 trainloss: -0.70294666 validloss: -0.2962888\n",
      "time: 4.844998598098755 Epoch: 4769 trainloss: -0.7029622 validloss: -0.2979224\n",
      "time: 4.965174913406372 Epoch: 4770 trainloss: -0.7029633 validloss: -0.29829\n",
      "time: 4.6769187450408936 Epoch: 4771 trainloss: -0.70293456 validloss: -0.29781097\n",
      "time: 4.787824869155884 Epoch: 4772 trainloss: -0.702939 validloss: -0.29604355\n",
      "time: 4.732858180999756 Epoch: 4773 trainloss: -0.7029512 validloss: -0.2971112\n",
      "time: 4.730385065078735 Epoch: 4774 trainloss: -0.7029605 validloss: -0.29772797\n",
      "time: 4.844194650650024 Epoch: 4775 trainloss: -0.7029551 validloss: -0.29856816\n",
      "time: 4.8174803256988525 Epoch: 4776 trainloss: -0.70294666 validloss: -0.29713967\n",
      "time: 4.726425409317017 Epoch: 4777 trainloss: -0.70293826 validloss: -0.2958893\n",
      "time: 4.963263034820557 Epoch: 4778 trainloss: -0.7029494 validloss: -0.29968807\n",
      "time: 4.974365234375 Epoch: 4779 trainloss: -0.70292926 validloss: -0.29544908\n",
      "time: 4.595621347427368 Epoch: 4780 trainloss: -0.7029312 validloss: -0.30034497\n",
      "time: 4.563909292221069 Epoch: 4781 trainloss: -0.7029245 validloss: -0.29266444\n",
      "time: 4.84722113609314 Epoch: 4782 trainloss: -0.70293534 validloss: -0.30257094\n",
      "time: 4.5599470138549805 Epoch: 4783 trainloss: -0.7029473 validloss: -0.29526785\n",
      "time: 4.673719644546509 Epoch: 4784 trainloss: -0.702918 validloss: -0.29440778\n",
      "time: 4.7954747676849365 Epoch: 4785 trainloss: -0.7029291 validloss: -0.3042067\n",
      "time: 4.620251417160034 Epoch: 4786 trainloss: -0.70292574 validloss: -0.29390624\n",
      "time: 4.783906698226929 Epoch: 4787 trainloss: -0.7029129 validloss: -0.29811767\n",
      "time: 4.7787487506866455 Epoch: 4788 trainloss: -0.7029346 validloss: -0.29717836\n",
      "time: 5.148063659667969 Epoch: 4789 trainloss: -0.70291764 validloss: -0.2966826\n",
      "time: 5.200678825378418 Epoch: 4790 trainloss: -0.7029122 validloss: -0.29540452\n",
      "time: 5.304106712341309 Epoch: 4791 trainloss: -0.70292 validloss: -0.29746896\n",
      "time: 5.172020196914673 Epoch: 4792 trainloss: -0.7029376 validloss: -0.29740986\n",
      "time: 5.1029908657073975 Epoch: 4793 trainloss: -0.70293504 validloss: -0.2942536\n",
      "time: 5.098298072814941 Epoch: 4794 trainloss: -0.7029403 validloss: -0.29650792\n",
      "time: 4.7058374881744385 Epoch: 4795 trainloss: -0.7029375 validloss: -0.29970682\n",
      "time: 4.677958011627197 Epoch: 4796 trainloss: -0.70295465 validloss: -0.29519653\n",
      "time: 4.750470399856567 Epoch: 4797 trainloss: -0.7029503 validloss: -0.29417545\n",
      "time: 5.078930854797363 Epoch: 4798 trainloss: -0.7029569 validloss: -0.29965344\n",
      "time: 4.93479061126709 Epoch: 4799 trainloss: -0.70294243 validloss: -0.29636198\n",
      "time: 4.578706741333008 Epoch: 4800 trainloss: -0.702975 validloss: -0.29556182\n",
      "time: 4.548986434936523 Epoch: 4801 trainloss: -0.702977 validloss: -0.29361838\n",
      "time: 4.664650201797485 Epoch: 4802 trainloss: -0.70297796 validloss: -0.29931062\n",
      "time: 4.5283362865448 Epoch: 4803 trainloss: -0.70296866 validloss: -0.29645026\n",
      "time: 4.62397027015686 Epoch: 4804 trainloss: -0.7029826 validloss: -0.29519206\n",
      "time: 4.812057733535767 Epoch: 4805 trainloss: -0.70296764 validloss: -0.297787\n",
      "time: 4.715826988220215 Epoch: 4806 trainloss: -0.7029534 validloss: -0.2987769\n",
      "time: 4.536418914794922 Epoch: 4807 trainloss: -0.70295185 validloss: -0.29617074\n",
      "time: 4.747345685958862 Epoch: 4808 trainloss: -0.7029497 validloss: -0.29474384\n",
      "time: 4.66777491569519 Epoch: 4809 trainloss: -0.7029569 validloss: -0.30079448\n",
      "time: 4.739441871643066 Epoch: 4810 trainloss: -0.70293975 validloss: -0.2962387\n",
      "time: 4.80687689781189 Epoch: 4811 trainloss: -0.7029493 validloss: -0.2969839\n",
      "time: 4.635541677474976 Epoch: 4812 trainloss: -0.702912 validloss: -0.29463452\n",
      "time: 4.654107332229614 Epoch: 4813 trainloss: -0.7029183 validloss: -0.29930705\n",
      "time: 4.786978006362915 Epoch: 4814 trainloss: -0.7028843 validloss: -0.29892084\n",
      "time: 4.821170091629028 Epoch: 4815 trainloss: -0.70291686 validloss: -0.29660273\n",
      "time: 4.595175743103027 Epoch: 4816 trainloss: -0.7029363 validloss: -0.2979579\n",
      "time: 4.5876688957214355 Epoch: 4817 trainloss: -0.70294076 validloss: -0.29883304\n",
      "time: 4.900357961654663 Epoch: 4818 trainloss: -0.70297146 validloss: -0.2977633\n",
      "time: 5.036024570465088 Epoch: 4819 trainloss: -0.70298374 validloss: -0.29514864\n",
      "time: 4.649878025054932 Epoch: 4820 trainloss: -0.70300096 validloss: -0.29787475\n",
      "time: 4.624830961227417 Epoch: 4821 trainloss: -0.7029828 validloss: -0.2998849\n",
      "time: 4.8710036277771 Epoch: 4822 trainloss: -0.70299757 validloss: -0.29564878\n",
      "time: 4.959144592285156 Epoch: 4823 trainloss: -0.7029944 validloss: -0.29700097\n",
      "time: 4.7239251136779785 Epoch: 4824 trainloss: -0.7029787 validloss: -0.2969768\n",
      "time: 5.4400634765625 Epoch: 4825 trainloss: -0.702976 validloss: -0.2986858\n",
      "time: 4.913516521453857 Epoch: 4826 trainloss: -0.70297027 validloss: -0.29756624\n",
      "time: 4.644363641738892 Epoch: 4827 trainloss: -0.70298433 validloss: -0.29728848\n",
      "time: 4.764341115951538 Epoch: 4828 trainloss: -0.7029644 validloss: -0.300304\n",
      "time: 5.078586101531982 Epoch: 4829 trainloss: -0.70299655 validloss: -0.29490018\n",
      "time: 4.958233833312988 Epoch: 4830 trainloss: -0.7029834 validloss: -0.29686224\n",
      "time: 5.02550196647644 Epoch: 4831 trainloss: -0.7029888 validloss: -0.29713446\n",
      "time: 5.069041013717651 Epoch: 4832 trainloss: -0.7029683 validloss: -0.29792997\n",
      "time: 5.126702547073364 Epoch: 4833 trainloss: -0.7029651 validloss: -0.29795167\n",
      "time: 4.785881042480469 Epoch: 4834 trainloss: -0.7029628 validloss: -0.2945179\n",
      "time: 4.865863561630249 Epoch: 4835 trainloss: -0.70298326 validloss: -0.29924396\n",
      "time: 4.8360981941223145 Epoch: 4836 trainloss: -0.702971 validloss: -0.29497612\n",
      "time: 4.548889875411987 Epoch: 4837 trainloss: -0.70297503 validloss: -0.29706746\n",
      "time: 4.571260929107666 Epoch: 4838 trainloss: -0.7029651 validloss: -0.29533333\n",
      "time: 4.728194952011108 Epoch: 4839 trainloss: -0.7029506 validloss: -0.2985563\n",
      "time: 4.6820433139801025 Epoch: 4840 trainloss: -0.7029817 validloss: -0.2953991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.674912452697754 Epoch: 4841 trainloss: -0.7029761 validloss: -0.29555422\n",
      "time: 4.638279438018799 Epoch: 4842 trainloss: -0.70297694 validloss: -0.29859143\n",
      "time: 4.784108400344849 Epoch: 4843 trainloss: -0.70297265 validloss: -0.3001857\n",
      "time: 4.59208869934082 Epoch: 4844 trainloss: -0.70299613 validloss: -0.29355162\n",
      "time: 5.027001142501831 Epoch: 4845 trainloss: -0.70298445 validloss: -0.29880962\n",
      "time: 4.861515760421753 Epoch: 4846 trainloss: -0.70296437 validloss: -0.29680344\n",
      "time: 4.725953578948975 Epoch: 4847 trainloss: -0.7029572 validloss: -0.3001909\n",
      "time: 4.6000401973724365 Epoch: 4848 trainloss: -0.70296776 validloss: -0.2956684\n",
      "time: 4.577057838439941 Epoch: 4849 trainloss: -0.70294046 validloss: -0.29793155\n",
      "time: 4.727838516235352 Epoch: 4850 trainloss: -0.7029301 validloss: -0.29429135\n",
      "time: 4.704608201980591 Epoch: 4851 trainloss: -0.7029057 validloss: -0.29698566\n",
      "time: 4.680457592010498 Epoch: 4852 trainloss: -0.70291346 validloss: -0.29977587\n",
      "time: 4.952438592910767 Epoch: 4853 trainloss: -0.70289344 validloss: -0.2945505\n",
      "time: 4.712861776351929 Epoch: 4854 trainloss: -0.7028932 validloss: -0.2983581\n",
      "time: 4.8985912799835205 Epoch: 4855 trainloss: -0.7028557 validloss: -0.2980067\n",
      "time: 4.961737155914307 Epoch: 4856 trainloss: -0.7028952 validloss: -0.2941926\n",
      "time: 4.9154980182647705 Epoch: 4857 trainloss: -0.7028944 validloss: -0.29433373\n",
      "time: 4.6648783683776855 Epoch: 4858 trainloss: -0.7029222 validloss: -0.30100694\n",
      "time: 4.97104549407959 Epoch: 4859 trainloss: -0.7029347 validloss: -0.29505923\n",
      "time: 4.811681747436523 Epoch: 4860 trainloss: -0.702944 validloss: -0.29624125\n",
      "time: 4.894827604293823 Epoch: 4861 trainloss: -0.7029606 validloss: -0.2949168\n",
      "time: 4.86070990562439 Epoch: 4862 trainloss: -0.7029143 validloss: -0.29713306\n",
      "time: 5.115164518356323 Epoch: 4863 trainloss: -0.702928 validloss: -0.30092412\n",
      "time: 5.111303329467773 Epoch: 4864 trainloss: -0.702921 validloss: -0.29151487\n",
      "time: 5.0217461585998535 Epoch: 4865 trainloss: -0.70292085 validloss: -0.29974347\n",
      "time: 5.070223808288574 Epoch: 4866 trainloss: -0.7029259 validloss: -0.29715592\n",
      "time: 4.9643168449401855 Epoch: 4867 trainloss: -0.70290744 validloss: -0.2972956\n",
      "time: 4.908411502838135 Epoch: 4868 trainloss: -0.7029182 validloss: -0.29890603\n",
      "time: 4.926532745361328 Epoch: 4869 trainloss: -0.70290077 validloss: -0.29552382\n",
      "time: 4.7367329597473145 Epoch: 4870 trainloss: -0.7028992 validloss: -0.29902253\n",
      "time: 4.788018226623535 Epoch: 4871 trainloss: -0.7028982 validloss: -0.2948229\n",
      "time: 4.632137298583984 Epoch: 4872 trainloss: -0.70292693 validloss: -0.29669178\n",
      "time: 4.872324466705322 Epoch: 4873 trainloss: -0.702917 validloss: -0.2992623\n",
      "time: 4.821688175201416 Epoch: 4874 trainloss: -0.70293117 validloss: -0.29939196\n",
      "time: 4.695569038391113 Epoch: 4875 trainloss: -0.702928 validloss: -0.2934147\n",
      "time: 4.5925657749176025 Epoch: 4876 trainloss: -0.70293224 validloss: -0.2980046\n",
      "time: 4.893359184265137 Epoch: 4877 trainloss: -0.7029314 validloss: -0.29954445\n",
      "time: 4.759318590164185 Epoch: 4878 trainloss: -0.7029238 validloss: -0.29602134\n",
      "time: 5.039220571517944 Epoch: 4879 trainloss: -0.70293105 validloss: -0.29667088\n",
      "time: 5.15958046913147 Epoch: 4880 trainloss: -0.7028988 validloss: -0.30074602\n",
      "time: 5.351845026016235 Epoch: 4881 trainloss: -0.70289963 validloss: -0.29318067\n",
      "time: 5.245235443115234 Epoch: 4882 trainloss: -0.70288885 validloss: -0.2973845\n",
      "time: 5.1259589195251465 Epoch: 4883 trainloss: -0.70290154 validloss: -0.29730874\n",
      "time: 4.934486389160156 Epoch: 4884 trainloss: -0.70290726 validloss: -0.29980633\n",
      "time: 4.78730320930481 Epoch: 4885 trainloss: -0.70291436 validloss: -0.29459822\n",
      "time: 5.011220693588257 Epoch: 4886 trainloss: -0.7029143 validloss: -0.30045485\n",
      "time: 4.943857908248901 Epoch: 4887 trainloss: -0.70293087 validloss: -0.29602358\n",
      "time: 4.920843839645386 Epoch: 4888 trainloss: -0.7029321 validloss: -0.2990907\n",
      "time: 5.0510101318359375 Epoch: 4889 trainloss: -0.7029226 validloss: -0.2907031\n",
      "time: 5.017064809799194 Epoch: 4890 trainloss: -0.70292723 validloss: -0.29996386\n",
      "time: 4.882216930389404 Epoch: 4891 trainloss: -0.7029276 validloss: -0.29854625\n",
      "time: 4.908541917800903 Epoch: 4892 trainloss: -0.7029409 validloss: -0.2937221\n",
      "time: 4.674613952636719 Epoch: 4893 trainloss: -0.70295745 validloss: -0.29724294\n",
      "time: 4.803423643112183 Epoch: 4894 trainloss: -0.7029541 validloss: -0.29741418\n",
      "time: 4.965505599975586 Epoch: 4895 trainloss: -0.70299137 validloss: -0.29873142\n",
      "time: 5.054530143737793 Epoch: 4896 trainloss: -0.7029761 validloss: -0.29589915\n",
      "time: 4.911306858062744 Epoch: 4897 trainloss: -0.7029653 validloss: -0.29358605\n",
      "time: 4.906033754348755 Epoch: 4898 trainloss: -0.7029552 validloss: -0.29980853\n",
      "time: 5.0317769050598145 Epoch: 4899 trainloss: -0.7029764 validloss: -0.295079\n",
      "time: 5.061265468597412 Epoch: 4900 trainloss: -0.70295787 validloss: -0.29652986\n",
      "time: 5.064867973327637 Epoch: 4901 trainloss: -0.7029687 validloss: -0.29815853\n",
      "time: 5.105700254440308 Epoch: 4902 trainloss: -0.7029928 validloss: -0.29840496\n",
      "time: 5.039123296737671 Epoch: 4903 trainloss: -0.70296985 validloss: -0.29881284\n",
      "time: 5.064844131469727 Epoch: 4904 trainloss: -0.7029818 validloss: -0.29432303\n",
      "time: 5.111587762832642 Epoch: 4905 trainloss: -0.70298064 validloss: -0.30094543\n",
      "time: 5.072834253311157 Epoch: 4906 trainloss: -0.7029797 validloss: -0.29415712\n",
      "time: 5.006941795349121 Epoch: 4907 trainloss: -0.7029872 validloss: -0.29751387\n",
      "time: 4.791198015213013 Epoch: 4908 trainloss: -0.7029851 validloss: -0.29833934\n",
      "time: 4.874223947525024 Epoch: 4909 trainloss: -0.7029873 validloss: -0.29572716\n",
      "time: 4.7591774463653564 Epoch: 4910 trainloss: -0.7029799 validloss: -0.2981186\n",
      "time: 4.992159605026245 Epoch: 4911 trainloss: -0.70297253 validloss: -0.29428825\n",
      "time: 4.987958908081055 Epoch: 4912 trainloss: -0.70294994 validloss: -0.29953283\n",
      "time: 4.550483703613281 Epoch: 4913 trainloss: -0.70294935 validloss: -0.297646\n",
      "time: 4.616699457168579 Epoch: 4914 trainloss: -0.7029343 validloss: -0.2929217\n",
      "time: 4.827965497970581 Epoch: 4915 trainloss: -0.70296067 validloss: -0.30098036\n",
      "time: 4.562795877456665 Epoch: 4916 trainloss: -0.7029471 validloss: -0.29495883\n",
      "time: 4.609859466552734 Epoch: 4917 trainloss: -0.70296484 validloss: -0.2953724\n",
      "time: 4.58493971824646 Epoch: 4918 trainloss: -0.7029791 validloss: -0.2986005\n",
      "time: 4.541228771209717 Epoch: 4919 trainloss: -0.7029492 validloss: -0.29803774\n",
      "time: 4.672529935836792 Epoch: 4920 trainloss: -0.7029569 validloss: -0.29732537\n",
      "time: 5.063363552093506 Epoch: 4921 trainloss: -0.702969 validloss: -0.29550534\n",
      "time: 5.054657220840454 Epoch: 4922 trainloss: -0.7029884 validloss: -0.2972652\n",
      "time: 5.010121583938599 Epoch: 4923 trainloss: -0.7029786 validloss: -0.29827237\n",
      "time: 5.156641483306885 Epoch: 4924 trainloss: -0.7029819 validloss: -0.2992762\n",
      "time: 4.8264312744140625 Epoch: 4925 trainloss: -0.7029866 validloss: -0.29479837\n",
      "time: 4.684776306152344 Epoch: 4926 trainloss: -0.7029873 validloss: -0.29685935\n",
      "time: 4.675737142562866 Epoch: 4927 trainloss: -0.702972 validloss: -0.2979062\n",
      "time: 5.0201709270477295 Epoch: 4928 trainloss: -0.7029717 validloss: -0.29662803\n",
      "time: 4.595717668533325 Epoch: 4929 trainloss: -0.70297515 validloss: -0.2970869\n",
      "time: 4.995646953582764 Epoch: 4930 trainloss: -0.7029853 validloss: -0.29583928\n",
      "time: 4.75938081741333 Epoch: 4931 trainloss: -0.7029864 validloss: -0.2994398\n",
      "time: 4.6449174880981445 Epoch: 4932 trainloss: -0.7029754 validloss: -0.29686698\n",
      "time: 5.040322303771973 Epoch: 4933 trainloss: -0.7029936 validloss: -0.29840133\n",
      "time: 4.80600118637085 Epoch: 4934 trainloss: -0.70299053 validloss: -0.29744074\n",
      "time: 4.683181047439575 Epoch: 4935 trainloss: -0.7030198 validloss: -0.2953465\n",
      "time: 4.53176736831665 Epoch: 4936 trainloss: -0.70299876 validloss: -0.29721898\n",
      "time: 4.952718734741211 Epoch: 4937 trainloss: -0.7030022 validloss: -0.29595628\n",
      "time: 4.853496789932251 Epoch: 4938 trainloss: -0.702997 validloss: -0.29712403\n",
      "time: 4.6306469440460205 Epoch: 4939 trainloss: -0.7030038 validloss: -0.2979791\n",
      "time: 4.764457941055298 Epoch: 4940 trainloss: -0.7029958 validloss: -0.29667634\n",
      "time: 4.761808633804321 Epoch: 4941 trainloss: -0.70299757 validloss: -0.2956115\n",
      "time: 5.123422384262085 Epoch: 4942 trainloss: -0.70300514 validloss: -0.29620028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.775187015533447 Epoch: 4943 trainloss: -0.7029897 validloss: -0.29727113\n",
      "time: 4.621475696563721 Epoch: 4944 trainloss: -0.70299053 validloss: -0.29572627\n",
      "time: 4.959887981414795 Epoch: 4945 trainloss: -0.7029635 validloss: -0.30018967\n",
      "time: 5.142496347427368 Epoch: 4946 trainloss: -0.70298666 validloss: -0.2966575\n",
      "time: 4.937814950942993 Epoch: 4947 trainloss: -0.7029731 validloss: -0.2952507\n",
      "time: 4.9765284061431885 Epoch: 4948 trainloss: -0.70299494 validloss: -0.2973418\n",
      "time: 4.532475233078003 Epoch: 4949 trainloss: -0.7029744 validloss: -0.29471064\n",
      "time: 4.714528799057007 Epoch: 4950 trainloss: -0.7029783 validloss: -0.29707798\n",
      "time: 4.753751277923584 Epoch: 4951 trainloss: -0.7029692 validloss: -0.2945233\n",
      "time: 4.95508074760437 Epoch: 4952 trainloss: -0.70296836 validloss: -0.30011615\n",
      "time: 4.818689346313477 Epoch: 4953 trainloss: -0.7029452 validloss: -0.2967749\n",
      "time: 4.600012302398682 Epoch: 4954 trainloss: -0.70297045 validloss: -0.29748333\n",
      "time: 4.534488677978516 Epoch: 4955 trainloss: -0.70295215 validloss: -0.2948113\n",
      "time: 4.526274681091309 Epoch: 4956 trainloss: -0.7029595 validloss: -0.29563823\n",
      "time: 4.535324573516846 Epoch: 4957 trainloss: -0.7029891 validloss: -0.29993913\n",
      "time: 4.628021001815796 Epoch: 4958 trainloss: -0.7029801 validloss: -0.29391822\n",
      "time: 4.582028150558472 Epoch: 4959 trainloss: -0.7029916 validloss: -0.29740307\n",
      "time: 4.537019968032837 Epoch: 4960 trainloss: -0.70300245 validloss: -0.2971635\n",
      "time: 4.530963897705078 Epoch: 4961 trainloss: -0.7029911 validloss: -0.29814\n",
      "time: 4.5176472663879395 Epoch: 4962 trainloss: -0.7029741 validloss: -0.29884973\n",
      "time: 4.5289366245269775 Epoch: 4963 trainloss: -0.70296746 validloss: -0.29566193\n",
      "time: 4.529633283615112 Epoch: 4964 trainloss: -0.7029778 validloss: -0.30048355\n",
      "time: 4.554264068603516 Epoch: 4965 trainloss: -0.70295084 validloss: -0.295904\n",
      "time: 4.529884576797485 Epoch: 4966 trainloss: -0.7029674 validloss: -0.2960641\n",
      "time: 4.553187131881714 Epoch: 4967 trainloss: -0.70293444 validloss: -0.3007848\n",
      "time: 4.569666385650635 Epoch: 4968 trainloss: -0.7029478 validloss: -0.2947957\n",
      "time: 4.5600905418396 Epoch: 4969 trainloss: -0.7029327 validloss: -0.2997718\n",
      "time: 4.541626214981079 Epoch: 4970 trainloss: -0.7029571 validloss: -0.29619336\n",
      "time: 4.557091236114502 Epoch: 4971 trainloss: -0.70296377 validloss: -0.30010346\n",
      "time: 4.53583288192749 Epoch: 4972 trainloss: -0.70297754 validloss: -0.29454735\n",
      "time: 4.53873348236084 Epoch: 4973 trainloss: -0.702974 validloss: -0.29951882\n",
      "time: 4.528271913528442 Epoch: 4974 trainloss: -0.7029815 validloss: -0.2995153\n",
      "time: 4.559178590774536 Epoch: 4975 trainloss: -0.7029923 validloss: -0.29762813\n",
      "time: 4.523457765579224 Epoch: 4976 trainloss: -0.7029827 validloss: -0.2980333\n",
      "time: 4.52595329284668 Epoch: 4977 trainloss: -0.7030073 validloss: -0.29512808\n",
      "time: 4.525665044784546 Epoch: 4978 trainloss: -0.7029854 validloss: -0.2984922\n",
      "time: 4.533135175704956 Epoch: 4979 trainloss: -0.7029976 validloss: -0.2974321\n",
      "time: 4.520126819610596 Epoch: 4980 trainloss: -0.70299256 validloss: -0.29893824\n",
      "time: 4.531441688537598 Epoch: 4981 trainloss: -0.70298946 validloss: -0.29747075\n",
      "time: 4.5307629108428955 Epoch: 4982 trainloss: -0.70299286 validloss: -0.29762444\n",
      "time: 4.550310373306274 Epoch: 4983 trainloss: -0.7030105 validloss: -0.29776126\n",
      "time: 4.541662693023682 Epoch: 4984 trainloss: -0.70301205 validloss: -0.29661986\n",
      "time: 4.521060466766357 Epoch: 4985 trainloss: -0.70299995 validloss: -0.29922667\n",
      "time: 4.536391258239746 Epoch: 4986 trainloss: -0.7030041 validloss: -0.298254\n",
      "time: 4.527371406555176 Epoch: 4987 trainloss: -0.703002 validloss: -0.2926911\n",
      "time: 4.530990362167358 Epoch: 4988 trainloss: -0.7030103 validloss: -0.30015126\n",
      "time: 4.5381128787994385 Epoch: 4989 trainloss: -0.7029919 validloss: -0.29684985\n",
      "time: 4.549121618270874 Epoch: 4990 trainloss: -0.703012 validloss: -0.29763138\n",
      "time: 4.568805456161499 Epoch: 4991 trainloss: -0.7030128 validloss: -0.29872307\n",
      "time: 4.537160158157349 Epoch: 4992 trainloss: -0.703023 validloss: -0.29711038\n",
      "time: 4.520730257034302 Epoch: 4993 trainloss: -0.70301926 validloss: -0.2988848\n",
      "time: 4.528283357620239 Epoch: 4994 trainloss: -0.7030207 validloss: -0.29374558\n",
      "time: 4.632824420928955 Epoch: 4995 trainloss: -0.70300525 validloss: -0.3027617\n",
      "time: 4.562459468841553 Epoch: 4996 trainloss: -0.7030003 validloss: -0.29411468\n",
      "time: 4.529017448425293 Epoch: 4997 trainloss: -0.7030134 validloss: -0.2978802\n",
      "time: 4.543233156204224 Epoch: 4998 trainloss: -0.70299524 validloss: -0.2963151\n",
      "time: 4.535333633422852 Epoch: 4999 trainloss: -0.7029842 validloss: -0.2950453\n"
     ]
    }
   ],
   "source": [
    "### import time\n",
    "\n",
    "for epoch in range(2500,5000):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    metric.reset()\n",
    "\n",
    "    train_iter.reset()\n",
    "    \n",
    "    valid_iter.reset()\n",
    "    \n",
    "\n",
    "    for batch in train_iter:\n",
    "        # Copy data to executor input. Note the [:].\n",
    "        data[:] = batch.data[0]\n",
    "        label[:] = batch.label[0]\n",
    "\n",
    "        # Forward\n",
    "        outputs=exe.forward(is_train=True)\n",
    "        # Backward\n",
    "        exe.backward()\n",
    "\n",
    "        # Update\n",
    "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
    "            weight, grad = pair\n",
    "            updater(i, grad, weight)   \n",
    "        metric.update(batch.label[0], exe.outputs[0])#metric.update(label,p)\n",
    "        \n",
    "    e=metric.get()\n",
    "    err_train=-e[1].asnumpy()[0]\n",
    "    \n",
    "    if epoch % 100== 0:       \n",
    "        #print(\"do_checkpoint\")\n",
    "        arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
    "        aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
    "        mx.model.save_checkpoint(prefix, epoch, network, arg, aux)\n",
    "        \n",
    "        \n",
    "    #compute valid loss per epoch    \n",
    "    metric.reset()\n",
    "    for batch in valid_iter:        \n",
    "        data[:] = batch.data[0]       \n",
    "        label[:] = batch.label[0]\n",
    "        # predict\n",
    "        outputs = exe.forward(is_train=False)\n",
    "        metric.update(batch.label[0], exe.outputs[0])\n",
    "    e=metric.get()\n",
    "    err_valid=-e[1].asnumpy()[0]\n",
    "    end = time.time()\n",
    "    print('time:',end-start,'Epoch:',epoch,'trainloss:',err_train,'validloss:',err_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why train and valid error not the same ??!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_315():\n",
    "    source = mx.sym.Variable(\"data\")\n",
    "    label = mx.sym.Variable(\"softmax_label\")\n",
    "    #print_inferred_shape(source)\n",
    "\n",
    "    kernel_size = (3, 3, 3)\n",
    "    stride=(1, 1,1)\n",
    "    pad_size = (1, 1, 1)\n",
    "    filter_count = 32\n",
    "    net =  mx.sym.Convolution(data=source, kernel=kernel_size, stride=stride, pad=pad_size, num_filter=filter_count)\n",
    "    #net = mx.sym.BatchNorm(net)\n",
    "    net = mx.sym.Activation(net, act_type=\"relu\")\n",
    "    #print_inferred_shape(net)\n",
    "    \n",
    "    \n",
    "    net = mx.sym.Convolution(net, kernel=kernel_size, stride=stride, pad=pad_size, num_filter=filter_count)\n",
    "    #net = mx.sym.BatchNorm(net)\n",
    "    net = mx.sym.Activation(net, act_type=\"relu\")\n",
    "    #print_inferred_shape(net)\n",
    "    \n",
    "    net = mx.sym.Convolution(net, kernel=kernel_size, stride=stride, pad=pad_size, num_filter=filter_count)\n",
    "    #net = mx.sym.BatchNorm(net)\n",
    "    net = mx.sym.Activation(net, act_type=\"relu\")\n",
    "    #print_inferred_shape(net)\n",
    "    \n",
    "    net1=net\n",
    "    \n",
    "    net = mx.sym.Pooling(net, pool_type=\"max\", kernel=(2, 2,2), stride=(2,2, 2))\n",
    "    #print_inferred_shape(net)\n",
    "    \n",
    "    net = mx.sym.Convolution(net, kernel=kernel_size, stride=stride, pad=pad_size, num_filter=filter_count)\n",
    "    #net = mx.sym.BatchNorm(net)\n",
    "    net = mx.sym.Activation(net, act_type=\"relu\")\n",
    "\n",
    "    #print_inferred_shape(net)\n",
    "\n",
    "    \n",
    "    net =  mx.sym.Convolution(net, kernel=kernel_size, stride=stride, pad=pad_size, num_filter=filter_count)\n",
    "    #net = mx.sym.BatchNorm(net)\n",
    "    net = mx.sym.Activation(net, act_type=\"relu\")\n",
    "    #print_inferred_shape(net)\n",
    "    \n",
    "    net = mx.sym.Convolution(net, kernel=kernel_size, stride=stride, pad=pad_size, num_filter=filter_count)\n",
    "    #net = mx.sym.BatchNorm(net)\n",
    "    net = mx.sym.Activation(net, act_type=\"relu\")\n",
    "    #print_inferred_shape(net)\n",
    "    \n",
    "    net = mx.sym.Dropout(net,p=0.4)\n",
    "    \n",
    "    net = mx.sym.Deconvolution(net, kernel=(2, 2,2), pad=(0, 0,0), stride=(2,2, 2), num_filter=filter_count)\n",
    "    net = mx.sym.Activation(net, act_type=\"relu\")\n",
    "\n",
    "\n",
    "    \n",
    "    net = mx.sym.Concat(*[net1, net])\n",
    "    #print_inferred_shape(net)\n",
    "\n",
    "    net = mx.sym.Convolution(net, kernel=kernel_size, stride=stride, pad=pad_size, num_filter=filter_count)\n",
    "    #net = mx.sym.BatchNorm(net)\n",
    "    net = mx.sym.Activation(net, act_type=\"relu\")\n",
    "    #print_inferred_shape(net)\n",
    "    \n",
    "    net = mx.sym.Convolution(net, kernel=kernel_size, stride=stride, pad=pad_size, num_filter=filter_count)\n",
    "    #net = mx.sym.BatchNorm(net)\n",
    "    net = mx.sym.Activation(net, act_type=\"relu\")\n",
    "    #print_inferred_shape(net)\n",
    "        \n",
    "    net = mx.sym.Convolution(net, kernel=kernel_size, stride=stride, pad=pad_size, num_filter=1)\n",
    "    #net = mx.sym.BatchNorm(net)\n",
    "    net = mx.sym.Activation(net, act_type=\"sigmoid\")\n",
    "    #print_inferred_shape(net)\n",
    "    \n",
    "    y = mx.symbol.Flatten(net)\n",
    "    \n",
    "    loss= mx.sym.MakeLoss(nn.dice_coef_loss(label, y))\n",
    "    pred_loss = mx.sym.Group([mx.sym.BlockGrad(y), loss])\n",
    "\n",
    "    return pred_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
