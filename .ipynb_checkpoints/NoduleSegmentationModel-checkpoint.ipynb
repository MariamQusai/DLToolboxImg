{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodule Segmentation: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Configuration</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-mean-of-images\" data-toc-modified-id=\"Find-mean-of-images-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Find mean of images</a></span></li><li><span><a href=\"#Find-variance-of-images\" data-toc-modified-id=\"Find-variance-of-images-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Find variance of images</a></span></li></ul></li><li><span><a href=\"#Data-Iterator\" data-toc-modified-id=\"Data-Iterator-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Iterator</a></span></li><li><span><a href=\"#Evaluation-Metric\" data-toc-modified-id=\"Evaluation-Metric-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation Metric</a></span></li><li><span><a href=\"#Model-Architecture\" data-toc-modified-id=\"Model-Architecture-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Architecture</a></span></li><li><span><a href=\"#Optimizer\" data-toc-modified-id=\"Optimizer-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Optimizer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find--learning-rate\" data-toc-modified-id=\"Find--learning-rate-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Find  learning rate</a></span></li><li><span><a href=\"#Optimizer-Parameters\" data-toc-modified-id=\"Optimizer-Parameters-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Optimizer Parameters</a></span></li></ul></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Train Model</a></span></li><li><span><a href=\"#Evaluate-Model\" data-toc-modified-id=\"Evaluate-Model-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluate Model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mynnet7 as nn\n",
    "import pickle\n",
    "import mxnet as mx\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interm_dir4='/home/mas/x110/Datasets/Dataset2/' \n",
    "s = \"2018_10_31\"\n",
    "train_data_path=interm_dir4+'processed/train'+s+'.rec'\n",
    "train_idx_path=interm_dir4+'processed/train'+s+'.idx'\n",
    "valid_data_path=interm_dir4+'processed/valid'+s+'.rec'\n",
    "valid_idx_path=interm_dir4+'processed/valid'+s+'.idx'\n",
    "test_data_path=interm_dir4+'processed/test'+s+'.rec'\n",
    "test_idx_path=interm_dir4+'processed/test'+s+'.idx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_stats = True\n",
    "bs = 34\n",
    "load_model = False\n",
    "model_path = \"/home/mas/x110/model/oct22\"\n",
    "model_epoch=499\n",
    "prefix = \"/home/mas/x110/model/oct31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find mean of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27012206321241655"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if find_stats:\n",
    "    BATCH_SIZE=1\n",
    "    train_iter=nn.FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_augment=True,mean_image=0,std_image=1)\n",
    "    train_iter.reset()\n",
    "    x_mean = np.zeros((32,32,32))\n",
    "    for i,batch in enumerate(train_iter):\n",
    "        X =  batch.data[0][0][0].asnumpy()\n",
    "        x_mean+=X\n",
    "    x_mean=np.mean(x_mean/i)\n",
    "    # Saving the objects:\n",
    "    with open(interm_dir4+'processed/x_mean.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([x_mean], f)\n",
    "\n",
    "else:\n",
    "    with open(interm_dir4+'processed/x_mean.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "        x_mean = pickle.load(f)\n",
    "x_mean#x_mean=.2815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_mean=0.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variance of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.268007871005759"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if find_stats: \n",
    "    BATCH_SIZE=1\n",
    "    train_iter=nn.FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_augment=True,mean_image=0,std_image = 1)\n",
    "    train_iter.reset()\n",
    "    x_var = np.zeros((32,32,32))\n",
    "    for i,batch in enumerate(train_iter):\n",
    "        X =  (batch.data[0][0][0].asnumpy()-x_mean)**2\n",
    "        x_var+=X\n",
    "    #x_var=x_var/(i-1)\n",
    "    #x_var#x_mean=.2815\n",
    "    N = i*32*32*32\n",
    "    x_var = np.sum(x_var)/(N-1)\n",
    "    x_var#x_var = .07877\n",
    "    x_std = np.sqrt(x_var)#x_std=.2807\n",
    "    with open(interm_dir4+'processed/x_std.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([x_std], f)\n",
    "else:\n",
    "    with open(interm_dir4+'processed/x_std.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "        x_std = pickle.load(f)\n",
    "x_std#x_std=.2807"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_std = 0.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': (34, 1, 32, 32, 32), 'softmax_label': (34, 32768)}\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=bs\n",
    "train_iter=nn.FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_augment=False,mean_image=x_mean,std_image = x_std)\n",
    "input_shapes = dict(train_iter.provide_data+train_iter.provide_label)\n",
    "print(input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': (34, 1, 32, 32, 32), 'softmax_label': (34, 32768)}\n"
     ]
    }
   ],
   "source": [
    "print(input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=bs\n",
    "valid_iter=nn.FileIter(valid_data_path,valid_idx_path,batch_size=BATCH_SIZE,do_augment=False,mean_image=x_mean,std_image = x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_iter.reset()\n",
    "valid_iter.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dice_coef2(label, y):\n",
    "    smooth = 1.\n",
    "    label=mx.nd.array(label).as_in_context(mx.gpu(0))\n",
    "    y=mx.nd.array(y).as_in_context(mx.gpu(0))\n",
    "    intersection = mx.nd.sum(label*y)\n",
    "    return ((2. * intersection + smooth) / (mx.nd.sum(label) +mx.nd.sum(mx.nd.abs(y)) + smooth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===============Evaluation metric(s)================= \n",
    "metric = mx.metric.CustomMetric(feval=nn.dice_coef2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mas/.virtualenvs/colab/lib/python3.5/site-packages/ipykernel_launcher.py:27: DeprecationWarning: \u001b[91mCalling initializer with init(str, NDArray) has been deprecated.please use init(mx.init.InitDesc(...), NDArray) instead.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if load_model:\n",
    "    network, arg_params, aux_params = mx.model.load_checkpoint(model_path , model_epoch)\n",
    "\n",
    "    # Binding\n",
    "    exe = network.simple_bind(ctx=mx.gpu(0), **input_shapes)\n",
    "\n",
    "\n",
    "    exe.copy_params_from(arg_params, aux_params)\n",
    "    \n",
    "    # get handle to input arrays\n",
    "    arg_arrays = dict(zip(network.list_arguments(), exe.arg_arrays))\n",
    "    data = arg_arrays[train_iter.provide_data[0][0]]\n",
    "    label = arg_arrays[train_iter.provide_label[0][0]]\n",
    "else:\n",
    "\n",
    "    network = nn.get_net_317()\n",
    "    init = mx.init.Normal(0.01) #note biases and gamma/beta are not affected\n",
    "\n",
    "    # Binding\n",
    "    exe = network.simple_bind(ctx=mx.gpu(), **input_shapes)\n",
    "    # get handle to input arrays\n",
    "    arg_arrays = dict(zip(network.list_arguments(), exe.arg_arrays))\n",
    "    data = arg_arrays[train_iter.provide_data[0][0]]\n",
    "    label = arg_arrays[train_iter.provide_label[0][0]]\n",
    "    for name, arr in arg_arrays.items():\n",
    "        if name not in input_shapes:\n",
    "            init(name, arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find  learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb=train_iter.num_data//train_iter.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sched=nn.lr_find(1e-4,nb,end_lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We also need to create an optimizer for updating weights\n",
    "opt = mx.optimizer.SGD(\n",
    "    learning_rate=.01,\n",
    "    momentum=0.9,\n",
    "    wd=0.00001,\n",
    "    lr_scheduler=sched)\n",
    "\n",
    "updater = mx.optimizer.get_updater(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 139.71043348312378 Epoch: 0 trainloss: -0.18696861 validloss: -0.18071817\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,1):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    metric.reset()\n",
    "\n",
    "    train_iter.reset()\n",
    "    \n",
    "    valid_iter.reset()\n",
    "    \n",
    "    sched.reset()\n",
    "        \n",
    "    sched.on_train_begin()\n",
    "    \n",
    "\n",
    "    for batch in train_iter:\n",
    "        # Copy data to executor input. Note the [:].\n",
    "        data[:] = batch.data[0]\n",
    "        label[:] = batch.label[0]\n",
    "\n",
    "        # Forward\n",
    "        outputs=exe.forward(is_train=True)\n",
    "        # Backward\n",
    "        exe.backward()\n",
    "\n",
    "        # Update\n",
    "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
    "            weight, grad = pair\n",
    "            updater(i, grad, weight)   \n",
    "        metric.update(batch.label[0], exe.outputs[0])#metric.update(label,p)\n",
    "        \n",
    "        e=metric.get()\n",
    "        err_train=-e[1].asnumpy()[0]\n",
    "        sched.on_batch_end(err_train)\n",
    "    \n",
    "    if epoch % 100== 0:       \n",
    "        #print(\"do_checkpoint\")\n",
    "        arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
    "        aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
    "        mx.model.save_checkpoint(prefix, epoch, network, arg, aux)\n",
    "        \n",
    "        \n",
    "    #compute valid loss per epoch    \n",
    "    metric.reset()\n",
    "    for batch in valid_iter:        \n",
    "        data[:] = batch.data[0]       \n",
    "        label[:] = batch.label[0]\n",
    "        # predict\n",
    "        outputs = exe.forward(is_train=False)\n",
    "        metric.update(batch.label[0], exe.outputs[0])\n",
    "    e=metric.get()\n",
    "    err_valid=-e[1].asnumpy()[0]\n",
    "    end = time.time()\n",
    "    print('time:',end-start,'Epoch:',epoch,'trainloss:',err_train,'validloss:',err_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f31302cae80>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sched.lrs, sched.losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We also need to create an optimizer for updating weights\n",
    "# ===============Optimizer=================                        \n",
    "opt = mx.optimizer.SGD(\n",
    "    learning_rate=.01,momentum=0.99,wd=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updater.optimizer.lr_scheduler=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updater = mx.optimizer.get_updater(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 99.13337731361389 Epoch: 0 trainloss: -0.21006662 validloss: -0.22243527\n",
      "time: 98.13234972953796 Epoch: 1 trainloss: -0.21784371 validloss: -0.2329826\n",
      "time: 98.28647017478943 Epoch: 2 trainloss: -0.22565451 validloss: -0.24015585\n",
      "time: 98.30458879470825 Epoch: 3 trainloss: -0.23762484 validloss: -0.26260078\n",
      "time: 98.54022288322449 Epoch: 4 trainloss: -0.2469695 validloss: -0.2995131\n",
      "time: 98.27189826965332 Epoch: 5 trainloss: -0.25938457 validloss: -0.28533262\n",
      "time: 98.3297986984253 Epoch: 6 trainloss: -0.2757792 validloss: -0.30065966\n",
      "time: 98.16549921035767 Epoch: 7 trainloss: -0.29839376 validloss: -0.3418324\n",
      "time: 98.27327394485474 Epoch: 8 trainloss: -0.32213333 validloss: -0.26442698\n",
      "time: 98.25467419624329 Epoch: 9 trainloss: -0.35070053 validloss: -0.26968226\n",
      "time: 98.2281584739685 Epoch: 10 trainloss: -0.36434758 validloss: -0.41894838\n",
      "time: 98.25940012931824 Epoch: 11 trainloss: -0.41212115 validloss: -0.41288796\n",
      "time: 100.67501735687256 Epoch: 12 trainloss: -0.44332725 validloss: -0.49534422\n",
      "time: 113.92312622070312 Epoch: 13 trainloss: -0.48908645 validloss: -0.37675467\n",
      "time: 109.4739978313446 Epoch: 14 trainloss: -0.5117554 validloss: -0.3960545\n",
      "time: 114.15375208854675 Epoch: 15 trainloss: -0.54173756 validloss: -0.38049504\n",
      "time: 114.17168951034546 Epoch: 16 trainloss: -0.5313222 validloss: -0.5388639\n",
      "time: 117.51226854324341 Epoch: 17 trainloss: -0.5770089 validloss: -0.5186944\n",
      "time: 99.6531629562378 Epoch: 18 trainloss: -0.5932314 validloss: -0.35549837\n",
      "time: 100.16243410110474 Epoch: 19 trainloss: -0.6234002 validloss: -0.41684029\n",
      "time: 100.33356428146362 Epoch: 20 trainloss: -0.5973676 validloss: -0.3844778\n",
      "time: 98.14392685890198 Epoch: 21 trainloss: -0.63331795 validloss: -0.43969178\n",
      "time: 101.51941323280334 Epoch: 22 trainloss: -0.63623214 validloss: -0.36663014\n",
      "time: 98.2800760269165 Epoch: 23 trainloss: -0.6575736 validloss: -0.6361992\n",
      "time: 98.26494336128235 Epoch: 24 trainloss: -0.67372555 validloss: -0.4891054\n",
      "time: 98.39475393295288 Epoch: 25 trainloss: -0.684345 validloss: -0.6310221\n",
      "time: 98.36770844459534 Epoch: 26 trainloss: -0.6772977 validloss: -0.6506237\n",
      "time: 106.10885071754456 Epoch: 27 trainloss: -0.65661055 validloss: -0.5346078\n",
      "time: 109.1261658668518 Epoch: 28 trainloss: -0.69542813 validloss: -0.5322326\n",
      "time: 107.093665599823 Epoch: 29 trainloss: -0.7133386 validloss: -0.59897035\n",
      "time: 101.70897459983826 Epoch: 30 trainloss: -0.7194737 validloss: -0.49111822\n",
      "time: 110.56725978851318 Epoch: 31 trainloss: -0.7083593 validloss: -0.6102535\n",
      "time: 105.24040126800537 Epoch: 32 trainloss: -0.6596787 validloss: -0.6780649\n",
      "time: 108.04086256027222 Epoch: 33 trainloss: -0.7231898 validloss: -0.6885094\n",
      "time: 102.2624523639679 Epoch: 34 trainloss: -0.7273612 validloss: -0.6891988\n",
      "time: 103.43218564987183 Epoch: 35 trainloss: -0.7233078 validloss: -0.67937744\n",
      "time: 102.78812408447266 Epoch: 36 trainloss: -0.72068065 validloss: -0.7105776\n",
      "time: 102.42433738708496 Epoch: 37 trainloss: -0.73708665 validloss: -0.6994739\n",
      "time: 101.87799072265625 Epoch: 38 trainloss: -0.72795683 validloss: -0.72727233\n",
      "time: 103.54151678085327 Epoch: 39 trainloss: -0.7521505 validloss: -0.72446626\n",
      "time: 100.91119408607483 Epoch: 40 trainloss: -0.75110877 validloss: -0.7515165\n",
      "time: 127.67717456817627 Epoch: 41 trainloss: -0.76274014 validloss: -0.7435487\n",
      "time: 102.51688647270203 Epoch: 42 trainloss: -0.74401546 validloss: -0.7410318\n",
      "time: 98.92440152168274 Epoch: 43 trainloss: -0.7685772 validloss: -0.7191836\n",
      "time: 107.73657464981079 Epoch: 44 trainloss: -0.77163965 validloss: -0.7518264\n",
      "time: 113.58714318275452 Epoch: 45 trainloss: -0.7783296 validloss: -0.73271227\n",
      "time: 115.05996227264404 Epoch: 46 trainloss: -0.7724601 validloss: -0.75822055\n",
      "time: 113.14483118057251 Epoch: 47 trainloss: -0.7403131 validloss: -0.75632477\n",
      "time: 115.11100149154663 Epoch: 48 trainloss: -0.7530223 validloss: -0.75447994\n",
      "time: 111.90988302230835 Epoch: 49 trainloss: -0.79004437 validloss: -0.7376433\n",
      "time: 115.90242671966553 Epoch: 50 trainloss: -0.7735759 validloss: -0.7590705\n",
      "time: 110.32131385803223 Epoch: 51 trainloss: -0.778393 validloss: -0.7523132\n",
      "time: 101.17197275161743 Epoch: 52 trainloss: -0.7876159 validloss: -0.7238682\n",
      "time: 115.17333102226257 Epoch: 53 trainloss: -0.7658246 validloss: -0.76701707\n",
      "time: 105.92204451560974 Epoch: 54 trainloss: -0.8009499 validloss: -0.77014786\n",
      "time: 101.47484970092773 Epoch: 55 trainloss: -0.79786956 validloss: -0.7684444\n",
      "time: 98.87162947654724 Epoch: 56 trainloss: -0.8045894 validloss: -0.7633161\n",
      "time: 98.67868828773499 Epoch: 57 trainloss: -0.7621254 validloss: -0.77630836\n",
      "time: 98.70830821990967 Epoch: 58 trainloss: -0.7946177 validloss: -0.77925354\n",
      "time: 98.74840188026428 Epoch: 59 trainloss: -0.81022733 validloss: -0.7606753\n",
      "time: 103.7239305973053 Epoch: 60 trainloss: -0.79897225 validloss: -0.73913544\n",
      "time: 124.1809470653534 Epoch: 61 trainloss: -0.800372 validloss: -0.7763875\n",
      "time: 100.49501013755798 Epoch: 62 trainloss: -0.80724055 validloss: -0.7796811\n",
      "time: 98.083172082901 Epoch: 63 trainloss: -0.80534244 validloss: -0.780281\n",
      "time: 98.02549719810486 Epoch: 64 trainloss: -0.8225649 validloss: -0.76179904\n",
      "time: 98.05191898345947 Epoch: 65 trainloss: -0.80706275 validloss: -0.7542982\n",
      "time: 98.07244539260864 Epoch: 66 trainloss: -0.8251945 validloss: -0.7788605\n",
      "time: 98.00951528549194 Epoch: 67 trainloss: -0.80546594 validloss: -0.7910003\n",
      "time: 98.45005416870117 Epoch: 68 trainloss: -0.7922862 validloss: -0.7861344\n",
      "time: 118.82299304008484 Epoch: 69 trainloss: -0.82772994 validloss: -0.78096473\n",
      "time: 117.45067381858826 Epoch: 70 trainloss: -0.827975 validloss: -0.7944217\n",
      "time: 113.9080548286438 Epoch: 71 trainloss: -0.8316813 validloss: -0.7894413\n",
      "time: 104.79974102973938 Epoch: 72 trainloss: -0.7980034 validloss: -0.7922432\n",
      "time: 109.77365827560425 Epoch: 73 trainloss: -0.8322884 validloss: -0.7857669\n",
      "time: 106.22043871879578 Epoch: 74 trainloss: -0.83324355 validloss: -0.7804537\n",
      "time: 102.63986134529114 Epoch: 75 trainloss: -0.8269956 validloss: -0.7934138\n",
      "time: 116.54667019844055 Epoch: 76 trainloss: -0.8271533 validloss: -0.7954136\n",
      "time: 101.41023969650269 Epoch: 77 trainloss: -0.8341439 validloss: -0.79409826\n",
      "time: 98.25946235656738 Epoch: 78 trainloss: -0.8283792 validloss: -0.7878543\n",
      "time: 98.23538756370544 Epoch: 79 trainloss: -0.80717295 validloss: -0.73559225\n",
      "time: 98.12808632850647 Epoch: 80 trainloss: -0.8161141 validloss: -0.7927634\n",
      "time: 98.26725316047668 Epoch: 81 trainloss: -0.838271 validloss: -0.8035959\n",
      "time: 98.31104969978333 Epoch: 82 trainloss: -0.81923 validloss: -0.80165756\n",
      "time: 100.08810758590698 Epoch: 83 trainloss: -0.83937335 validloss: -0.7719636\n",
      "time: 110.5805139541626 Epoch: 84 trainloss: -0.831789 validloss: -0.76312476\n",
      "time: 101.5668351650238 Epoch: 85 trainloss: -0.84707963 validloss: -0.77983624\n",
      "time: 101.66729760169983 Epoch: 86 trainloss: -0.8388921 validloss: -0.799336\n",
      "time: 103.84106945991516 Epoch: 87 trainloss: -0.8425012 validloss: -0.80567986\n",
      "time: 99.2466950416565 Epoch: 88 trainloss: -0.8100741 validloss: -0.80754143\n",
      "time: 99.0641074180603 Epoch: 89 trainloss: -0.83868897 validloss: -0.80047935\n",
      "time: 109.29019713401794 Epoch: 90 trainloss: -0.85685605 validloss: -0.7628419\n",
      "time: 128.4217438697815 Epoch: 91 trainloss: -0.8553722 validloss: -0.77884996\n",
      "time: 133.25796341896057 Epoch: 92 trainloss: -0.8584881 validloss: -0.8129347\n",
      "time: 147.23384308815002 Epoch: 93 trainloss: -0.8472173 validloss: -0.8020788\n",
      "time: 121.09214043617249 Epoch: 94 trainloss: -0.8634627 validloss: -0.8044911\n",
      "time: 107.64839339256287 Epoch: 95 trainloss: -0.8528837 validloss: -0.8022787\n",
      "time: 101.74554991722107 Epoch: 96 trainloss: -0.8222502 validloss: -0.78370667\n",
      "time: 110.49452066421509 Epoch: 97 trainloss: -0.8436007 validloss: -0.7809797\n",
      "time: 115.59905624389648 Epoch: 98 trainloss: -0.85363805 validloss: -0.78934014\n",
      "time: 117.38014483451843 Epoch: 99 trainloss: -0.8480855 validloss: -0.8053131\n",
      "time: 104.10500288009644 Epoch: 100 trainloss: -0.86615956 validloss: -0.7946801\n",
      "time: 100.66471934318542 Epoch: 101 trainloss: -0.85848165 validloss: -0.7956829\n",
      "time: 99.92255210876465 Epoch: 102 trainloss: -0.86102563 validloss: -0.81172806\n",
      "time: 100.00757145881653 Epoch: 103 trainloss: -0.8599482 validloss: -0.81778747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 100.03697514533997 Epoch: 104 trainloss: -0.86142844 validloss: -0.8189102\n",
      "time: 111.5131688117981 Epoch: 105 trainloss: -0.87197465 validloss: -0.81019485\n",
      "time: 102.14282488822937 Epoch: 106 trainloss: -0.8714419 validloss: -0.785817\n",
      "time: 107.58115720748901 Epoch: 107 trainloss: -0.85275906 validloss: -0.6779071\n",
      "time: 110.5771872997284 Epoch: 108 trainloss: -0.85043967 validloss: -0.7449916\n",
      "time: 108.27163982391357 Epoch: 109 trainloss: -0.8662728 validloss: -0.7930954\n",
      "time: 125.20734596252441 Epoch: 110 trainloss: -0.8633196 validloss: -0.82657224\n",
      "time: 125.38067531585693 Epoch: 111 trainloss: -0.87527233 validloss: -0.8255826\n",
      "time: 126.43857717514038 Epoch: 112 trainloss: -0.85854983 validloss: -0.8267223\n",
      "time: 101.52550458908081 Epoch: 113 trainloss: -0.8525556 validloss: -0.79445165\n",
      "time: 116.09350967407227 Epoch: 114 trainloss: -0.8528991 validloss: -0.7426984\n",
      "time: 141.10627675056458 Epoch: 115 trainloss: -0.87358564 validloss: -0.7812447\n",
      "time: 134.84520030021667 Epoch: 116 trainloss: -0.8658353 validloss: -0.81866735\n",
      "time: 130.08804512023926 Epoch: 117 trainloss: -0.88036793 validloss: -0.8152234\n",
      "time: 129.18168663978577 Epoch: 118 trainloss: -0.870715 validloss: -0.81595755\n",
      "time: 141.07404899597168 Epoch: 119 trainloss: -0.88211715 validloss: -0.8305816\n",
      "time: 147.31387305259705 Epoch: 120 trainloss: -0.8804734 validloss: -0.8162632\n",
      "time: 138.86818838119507 Epoch: 121 trainloss: -0.87024426 validloss: -0.80982393\n",
      "time: 177.1329963207245 Epoch: 122 trainloss: -0.8432328 validloss: -0.82685226\n",
      "time: 174.62696361541748 Epoch: 123 trainloss: -0.8786864 validloss: -0.83145\n",
      "time: 208.3502492904663 Epoch: 124 trainloss: -0.8890174 validloss: -0.82557136\n",
      "time: 207.63444995880127 Epoch: 125 trainloss: -0.8799391 validloss: -0.82042646\n",
      "time: 206.51440119743347 Epoch: 126 trainloss: -0.88343596 validloss: -0.8260373\n",
      "time: 199.38621520996094 Epoch: 127 trainloss: -0.8827306 validloss: -0.8161915\n",
      "time: 191.613299369812 Epoch: 128 trainloss: -0.8854288 validloss: -0.8164791\n",
      "time: 196.582848072052 Epoch: 129 trainloss: -0.869311 validloss: -0.81947047\n",
      "time: 204.95621013641357 Epoch: 130 trainloss: -0.8932101 validloss: -0.82732767\n",
      "time: 184.6135323047638 Epoch: 131 trainloss: -0.8785214 validloss: -0.8284896\n",
      "time: 156.1862711906433 Epoch: 132 trainloss: -0.8697709 validloss: -0.8294774\n",
      "time: 153.5883424282074 Epoch: 133 trainloss: -0.88838166 validloss: -0.83926815\n",
      "time: 153.67316722869873 Epoch: 134 trainloss: -0.89457774 validloss: -0.8410363\n",
      "time: 153.80082297325134 Epoch: 135 trainloss: -0.8825028 validloss: -0.8336886\n",
      "time: 153.48204970359802 Epoch: 136 trainloss: -0.8975128 validloss: -0.8331253\n",
      "time: 153.20296120643616 Epoch: 137 trainloss: -0.8933584 validloss: -0.826145\n",
      "time: 153.6341052055359 Epoch: 138 trainloss: -0.89149415 validloss: -0.82782096\n",
      "time: 153.4725992679596 Epoch: 139 trainloss: -0.89413255 validloss: -0.83200854\n",
      "time: 153.52050280570984 Epoch: 140 trainloss: -0.8841811 validloss: -0.8452271\n",
      "time: 153.65350246429443 Epoch: 141 trainloss: -0.8936586 validloss: -0.83933365\n",
      "time: 153.3740313053131 Epoch: 142 trainloss: -0.8999089 validloss: -0.8338474\n",
      "time: 153.88770580291748 Epoch: 143 trainloss: -0.896717 validloss: -0.8323771\n",
      "time: 153.7219181060791 Epoch: 144 trainloss: -0.90433204 validloss: -0.82741195\n",
      "time: 153.91398572921753 Epoch: 145 trainloss: -0.90793014 validloss: -0.8299705\n",
      "time: 156.6500735282898 Epoch: 146 trainloss: -0.88098264 validloss: -0.84200156\n",
      "time: 156.85985898971558 Epoch: 147 trainloss: -0.9058742 validloss: -0.849288\n",
      "time: 155.6387906074524 Epoch: 148 trainloss: -0.9012979 validloss: -0.85268676\n",
      "time: 155.53298425674438 Epoch: 149 trainloss: -0.9023817 validloss: -0.8530246\n",
      "time: 159.43234062194824 Epoch: 150 trainloss: -0.90762323 validloss: -0.84953576\n",
      "time: 162.22261500358582 Epoch: 151 trainloss: -0.9104542 validloss: -0.843392\n",
      "time: 106.97477054595947 Epoch: 152 trainloss: -0.9120289 validloss: -0.8473655\n",
      "time: 114.41277194023132 Epoch: 153 trainloss: -0.90095997 validloss: -0.84491575\n",
      "time: 126.89788770675659 Epoch: 154 trainloss: -0.90239704 validloss: -0.79814756\n",
      "time: 150.2926847934723 Epoch: 155 trainloss: -0.8880587 validloss: -0.846541\n",
      "time: 156.67321753501892 Epoch: 156 trainloss: -0.8973136 validloss: -0.84529346\n",
      "time: 199.2178544998169 Epoch: 157 trainloss: -0.91127574 validloss: -0.84048176\n",
      "time: 195.72692584991455 Epoch: 158 trainloss: -0.9013403 validloss: -0.83667606\n",
      "time: 128.79878902435303 Epoch: 159 trainloss: -0.8976932 validloss: -0.85627323\n",
      "time: 128.88127946853638 Epoch: 160 trainloss: -0.8938824 validloss: -0.85482645\n",
      "time: 128.98307156562805 Epoch: 161 trainloss: -0.9022825 validloss: -0.83401054\n",
      "time: 134.07164883613586 Epoch: 162 trainloss: -0.875374 validloss: -0.828922\n",
      "time: 125.04460549354553 Epoch: 163 trainloss: -0.8987746 validloss: -0.84027666\n",
      "time: 125.11736226081848 Epoch: 164 trainloss: -0.8969677 validloss: -0.838297\n",
      "time: 124.96261239051819 Epoch: 165 trainloss: -0.89766866 validloss: -0.8398716\n",
      "time: 125.31445741653442 Epoch: 166 trainloss: -0.90140444 validloss: -0.83105314\n",
      "time: 125.12018370628357 Epoch: 167 trainloss: -0.89845425 validloss: -0.8417203\n",
      "time: 125.22899580001831 Epoch: 168 trainloss: -0.90829 validloss: -0.8488262\n",
      "time: 124.92480087280273 Epoch: 169 trainloss: -0.89368355 validloss: -0.83760446\n",
      "time: 125.43440532684326 Epoch: 170 trainloss: -0.9024625 validloss: -0.8335499\n",
      "time: 125.03322076797485 Epoch: 171 trainloss: -0.90521973 validloss: -0.85560834\n",
      "time: 125.18499255180359 Epoch: 172 trainloss: -0.9124579 validloss: -0.8500512\n",
      "time: 125.54837274551392 Epoch: 173 trainloss: -0.9058115 validloss: -0.8435926\n",
      "time: 141.42458176612854 Epoch: 174 trainloss: -0.9023173 validloss: -0.8458119\n",
      "time: 134.43056297302246 Epoch: 175 trainloss: -0.91522545 validloss: -0.84721196\n",
      "time: 130.8730947971344 Epoch: 176 trainloss: -0.90945214 validloss: -0.84712994\n",
      "time: 129.5955274105072 Epoch: 177 trainloss: -0.9130193 validloss: -0.8286141\n",
      "time: 129.6221399307251 Epoch: 178 trainloss: -0.9155437 validloss: -0.83613366\n",
      "time: 128.4865448474884 Epoch: 179 trainloss: -0.89708495 validloss: -0.85497147\n",
      "time: 129.12161922454834 Epoch: 180 trainloss: -0.90704656 validloss: -0.84270525\n",
      "time: 125.61301374435425 Epoch: 181 trainloss: -0.8950058 validloss: -0.8479699\n",
      "time: 133.6120285987854 Epoch: 182 trainloss: -0.89444745 validloss: -0.83745086\n",
      "time: 125.34920525550842 Epoch: 183 trainloss: -0.90139073 validloss: -0.8224359\n",
      "time: 125.57713484764099 Epoch: 184 trainloss: -0.8977707 validloss: -0.8457266\n",
      "time: 125.53542184829712 Epoch: 185 trainloss: -0.9122508 validloss: -0.8508516\n",
      "time: 124.90905261039734 Epoch: 186 trainloss: -0.9166438 validloss: -0.8380924\n",
      "time: 125.25776886940002 Epoch: 187 trainloss: -0.9013502 validloss: -0.8537547\n",
      "time: 125.04285478591919 Epoch: 188 trainloss: -0.9123701 validloss: -0.8502807\n",
      "time: 125.18860149383545 Epoch: 189 trainloss: -0.91800964 validloss: -0.8508367\n",
      "time: 125.18928742408752 Epoch: 190 trainloss: -0.902158 validloss: -0.853511\n",
      "time: 125.25492668151855 Epoch: 191 trainloss: -0.9196518 validloss: -0.8417656\n",
      "time: 124.9746208190918 Epoch: 192 trainloss: -0.9249863 validloss: -0.85384023\n",
      "time: 125.26999521255493 Epoch: 193 trainloss: -0.9184143 validloss: -0.8617181\n",
      "time: 125.2290244102478 Epoch: 194 trainloss: -0.9244335 validloss: -0.857924\n",
      "time: 124.94671297073364 Epoch: 195 trainloss: -0.92612076 validloss: -0.84862715\n",
      "time: 125.1410174369812 Epoch: 196 trainloss: -0.91924363 validloss: -0.8570666\n",
      "time: 125.41791415214539 Epoch: 197 trainloss: -0.9237536 validloss: -0.8640219\n",
      "time: 124.89681029319763 Epoch: 198 trainloss: -0.89700013 validloss: -0.83583516\n",
      "time: 125.08309960365295 Epoch: 199 trainloss: -0.91972667 validloss: -0.86245865\n",
      "time: 125.47221755981445 Epoch: 200 trainloss: -0.92068434 validloss: -0.85808563\n",
      "time: 125.18145442008972 Epoch: 201 trainloss: -0.9065079 validloss: -0.8337353\n",
      "time: 125.00224423408508 Epoch: 202 trainloss: -0.91957533 validloss: -0.82941145\n",
      "time: 125.30027079582214 Epoch: 203 trainloss: -0.92368054 validloss: -0.8458021\n",
      "time: 125.36578392982483 Epoch: 204 trainloss: -0.9112154 validloss: -0.8520228\n",
      "time: 124.9403064250946 Epoch: 205 trainloss: -0.9216793 validloss: -0.8527576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125.2642023563385 Epoch: 206 trainloss: -0.9142902 validloss: -0.85737926\n",
      "time: 125.2261745929718 Epoch: 207 trainloss: -0.89594054 validloss: -0.8504585\n",
      "time: 131.04328155517578 Epoch: 208 trainloss: -0.92365485 validloss: -0.8342425\n",
      "time: 134.79119277000427 Epoch: 209 trainloss: -0.9185366 validloss: -0.84746\n",
      "time: 130.9949655532837 Epoch: 210 trainloss: -0.923588 validloss: -0.85706466\n",
      "time: 138.69810390472412 Epoch: 211 trainloss: -0.9128103 validloss: -0.84623253\n",
      "time: 138.85643005371094 Epoch: 212 trainloss: -0.9265204 validloss: -0.859681\n",
      "time: 136.35539650917053 Epoch: 213 trainloss: -0.9224039 validloss: -0.8664108\n",
      "time: 138.59972047805786 Epoch: 214 trainloss: -0.9226113 validloss: -0.8545657\n",
      "time: 131.91803693771362 Epoch: 215 trainloss: -0.9206498 validloss: -0.8476559\n"
     ]
    }
   ],
   "source": [
    "Es_train=[]\n",
    "for epoch in range(0,epochs+1):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    metric.reset()\n",
    "\n",
    "    train_iter.reset()\n",
    "    \n",
    "    valid_iter.reset()\n",
    "    \n",
    "\n",
    "    for batch in train_iter:\n",
    "        # Copy data to executor input. Note the [:].\n",
    "        data[:] = batch.data[0]\n",
    "        label[:] = batch.label[0]\n",
    "\n",
    "        # Forward\n",
    "        outputs=exe.forward(is_train=True)\n",
    "        Es_train.append(outputs[1].asnumpy()[0])\n",
    "        # Backward\n",
    "        exe.backward()\n",
    "\n",
    "        # Update\n",
    "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
    "            weight, grad = pair\n",
    "            updater(i, grad, weight)   \n",
    "        metric.update(batch.label[0], exe.outputs[0])#metric.update(label,p)\n",
    "        \n",
    "    e=metric.get()\n",
    "    err_train=-e[1].asnumpy()[0]\n",
    "    \n",
    "    if epoch % 100== 0:       \n",
    "        #print(\"do_checkpoint\")\n",
    "        arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
    "        aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
    "        mx.model.save_checkpoint(prefix, epoch, network, arg, aux)\n",
    "        \n",
    "        \n",
    "    #compute valid loss per epoch    \n",
    "    metric.reset()\n",
    "    for batch in valid_iter:        \n",
    "        data[:] = batch.data[0]       \n",
    "        label[:] = batch.label[0]\n",
    "        # predict\n",
    "        outputs = exe.forward(is_train=False)\n",
    "        metric.update(batch.label[0], exe.outputs[0])\n",
    "    e=metric.get()\n",
    "    err_valid=-e[1].asnumpy()[0]\n",
    "    end = time.time()\n",
    "    print('time:',end-start,'Epoch:',epoch,'trainloss:',err_train,'validloss:',err_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(Es_train2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Es_train[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Es_train = np.array(Es_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Es_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Es_train2 = Es_train.reshape((-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(Es_train2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_iter.num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "68/34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Es_train,'.-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=1\n",
    "test_iter=nn.FileIter(test_data_path,test_idx_path,batch_size=BATCH_SIZE,do_shuffle=False,mean_image=x_mean,std_image = x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_sample_at(valid_iter,n):\n",
    "    valid_iter.ind2=[n]\n",
    "    return valid_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "K = valid_iter.num_data\n",
    "n = random.randint(0,K)\n",
    "print('index = '+ str(n))\n",
    "batch = get_sample_at(valid_iter,n)\n",
    "\n",
    "\n",
    "data[:] = batch.data[0]       \n",
    "label[:] = batch.label[0]\n",
    "# predict\n",
    "outputs = exe.forward(is_train=False)\n",
    "\n",
    "\n",
    "p = outputs[0][0].asnumpy().reshape(32,32,32)\n",
    "\n",
    "\n",
    "\n",
    "X = batch.data[0][0][0].asnumpy()\n",
    "Y = batch.label[0][0].asnumpy().reshape((32,32,32))\n",
    "                              \n",
    "img = X*x_std+x_mean\n",
    "msk1 = Y\n",
    "msk2 = p>.5#.001\n",
    "msk2=msk2*1\n",
    "msk1= np.ma.masked_where(msk1 == 0, msk1)\n",
    "msk2= np.ma.masked_where(msk2 == 0, msk2)\n",
    "\n",
    "zs=32\n",
    "num_rows=np.ceil(zs/8).astype(int)\n",
    "f, plots = plt.subplots(num_rows, 8, sharex='col', sharey='row', figsize=(10, 8))\n",
    "for i in range(zs):\n",
    "    plots[i // 8, i % 8].axis('off')\n",
    "    plots[i // 8, i % 8].imshow(img[i], 'gray',vmin=0,vmax=1)\n",
    "    plots[i // 8, i % 8].imshow(msk1[i],interpolation='none', cmap=plt.cm.Reds, alpha=.7, vmin=0, vmax=1)\n",
    "    plots[i // 8, i % 8].imshow(msk2[i],interpolation='none',  alpha=0.4, vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "      \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {
    "height": "290px",
    "width": "353.333px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "65.6167px",
    "left": "954px",
    "top": "110.567px",
    "width": "160px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
