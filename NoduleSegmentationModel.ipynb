{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodule Segmentation: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Configuration</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-mean-of-images\" data-toc-modified-id=\"Find-mean-of-images-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Find mean of images</a></span></li><li><span><a href=\"#Find-variance-of-images\" data-toc-modified-id=\"Find-variance-of-images-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Find variance of images</a></span></li></ul></li><li><span><a href=\"#Data-Iterator\" data-toc-modified-id=\"Data-Iterator-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Iterator</a></span></li><li><span><a href=\"#Evaluation-Metric\" data-toc-modified-id=\"Evaluation-Metric-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation Metric</a></span></li><li><span><a href=\"#Model-Architecture\" data-toc-modified-id=\"Model-Architecture-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Architecture</a></span></li><li><span><a href=\"#Optimizer\" data-toc-modified-id=\"Optimizer-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Optimizer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find--learning-rate\" data-toc-modified-id=\"Find--learning-rate-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Find  learning rate</a></span></li><li><span><a href=\"#Optimizer-Parameters\" data-toc-modified-id=\"Optimizer-Parameters-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Optimizer Parameters</a></span></li></ul></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Train Model</a></span></li><li><span><a href=\"#Evaluate-Model\" data-toc-modified-id=\"Evaluate-Model-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluate Model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mynnet7 as nn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interm_dir4='/home/mas/x110/Datasets/Dataset1/' \n",
    "train_data_path=interm_dir4+'processed/Train31Oct2018augment.rec'\n",
    "train_idx_path=interm_dir4+'processed/Train31Oct2018augment.rec'\n",
    "vaid_data_path=interm_dir4+'processed/Valid31Oct2018augment.rec'\n",
    "valid_idx_path=interm_dir4+'processed/Valid31Oct2018augment.rec'\n",
    "test_data_path=interm_dir4+'processed/Test31Oct2018augment.rec'\n",
    "test_idx_path=interm_dir4+'processed/Test31Oct2018augment.rec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_stats = True\n",
    "bs = 5\n",
    "load_model = True\n",
    "model_path = \"/home/mas/x110/model/oct22\"\n",
    "model_epoch=499\n",
    "prefix = \"/home/mas/x110/model/oct23\"\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find mean of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2815327279660965"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if find_stats:\n",
    "    BATCH_SIZE=1\n",
    "    train_iter=FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_augment=True,mean_image=0,std_image=1)\n",
    "    train_iter.reset()\n",
    "    x_mean = np.zeros((32,32,32))\n",
    "    for i,batch in enumerate(train_iter):\n",
    "        X =  batch.data[0][0][0].asnumpy()\n",
    "        x_mean+=X\n",
    "    x_mean=np.mean(x_mean/i)\n",
    "    # Saving the objects:\n",
    "    with open(interm_dir4+'processed/x_mean.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([x_mean], f)\n",
    "\n",
    "else:\n",
    "    with open(interm_dir4+'processed/x_mean.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "        x_mean = pickle.load(f)\n",
    "x_mean#x_mean=.2815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_mean=.2815"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variance of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28066587175585705"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if find_stats: \n",
    "    BATCH_SIZE=1\n",
    "    train_iter=FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_augment=True,mean_image=0,std_image = 1)\n",
    "    train_iter.reset()\n",
    "    x_var = np.zeros((32,32,32))\n",
    "    for i,batch in enumerate(train_iter):\n",
    "        X =  (batch.data[0][0][0].asnumpy()-x_mean)**2\n",
    "        x_var+=X\n",
    "    #x_var=x_var/(i-1)\n",
    "    #x_var#x_mean=.2815\n",
    "    N = i*32*32*32\n",
    "    x_var = np.sum(x_var)/(N-1)\n",
    "    x_var#x_var = .07877\n",
    "    x_std = np.sqrt(x_var)#x_std=.2807\n",
    "    with open(interm_dir4+'processed/x_std.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([x_std], f)\n",
    "else:\n",
    "    with open(interm_dir4+'processed/x_std.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "        x_mean = pickle.load(f)\n",
    "x_std#x_mean=.2815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_std=.2807"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': (5, 1, 32, 32, 32), 'softmax_label': (5, 32768)}\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=bs\n",
    "train_iter=FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_augment=False,mean_image=x_mean,std_image = x_std)\n",
    "input_shapes = dict(train_iter.provide_data+train_iter.provide_label)\n",
    "print(input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': (5, 1, 32, 32, 32), 'softmax_label': (5, 32768)}\n"
     ]
    }
   ],
   "source": [
    "print(input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=bs\n",
    "valid_iter=FileIter(valid_data_path,valid_idx_path,batch_size=BATCH_SIZE,do_augment=False,mean_image=x_mean,std_image = x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter.reset()\n",
    "valid_iter.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============Evaluation metric(s)================= \n",
    "metric = mx.metric.CustomMetric(feval=nn.dice_coef2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    network, arg_params, aux_params = mx.model.load_checkpoint(model_path , model_epoch)\n",
    "\n",
    "    # Binding\n",
    "    exe = network.simple_bind(ctx=mx.gpu(0), **input_shapes)\n",
    "\n",
    "\n",
    "    exe.copy_params_from(arg_params, aux_params)\n",
    "else:\n",
    "\n",
    "    network = nn.get_net_317()\n",
    "    init = mx.init.Normal(0.01) #note biases and gamma/beta are not affected\n",
    "\n",
    "    # Binding\n",
    "    exe = network.simple_bind(ctx=mx.gpu(), **input_shapes)\n",
    "    # get handle to input arrays\n",
    "    arg_arrays = dict(zip(network.list_arguments(), exe.arg_arrays))\n",
    "    data = arg_arrays[train_iter.provide_data[0][0]]\n",
    "    label = arg_arrays[train_iter.provide_label[0][0]]\n",
    "\n",
    "    # Binding\n",
    "    exe = network.simple_bind(ctx=mx.gpu(), **input_shapes)\n",
    "# get handle to input arrays\n",
    "arg_arrays = dict(zip(network.list_arguments(), exe.arg_arrays))\n",
    "data = arg_arrays[train_iter.provide_data[0][0]]\n",
    "label = arg_arrays[train_iter.provide_label[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find  learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-21e605261e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_iter' is not defined"
     ]
    }
   ],
   "source": [
    "nb=train_iter.num_data//train_iter.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched=nn.lr_find(1e-4,nb,end_lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need to create an optimizer for updating weights\n",
    "opt = mx.optimizer.SGD(\n",
    "    learning_rate=.01,\n",
    "    momentum=0.9,\n",
    "    wd=0.00001,\n",
    "    lr_scheduler=sched)\n",
    "\n",
    "updater = mx.optimizer.get_updater(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,1):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    metric.reset()\n",
    "\n",
    "    train_iter.reset()\n",
    "    \n",
    "    valid_iter.reset()\n",
    "    \n",
    "    sched.reset()\n",
    "        \n",
    "    sched.on_train_begin()\n",
    "    \n",
    "\n",
    "    for batch in train_iter:\n",
    "        # Copy data to executor input. Note the [:].\n",
    "        data[:] = batch.data[0]\n",
    "        label[:] = batch.label[0]\n",
    "\n",
    "        # Forward\n",
    "        outputs=exe.forward(is_train=True)\n",
    "        # Backward\n",
    "        exe.backward()\n",
    "\n",
    "        # Update\n",
    "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
    "            weight, grad = pair\n",
    "            updater(i, grad, weight)   \n",
    "        metric.update(batch.label[0], exe.outputs[0])#metric.update(label,p)\n",
    "        \n",
    "        e=metric.get()\n",
    "        err_train=-e[1].asnumpy()[0]\n",
    "        sched.on_batch_end(err_train)\n",
    "    \n",
    "    if epoch % 100== 0:       \n",
    "        #print(\"do_checkpoint\")\n",
    "        arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
    "        aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
    "        mx.model.save_checkpoint(prefix, epoch, network, arg, aux)\n",
    "        \n",
    "        \n",
    "    #compute valid loss per epoch    \n",
    "    metric.reset()\n",
    "    for batch in valid_iter:        \n",
    "        data[:] = batch.data[0]       \n",
    "        label[:] = batch.label[0]\n",
    "        # predict\n",
    "        outputs = exe.forward(is_train=False)\n",
    "        metric.update(batch.label[0], exe.outputs[0])\n",
    "    e=metric.get()\n",
    "    err_valid=-e[1].asnumpy()[0]\n",
    "    end = time.time()\n",
    "    print('time:',end-start,'Epoch:',epoch,'trainloss:',err_train,'validloss:',err_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sched.lrs, sched.losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need to create an optimizer for updating weights\n",
    "opt = mx.optimizer.SGD(\n",
    "    learning_rate=.03,rescale_grad=1.0/train_iter.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updater.optimizer.lr_scheduler=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updater = mx.optimizer.get_updater(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(0,epochs+1):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    metric.reset()\n",
    "\n",
    "    train_iter.reset()\n",
    "    \n",
    "    valid_iter.reset()\n",
    "    \n",
    "\n",
    "    for batch in train_iter:\n",
    "        # Copy data to executor input. Note the [:].\n",
    "        data[:] = batch.data[0]\n",
    "        label[:] = batch.label[0]\n",
    "\n",
    "        # Forward\n",
    "        outputs=exe.forward(is_train=True)\n",
    "        # Backward\n",
    "        exe.backward()\n",
    "\n",
    "        # Update\n",
    "        for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
    "            weight, grad = pair\n",
    "            updater(i, grad, weight)   \n",
    "        metric.update(batch.label[0], exe.outputs[0])#metric.update(label,p)\n",
    "        \n",
    "    e=metric.get()\n",
    "    err_train=-e[1].asnumpy()[0]\n",
    "    \n",
    "    if epoch % 100== 0:       \n",
    "        #print(\"do_checkpoint\")\n",
    "        arg={k:v for k, v in arg_arrays.items() if k not in input_shapes}\n",
    "        aux = dict(zip(network.list_auxiliary_states(), exe.aux_arrays))\n",
    "        mx.model.save_checkpoint(prefix, epoch, network, arg, aux)\n",
    "        \n",
    "        \n",
    "    #compute valid loss per epoch    \n",
    "    metric.reset()\n",
    "    for batch in valid_iter:        \n",
    "        data[:] = batch.data[0]       \n",
    "        label[:] = batch.label[0]\n",
    "        # predict\n",
    "        outputs = exe.forward(is_train=False)\n",
    "        metric.update(batch.label[0], exe.outputs[0])\n",
    "    e=metric.get()\n",
    "    err_valid=-e[1].asnumpy()[0]\n",
    "    end = time.time()\n",
    "    print('time:',end-start,'Epoch:',epoch,'trainloss:',err_train,'validloss:',err_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1\n",
    "valid_iter=nn.FileIter(train_data_path,train_idx_path,batch_size=BATCH_SIZE,do_shuffle=False,mean_image=x_mean,std_image = x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_at(valid_iter,n):\n",
    "    valid_iter.ind2=[n]\n",
    "    return valid_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = valid_iter.num_data\n",
    "n = random.randint(0,K)\n",
    "print('index = '+ str(n))\n",
    "batch = get_sample_at(valid_iter,n)\n",
    "\n",
    "\n",
    "data[:] = batch.data[0]       \n",
    "label[:] = batch.label[0]\n",
    "# predict\n",
    "outputs = exe.forward(is_train=False)\n",
    "\n",
    "\n",
    "p = outputs[0][0].asnumpy().reshape(32,32,32)\n",
    "\n",
    "\n",
    "\n",
    "X = batch.data[0][0][0].asnumpy()\n",
    "Y = batch.label[0][0].asnumpy().reshape((32,32,32))\n",
    "                              \n",
    "img = X*x_std+x_mean\n",
    "msk1 = Y\n",
    "msk2 = p>.5#.001\n",
    "msk2=msk2*1\n",
    "msk1= np.ma.masked_where(msk1 == 0, msk1)\n",
    "msk2= np.ma.masked_where(msk2 == 0, msk2)\n",
    "\n",
    "zs=32\n",
    "num_rows=np.ceil(zs/8).astype(int)\n",
    "f, plots = plt.subplots(num_rows, 8, sharex='col', sharey='row', figsize=(10, 8))\n",
    "for i in range(zs):\n",
    "    plots[i // 8, i % 8].axis('off')\n",
    "    plots[i // 8, i % 8].imshow(img[i], 'gray',vmin=0,vmax=1)\n",
    "    plots[i // 8, i % 8].imshow(msk1[i],interpolation='none', cmap=plt.cm.Reds, alpha=.7, vmin=0, vmax=1)\n",
    "    plots[i // 8, i % 8].imshow(msk2[i],interpolation='none',  alpha=0.4, vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "      \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {
    "height": "290px",
    "width": "353.333px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "449.333px",
    "left": "980px",
    "top": "134.667px",
    "width": "204.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
